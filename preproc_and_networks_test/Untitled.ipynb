{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "import random\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 16, 20, 8]\n"
     ]
    }
   ],
   "source": [
    "fnames = os.listdir('../train')\n",
    "#print(fnames)\n",
    "n_classes = 10\n",
    "\n",
    "speaker_idxs = []\n",
    "for i in range(4):\n",
    "    speaker_idxs.append(random.randint(0, (len(fnames) // n_classes)-1))\n",
    "\n",
    "print(speaker_idxs)\n",
    "X_train, X_test = [], []\n",
    "y_train, y_test = [], []\n",
    "len_files = []\n",
    "for  it in range(len(fnames)):\n",
    "    fs, tmp = wavfile.read('../train/'+fnames[it])\n",
    "    #checking if data length is cohesive\n",
    "    tmp = tmp / max(abs(tmp))\n",
    "    if len(tmp) < fs:\n",
    "        len_to_append = fs - len(tmp)\n",
    "        to_append = np.zeros(len_to_append)\n",
    "        tmp = np.append(tmp, to_append)\n",
    "    else:\n",
    "        tmp = tmp[:fs]\n",
    "    \n",
    "    if it//n_classes in speaker_idxs:\n",
    "        X_test.append(tmp)\n",
    "        y_test.append(it % n_classes)\n",
    "    else:\n",
    "        X_train.append(tmp)\n",
    "        y_train.append(it % n_classes)\n",
    "    \n",
    "# plt.plot(tmp)\n",
    "# plt.show()\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 180/180 [00:01<00:00, 124.51it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 40/40 [00:00<00:00, 140.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(180, 99, 13)\n",
      "1287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\wiktor\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:46: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_17 (InputLayer)        (None, 1287)              0         \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 128)               164864    \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 190,282\n",
      "Trainable params: 190,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 180 samples, validate on 40 samples\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 13.7138 - acc: 0.1000 - val_loss: 10.0393 - val_acc: 0.1250\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 11.5794 - acc: 0.1000 - val_loss: 8.7542 - val_acc: 0.2000\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 9.6421 - acc: 0.1889 - val_loss: 6.8509 - val_acc: 0.2250\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 8.3722 - acc: 0.1778 - val_loss: 4.5747 - val_acc: 0.2500\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 6.6082 - acc: 0.2611 - val_loss: 3.7502 - val_acc: 0.4000\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 5.5916 - acc: 0.3611 - val_loss: 3.1962 - val_acc: 0.4500\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 4.6067 - acc: 0.4500 - val_loss: 2.5094 - val_acc: 0.5500\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 3.9938 - acc: 0.4667 - val_loss: 1.9236 - val_acc: 0.5500\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 3.2481 - acc: 0.4722 - val_loss: 1.7507 - val_acc: 0.6250\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 2.5333 - acc: 0.5889 - val_loss: 1.5488 - val_acc: 0.6000\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 2.0629 - acc: 0.6111 - val_loss: 1.2507 - val_acc: 0.6750\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 308ms/step - loss: 1.6066 - acc: 0.6333 - val_loss: 0.9381 - val_acc: 0.7000\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 1.2330 - acc: 0.7444 - val_loss: 0.7241 - val_acc: 0.7750\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 1.0733 - acc: 0.6944 - val_loss: 0.6167 - val_acc: 0.7250\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 0.8527 - acc: 0.7611 - val_loss: 0.5348 - val_acc: 0.7750\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 0.8450 - acc: 0.7222 - val_loss: 0.5093 - val_acc: 0.7750\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.8912 - acc: 0.7222 - val_loss: 0.5179 - val_acc: 0.8000\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 0.9000 - acc: 0.7278 - val_loss: 0.5233 - val_acc: 0.8250\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.8914 - acc: 0.7500 - val_loss: 0.5059 - val_acc: 0.8250\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 0.6319 - acc: 0.7944 - val_loss: 0.4929 - val_acc: 0.8500\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 308ms/step - loss: 0.5304 - acc: 0.8222 - val_loss: 0.4835 - val_acc: 0.8500\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 0.5423 - acc: 0.8222 - val_loss: 0.4583 - val_acc: 0.8500\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 0.5266 - acc: 0.8222 - val_loss: 0.4346 - val_acc: 0.8750\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 0.3521 - acc: 0.8944 - val_loss: 0.4123 - val_acc: 0.9000\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 0.3979 - acc: 0.8778 - val_loss: 0.3950 - val_acc: 0.9000\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 0.3034 - acc: 0.8722 - val_loss: 0.3792 - val_acc: 0.9000\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 0.2494 - acc: 0.9389 - val_loss: 0.3598 - val_acc: 0.9000\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.3936 - acc: 0.8667 - val_loss: 0.3453 - val_acc: 0.9000\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 0.2577 - acc: 0.8944 - val_loss: 0.3376 - val_acc: 0.9000\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 0.3116 - acc: 0.8833 - val_loss: 0.3288 - val_acc: 0.9000\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 0.3659 - acc: 0.8833 - val_loss: 0.3254 - val_acc: 0.9250\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 306ms/step - loss: 0.3028 - acc: 0.8944 - val_loss: 0.3266 - val_acc: 0.9000\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.1486 - acc: 0.9389 - val_loss: 0.3267 - val_acc: 0.9000\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.1868 - acc: 0.9167 - val_loss: 0.3246 - val_acc: 0.9000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 1s 507ms/step - loss: 0.1834 - acc: 0.9167 - val_loss: 0.3181 - val_acc: 0.9000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 0.1552 - acc: 0.9444 - val_loss: 0.3129 - val_acc: 0.9000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 0.2000 - acc: 0.9500 - val_loss: 0.3136 - val_acc: 0.8750\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.2496 - acc: 0.9111 - val_loss: 0.3111 - val_acc: 0.8750\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.1633 - acc: 0.9500 - val_loss: 0.3122 - val_acc: 0.9000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 0.1146 - acc: 0.9667 - val_loss: 0.3142 - val_acc: 0.9000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.2383 - acc: 0.9167 - val_loss: 0.3235 - val_acc: 0.9000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.2225 - acc: 0.9278 - val_loss: 0.3277 - val_acc: 0.9000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 0.2023 - acc: 0.9333 - val_loss: 0.3290 - val_acc: 0.9000\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.0647 - acc: 0.9778 - val_loss: 0.3298 - val_acc: 0.9000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.1155 - acc: 0.9556 - val_loss: 0.3290 - val_acc: 0.9000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.1116 - acc: 0.9611 - val_loss: 0.3279 - val_acc: 0.9000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.1244 - acc: 0.9722 - val_loss: 0.3239 - val_acc: 0.9000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 0.1477 - acc: 0.9556 - val_loss: 0.3218 - val_acc: 0.9000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 0.1601 - acc: 0.9444 - val_loss: 0.3173 - val_acc: 0.9250\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 0.0791 - acc: 0.9722 - val_loss: 0.3117 - val_acc: 0.9250\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 0.0786 - acc: 0.9833 - val_loss: 0.3065 - val_acc: 0.9500\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 0.1001 - acc: 0.9722 - val_loss: 0.3003 - val_acc: 0.9500\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 306ms/step - loss: 0.1428 - acc: 0.9500 - val_loss: 0.2925 - val_acc: 0.9500\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 0.1450 - acc: 0.9444 - val_loss: 0.2877 - val_acc: 0.9500\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 0.1022 - acc: 0.9667 - val_loss: 0.2847 - val_acc: 0.9500\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.0305 - acc: 0.9889 - val_loss: 0.2819 - val_acc: 0.9500\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.1270 - acc: 0.9556 - val_loss: 0.2792 - val_acc: 0.9500\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.1213 - acc: 0.9556 - val_loss: 0.2752 - val_acc: 0.9500\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 0.0643 - acc: 0.9833 - val_loss: 0.2705 - val_acc: 0.9500\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.0593 - acc: 0.9833 - val_loss: 0.2672 - val_acc: 0.9500\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 0.0791 - acc: 0.9667 - val_loss: 0.2641 - val_acc: 0.9500\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 0.0919 - acc: 0.9556 - val_loss: 0.2620 - val_acc: 0.9500\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 0.0749 - acc: 0.9833 - val_loss: 0.2619 - val_acc: 0.9500\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.1138 - acc: 0.9556 - val_loss: 0.2618 - val_acc: 0.9500\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.0421 - acc: 0.9833 - val_loss: 0.2614 - val_acc: 0.9500\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.0495 - acc: 0.9778 - val_loss: 0.2625 - val_acc: 0.9500\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 0.1040 - acc: 0.9722 - val_loss: 0.2624 - val_acc: 0.9500\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.0431 - acc: 0.9889 - val_loss: 0.2622 - val_acc: 0.9500\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.0555 - acc: 0.9833 - val_loss: 0.2621 - val_acc: 0.9500\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.0591 - acc: 0.9722 - val_loss: 0.2609 - val_acc: 0.9250\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.1206 - acc: 0.9722 - val_loss: 0.2604 - val_acc: 0.9250\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.0566 - acc: 0.9667 - val_loss: 0.2612 - val_acc: 0.9500\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.0331 - acc: 0.9889 - val_loss: 0.2623 - val_acc: 0.9500\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.0380 - acc: 0.9778 - val_loss: 0.2604 - val_acc: 0.9500\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.0659 - acc: 0.9778 - val_loss: 0.2577 - val_acc: 0.9500\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.0806 - acc: 0.9778 - val_loss: 0.2557 - val_acc: 0.9500\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.0673 - acc: 0.9778 - val_loss: 0.2545 - val_acc: 0.9500\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.0600 - acc: 0.9722 - val_loss: 0.2537 - val_acc: 0.9500\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.0305 - acc: 0.9889 - val_loss: 0.2528 - val_acc: 0.9500\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.0533 - acc: 0.9778 - val_loss: 0.2524 - val_acc: 0.9500\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.0732 - acc: 0.9722 - val_loss: 0.2495 - val_acc: 0.9500\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.1032 - acc: 0.9778 - val_loss: 0.2478 - val_acc: 0.9500\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.0722 - acc: 0.9667 - val_loss: 0.2476 - val_acc: 0.9500\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.0863 - acc: 0.9778 - val_loss: 0.2481 - val_acc: 0.9500\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.0461 - acc: 0.9778 - val_loss: 0.2444 - val_acc: 0.9500\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 0.0779 - acc: 0.9833 - val_loss: 0.2416 - val_acc: 0.9500\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 0.0612 - acc: 0.9778 - val_loss: 0.2378 - val_acc: 0.9500\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.0376 - acc: 0.9833 - val_loss: 0.2339 - val_acc: 0.9500\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.0618 - acc: 0.9722 - val_loss: 0.2316 - val_acc: 0.9500\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 0.0577 - acc: 0.9833 - val_loss: 0.2313 - val_acc: 0.9500\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.0491 - acc: 0.9833 - val_loss: 0.2315 - val_acc: 0.9500\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 0.0469 - acc: 0.9722 - val_loss: 0.2407 - val_acc: 0.9500\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.0439 - acc: 0.9833 - val_loss: 0.2486 - val_acc: 0.9500\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.0289 - acc: 0.9889 - val_loss: 0.2543 - val_acc: 0.9500\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.0487 - acc: 0.9778 - val_loss: 0.2594 - val_acc: 0.9250\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.0421 - acc: 0.9889 - val_loss: 0.2618 - val_acc: 0.9250\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.0257 - acc: 0.9889 - val_loss: 0.2637 - val_acc: 0.9500\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.0696 - acc: 0.9778 - val_loss: 0.2663 - val_acc: 0.9500\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.0348 - acc: 0.9778 - val_loss: 0.2673 - val_acc: 0.9500\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.0642 - acc: 0.9778 - val_loss: 0.2735 - val_acc: 0.9500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bb14948390>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"MFCC and FNN\"\"\"\n",
    "\n",
    "from python_speech_features import mfcc\n",
    "from tqdm import tqdm\n",
    "X_train_mfcc = []\n",
    "for it in tqdm(range(X_train.shape[0])):\n",
    "    tmp = X_train[it, :]\n",
    "    tmp_mfcc = mfcc(tmp).tolist()\n",
    "    X_train_mfcc.append(tmp_mfcc)\n",
    "    \n",
    "X_test_mfcc = []\n",
    "for it in tqdm(range(X_test.shape[0])):\n",
    "    tmp = X_test[it, :]\n",
    "    tmp_mfcc = mfcc(tmp).tolist()\n",
    "    X_test_mfcc.append(tmp_mfcc)\n",
    "    \n",
    "X_train_mfcc = np.array(X_train_mfcc)\n",
    "X_test_mfcc = np.array(X_test_mfcc)\n",
    "\n",
    "print(X_train_mfcc.shape)\n",
    "plt.imshow(X_train_mfcc[100, :, :])\n",
    "\n",
    "from keras.models import Sequential, Input, Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.constraints import unit_norm\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "input_shape = X_train_mfcc.shape[1] * X_train_mfcc.shape[2]\n",
    "print(input_shape)\n",
    "\n",
    "X_train_mfcc_flat = np.reshape(X_train_mfcc, (-1, input_shape))\n",
    "X_test_mfcc_flat = np.reshape(X_test_mfcc, (-1, input_shape))\n",
    "\n",
    "\"\"\"onehoting network outputs\"\"\"\n",
    "from keras.utils import to_categorical\n",
    "y_train_onehot = to_categorical(y_train, 10)\n",
    "y_test_onehot = to_categorical(y_test, 10)\n",
    "\n",
    "model_dense_input = Input(shape=(input_shape,))\n",
    "model_dense = Dense(units=128, activation='relu', input_dim=input_shape,\n",
    "             kernel_constraint=unit_norm())(model_dense_input)\n",
    "model_dense = Dropout(0.5)(model_dense)\n",
    "model_dense = Dense(units=128, activation='relu')(model_dense)\n",
    "model_dense = Dense(units=64, activation='relu')(model_dense)\n",
    "model_dense = Dense(units=10, activation='softmax')(model_dense)\n",
    "model_dense = Model(inputs=model_dense_input, output=model_dense)\n",
    "\n",
    "model_dense.summary()\n",
    "\n",
    "adam = Adam(lr = 0.001)\n",
    "model_dense.compile(loss='categorical_crossentropy',\n",
    "             optimizer = adam, metrics=['accuracy'])\n",
    "\n",
    "model_dense.fit(X_train_mfcc_flat, y_train_onehot, epochs=100, steps_per_epoch=1, \n",
    "          validation_data=(X_test_mfcc_flat, y_test_onehot), validation_steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_mfcc_to_digit(data, fs, model):\n",
    "    if len(data) < fs:\n",
    "        len_to_append = fs - len(data)\n",
    "        to_append = np.zeros(len_to_append)\n",
    "        data = np.append(data, to_append)\n",
    "    else:\n",
    "        data = data[:fs]\n",
    "        \n",
    "    data_mfcc = mfcc(data, fs)\n",
    "    input_shape = data_mfcc.shape[0] * data_mfcc.shape[1]\n",
    "    data_mfcc = np.reshape(data_mfcc, (1, input_shape))\n",
    "    \n",
    "    prediction = model.predict(data_mfcc)\n",
    "    digit = np.argmax(prediction)\n",
    "    \n",
    "    return digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "fs, data = wavfile.read('ex_data.wav')\n",
    "print(predict_mfcc_to_digit(data, fs, model_dense))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dense.save('model_mfcc_dense.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
