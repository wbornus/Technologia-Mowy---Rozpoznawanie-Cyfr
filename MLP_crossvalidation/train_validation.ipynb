{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "with open('../mfcc_loader/mfcc_dict.pickle', 'rb') as handle: \n",
    "        mfcc_dict = pickle.load(handle)\n",
    "\n",
    "        \n",
    "plt.pcolormesh(mfcc_dict[0][0])\n",
    "plt.show()\n",
    "plt.pcolormesh(mfcc_dict[0][1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"data preprocessing\"\"\"\n",
    "# X = []\n",
    "# y = []\n",
    "# for it_0 in range(len(mfcc_dict)):\n",
    "#     X_column = []\n",
    "#     y_column = []\n",
    "#     for it_1 in range(len(mfcc_dict[0])):\n",
    "#         tmp = np.array(mfcc_dict[it_0][it_1])\n",
    "#         tmp.resize((50, 13))\n",
    "#         X_column.append(tmp)\n",
    "#         y_column.append(it_1)\n",
    "#     X.append(X_column)\n",
    "#     y.append(y_column)\n",
    "# X = np.array(X)\n",
    "# y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63.35909090909091\n",
      "15.033089535811843\n",
      "5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 10, 70, 13)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"data preprocessing\"\"\"\n",
    "X = []\n",
    "y = []\n",
    "to_avg = []\n",
    "for it_0 in range(len(mfcc_dict)):\n",
    "    X_column = []\n",
    "    y_column = []\n",
    "    for it_1 in range(len(mfcc_dict[0])):\n",
    "        tmp = np.array(mfcc_dict[it_0][it_1])\n",
    "        to_avg.append(tmp.shape[0])\n",
    "        if tmp.shape[0] > 70:\n",
    "            tmp = tmp[:70, :]\n",
    "        else:\n",
    "            to_append = np.zeros((70 - tmp.shape[0], 13))\n",
    "            tmp = np.concatenate((tmp, to_append), axis=0)\n",
    "        X_column.append(tmp)\n",
    "        y_column.append(it_1)\n",
    "    X.append(X_column)\n",
    "    y.append(y_column)\n",
    "    \n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "print(np.mean(to_avg))\n",
    "print(np.std(to_avg))\n",
    "print(y[10, 5])\n",
    "plt.pcolormesh(X[10, 5])\n",
    "plt.show()\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.pcolormesh(X[21, 5])\n",
    "# print(y[21][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "c:\\users\\wiktor\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\wiktor\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\wiktor\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\wiktor\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\wiktor\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\wiktor\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "c:\\users\\wiktor\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\wiktor\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\wiktor\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\wiktor\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\wiktor\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\wiktor\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1115 17:34:14.717543  4844 deprecation_wrapper.py:119] From c:\\users\\wiktor\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1115 17:34:14.744528  4844 deprecation_wrapper.py:119] From c:\\users\\wiktor\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1115 17:34:14.751524  4844 deprecation_wrapper.py:119] From c:\\users\\wiktor\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1115 17:34:14.784501  4844 deprecation_wrapper.py:119] From c:\\users\\wiktor\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W1115 17:34:14.799494  4844 deprecation.py:506] From c:\\users\\wiktor\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "c:\\users\\wiktor\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:18: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "910\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 910)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               116608    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 142,026\n",
      "Trainable params: 142,026\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1115 17:34:14.931412  4844 deprecation_wrapper.py:119] From c:\\users\\wiktor\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1115 17:34:14.948402  4844 deprecation_wrapper.py:119] From c:\\users\\wiktor\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Input, Model\n",
    "from keras.layers import Dense, Dropout, Conv2D, Flatten\n",
    "from keras.constraints import unit_norm\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "input_shape = 70*13\n",
    "print(input_shape)\n",
    "\n",
    "\"\"\"MultiLayer Perceprton implementation\"\"\"\n",
    "\n",
    "model_dense_input = Input(shape=(input_shape,))\n",
    "model_dense = Dense(units=128, activation='relu', input_dim=input_shape,\n",
    "             kernel_constraint=unit_norm())(model_dense_input)\n",
    "model_dense = Dropout(0.5)(model_dense)\n",
    "model_dense = Dense(units=128, activation='relu')(model_dense)\n",
    "model_dense = Dense(units=64, activation='relu')(model_dense)\n",
    "model_dense = Dense(units=10, activation='softmax')(model_dense)\n",
    "model_dense = Model(inputs=model_dense_input, output=model_dense)\n",
    "\n",
    "model_dense.summary()\n",
    "\n",
    "adam = Adam(lr = 0.001)\n",
    "model_dense.compile(loss='categorical_crossentropy',\n",
    "             optimizer = adam, metrics=['accuracy'])\n",
    "model_dense.save('model_dense_untrained.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\wiktor\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 70, 13, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 9, 2, 8)           208       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 144)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               14500     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 15,718\n",
      "Trainable params: 15,718\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"implementing Convolutional Neural Network\"\"\"\n",
    "\n",
    "model_conv_input = Input(shape=(X.shape[2], \n",
    "                                X.shape[3],\n",
    "                                1))\n",
    "model_conv = Conv2D(filters=8, kernel_size=(5,5), strides=(8,8),\n",
    "                    padding='same', activation='sigmoid')(model_conv_input)\n",
    "# model_conv = Conv2D(filters=16, kernel_size=(5,5), strides=(4,4),\n",
    "#                     padding='same', activation='sigmoid')(model_conv)\n",
    "model_conv = Flatten()(model_conv)\n",
    "model_conv = Dense(units=100, activation='sigmoid')(model_conv)\n",
    "# model_conv = Dense(units=128, activation='sigmoid')(model_conv)\n",
    "model_conv = Dense(units=10, activation='softmax')(model_conv)\n",
    "model_conv = Model(inputs=model_conv_input, output=model_conv)\n",
    "\n",
    "model_conv.summary()\n",
    "\n",
    "adam = Adam(lr = 0.001)\n",
    "model_conv.compile(loss='categorical_crossentropy',\n",
    "              optimizer = adam, metrics=['accuracy'])\n",
    "\n",
    "model_conv.save('model_conv_untrained.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 170 samples, validate on 50 samples\n",
      "Epoch 1/20\n",
      "100/100 [==============================] - ETA: 4:47 - loss: 2.5510 - acc: 0.100 - ETA: 46s - loss: 2.4038 - acc: 0.118 - ETA: 24s - loss: 2.3180 - acc: 0.17 - ETA: 18s - loss: 2.2806 - acc: 0.22 - ETA: 16s - loss: 2.2582 - acc: 0.26 - ETA: 11s - loss: 2.2051 - acc: 0.32 - ETA: 9s - loss: 2.1629 - acc: 0.3741 - ETA: 8s - loss: 2.1310 - acc: 0.416 - ETA: 7s - loss: 2.0989 - acc: 0.459 - ETA: 6s - loss: 2.0667 - acc: 0.495 - ETA: 5s - loss: 2.0234 - acc: 0.535 - ETA: 5s - loss: 1.9907 - acc: 0.561 - ETA: 4s - loss: 1.9467 - acc: 0.592 - ETA: 3s - loss: 1.9026 - acc: 0.618 - ETA: 3s - loss: 1.8696 - acc: 0.635 - ETA: 2s - loss: 1.8258 - acc: 0.655 - ETA: 2s - loss: 1.7824 - acc: 0.673 - ETA: 2s - loss: 1.7395 - acc: 0.689 - ETA: 1s - loss: 1.6870 - acc: 0.707 - ETA: 1s - loss: 1.6257 - acc: 0.725 - ETA: 1s - loss: 1.5764 - acc: 0.739 - ETA: 0s - loss: 1.5103 - acc: 0.756 - ETA: 0s - loss: 1.4740 - acc: 0.765 - ETA: 0s - loss: 1.4219 - acc: 0.777 - 5s 46ms/step - loss: 1.3968 - acc: 0.7832 - val_loss: 0.7868 - val_acc: 0.8400\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - ETA: 1s - loss: 0.5664 - acc: 0.964 - ETA: 1s - loss: 0.5485 - acc: 0.964 - ETA: 1s - loss: 0.5274 - acc: 0.964 - ETA: 1s - loss: 0.5154 - acc: 0.964 - ETA: 0s - loss: 0.4965 - acc: 0.966 - ETA: 0s - loss: 0.4753 - acc: 0.969 - ETA: 0s - loss: 0.4589 - acc: 0.972 - ETA: 0s - loss: 0.4464 - acc: 0.974 - ETA: 0s - loss: 0.4317 - acc: 0.975 - ETA: 0s - loss: 0.4177 - acc: 0.977 - ETA: 0s - loss: 0.4020 - acc: 0.978 - ETA: 0s - loss: 0.3921 - acc: 0.979 - ETA: 0s - loss: 0.3780 - acc: 0.980 - ETA: 0s - loss: 0.3669 - acc: 0.981 - ETA: 0s - loss: 0.3585 - acc: 0.982 - ETA: 0s - loss: 0.3483 - acc: 0.983 - ETA: 0s - loss: 0.3387 - acc: 0.983 - ETA: 0s - loss: 0.3313 - acc: 0.984 - ETA: 0s - loss: 0.3208 - acc: 0.985 - ETA: 0s - loss: 0.3141 - acc: 0.985 - ETA: 0s - loss: 0.3077 - acc: 0.986 - 1s 11ms/step - loss: 0.3014 - acc: 0.9871 - val_loss: 0.4527 - val_acc: 0.8600\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1479 - acc: 1.000 - ETA: 0s - loss: 0.1431 - acc: 1.000 - ETA: 0s - loss: 0.1400 - acc: 1.000 - ETA: 0s - loss: 0.1371 - acc: 1.000 - ETA: 0s - loss: 0.1336 - acc: 1.000 - ETA: 0s - loss: 0.1302 - acc: 1.000 - ETA: 0s - loss: 0.1270 - acc: 1.000 - ETA: 0s - loss: 0.1245 - acc: 1.000 - ETA: 0s - loss: 0.1210 - acc: 1.000 - ETA: 0s - loss: 0.1187 - acc: 1.000 - ETA: 0s - loss: 0.1160 - acc: 1.000 - ETA: 0s - loss: 0.1134 - acc: 1.000 - ETA: 0s - loss: 0.1109 - acc: 1.000 - ETA: 0s - loss: 0.1086 - acc: 1.000 - ETA: 0s - loss: 0.1063 - acc: 1.000 - ETA: 0s - loss: 0.1041 - acc: 1.000 - ETA: 0s - loss: 0.1024 - acc: 1.000 - ETA: 0s - loss: 0.1003 - acc: 1.000 - ETA: 0s - loss: 0.0980 - acc: 1.000 - ETA: 0s - loss: 0.0961 - acc: 1.000 - 1s 11ms/step - loss: 0.0939 - acc: 1.0000 - val_loss: 0.3830 - val_acc: 0.8600\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - ETA: 1s - loss: 0.0584 - acc: 1.000 - ETA: 1s - loss: 0.0573 - acc: 1.000 - ETA: 1s - loss: 0.0562 - acc: 1.000 - ETA: 0s - loss: 0.0552 - acc: 1.000 - ETA: 0s - loss: 0.0540 - acc: 1.000 - ETA: 0s - loss: 0.0531 - acc: 1.000 - ETA: 0s - loss: 0.0524 - acc: 1.000 - ETA: 0s - loss: 0.0513 - acc: 1.000 - ETA: 0s - loss: 0.0503 - acc: 1.000 - ETA: 0s - loss: 0.0496 - acc: 1.000 - ETA: 0s - loss: 0.0488 - acc: 1.000 - ETA: 0s - loss: 0.0481 - acc: 1.000 - ETA: 0s - loss: 0.0473 - acc: 1.000 - ETA: 0s - loss: 0.0466 - acc: 1.000 - ETA: 0s - loss: 0.0459 - acc: 1.000 - ETA: 0s - loss: 0.0452 - acc: 1.000 - ETA: 0s - loss: 0.0445 - acc: 1.000 - ETA: 0s - loss: 0.0440 - acc: 1.000 - ETA: 0s - loss: 0.0434 - acc: 1.000 - ETA: 0s - loss: 0.0429 - acc: 1.000 - 1s 12ms/step - loss: 0.0423 - acc: 1.0000 - val_loss: 0.3696 - val_acc: 0.8400\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - ETA: 1s - loss: 0.0305 - acc: 1.000 - ETA: 1s - loss: 0.0301 - acc: 1.000 - ETA: 1s - loss: 0.0297 - acc: 1.000 - ETA: 1s - loss: 0.0293 - acc: 1.000 - ETA: 0s - loss: 0.0289 - acc: 1.000 - ETA: 0s - loss: 0.0285 - acc: 1.000 - ETA: 0s - loss: 0.0281 - acc: 1.000 - ETA: 0s - loss: 0.0277 - acc: 1.000 - ETA: 0s - loss: 0.0274 - acc: 1.000 - ETA: 0s - loss: 0.0271 - acc: 1.000 - ETA: 0s - loss: 0.0268 - acc: 1.000 - ETA: 0s - loss: 0.0265 - acc: 1.000 - ETA: 0s - loss: 0.0261 - acc: 1.000 - ETA: 0s - loss: 0.0258 - acc: 1.000 - ETA: 0s - loss: 0.0255 - acc: 1.000 - ETA: 0s - loss: 0.0252 - acc: 1.000 - ETA: 0s - loss: 0.0250 - acc: 1.000 - ETA: 0s - loss: 0.0247 - acc: 1.000 - ETA: 0s - loss: 0.0245 - acc: 1.000 - ETA: 0s - loss: 0.0242 - acc: 1.000 - 1s 11ms/step - loss: 0.0239 - acc: 1.0000 - val_loss: 0.3651 - val_acc: 0.8400\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0187 - acc: 1.000 - ETA: 1s - loss: 0.0185 - acc: 1.000 - ETA: 0s - loss: 0.0183 - acc: 1.000 - ETA: 0s - loss: 0.0181 - acc: 1.000 - ETA: 0s - loss: 0.0179 - acc: 1.000 - ETA: 0s - loss: 0.0177 - acc: 1.000 - ETA: 0s - loss: 0.0175 - acc: 1.000 - ETA: 0s - loss: 0.0174 - acc: 1.000 - ETA: 0s - loss: 0.0172 - acc: 1.000 - ETA: 0s - loss: 0.0171 - acc: 1.000 - ETA: 0s - loss: 0.0169 - acc: 1.000 - ETA: 0s - loss: 0.0167 - acc: 1.000 - ETA: 0s - loss: 0.0166 - acc: 1.000 - ETA: 0s - loss: 0.0164 - acc: 1.000 - ETA: 0s - loss: 0.0163 - acc: 1.000 - ETA: 0s - loss: 0.0162 - acc: 1.000 - ETA: 0s - loss: 0.0160 - acc: 1.000 - ETA: 0s - loss: 0.0159 - acc: 1.000 - ETA: 0s - loss: 0.0157 - acc: 1.000 - ETA: 0s - loss: 0.0156 - acc: 1.000 - 1s 11ms/step - loss: 0.0155 - acc: 1.0000 - val_loss: 0.3643 - val_acc: 0.8400\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0128 - acc: 1.000 - ETA: 1s - loss: 0.0126 - acc: 1.000 - ETA: 1s - loss: 0.0125 - acc: 1.000 - ETA: 0s - loss: 0.0124 - acc: 1.000 - ETA: 0s - loss: 0.0123 - acc: 1.000 - ETA: 0s - loss: 0.0122 - acc: 1.000 - ETA: 0s - loss: 0.0121 - acc: 1.000 - ETA: 0s - loss: 0.0120 - acc: 1.000 - ETA: 0s - loss: 0.0119 - acc: 1.000 - ETA: 0s - loss: 0.0118 - acc: 1.000 - ETA: 0s - loss: 0.0118 - acc: 1.000 - ETA: 0s - loss: 0.0116 - acc: 1.000 - ETA: 0s - loss: 0.0116 - acc: 1.000 - ETA: 0s - loss: 0.0115 - acc: 1.000 - ETA: 0s - loss: 0.0114 - acc: 1.000 - ETA: 0s - loss: 0.0113 - acc: 1.000 - ETA: 0s - loss: 0.0112 - acc: 1.000 - ETA: 0s - loss: 0.0112 - acc: 1.000 - ETA: 0s - loss: 0.0111 - acc: 1.000 - ETA: 0s - loss: 0.0110 - acc: 1.000 - ETA: 0s - loss: 0.0109 - acc: 1.000 - 1s 12ms/step - loss: 0.0109 - acc: 1.0000 - val_loss: 0.3652 - val_acc: 0.8400\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - ETA: 1s - loss: 0.0093 - acc: 1.000 - ETA: 1s - loss: 0.0092 - acc: 1.000 - ETA: 1s - loss: 0.0092 - acc: 1.000 - ETA: 1s - loss: 0.0091 - acc: 1.000 - ETA: 1s - loss: 0.0090 - acc: 1.000 - ETA: 0s - loss: 0.0089 - acc: 1.000 - ETA: 0s - loss: 0.0089 - acc: 1.000 - ETA: 0s - loss: 0.0088 - acc: 1.000 - ETA: 0s - loss: 0.0088 - acc: 1.000 - ETA: 0s - loss: 0.0087 - acc: 1.000 - ETA: 0s - loss: 0.0087 - acc: 1.000 - ETA: 0s - loss: 0.0086 - acc: 1.000 - ETA: 0s - loss: 0.0086 - acc: 1.000 - ETA: 0s - loss: 0.0085 - acc: 1.000 - ETA: 0s - loss: 0.0085 - acc: 1.000 - ETA: 0s - loss: 0.0084 - acc: 1.000 - ETA: 0s - loss: 0.0084 - acc: 1.000 - ETA: 0s - loss: 0.0083 - acc: 1.000 - ETA: 0s - loss: 0.0082 - acc: 1.000 - ETA: 0s - loss: 0.0082 - acc: 1.000 - ETA: 0s - loss: 0.0081 - acc: 1.000 - 1s 12ms/step - loss: 0.0081 - acc: 1.0000 - val_loss: 0.3670 - val_acc: 0.8400\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0071 - acc: 1.000 - ETA: 1s - loss: 0.0070 - acc: 1.000 - ETA: 1s - loss: 0.0070 - acc: 1.000 - ETA: 1s - loss: 0.0069 - acc: 1.000 - ETA: 0s - loss: 0.0069 - acc: 1.000 - ETA: 0s - loss: 0.0069 - acc: 1.000 - ETA: 0s - loss: 0.0068 - acc: 1.000 - ETA: 0s - loss: 0.0068 - acc: 1.000 - ETA: 0s - loss: 0.0067 - acc: 1.000 - ETA: 0s - loss: 0.0067 - acc: 1.000 - ETA: 0s - loss: 0.0066 - acc: 1.000 - ETA: 0s - loss: 0.0066 - acc: 1.000 - ETA: 0s - loss: 0.0066 - acc: 1.000 - ETA: 0s - loss: 0.0065 - acc: 1.000 - ETA: 0s - loss: 0.0065 - acc: 1.000 - ETA: 0s - loss: 0.0065 - acc: 1.000 - ETA: 0s - loss: 0.0064 - acc: 1.000 - ETA: 0s - loss: 0.0064 - acc: 1.000 - ETA: 0s - loss: 0.0064 - acc: 1.000 - ETA: 0s - loss: 0.0063 - acc: 1.000 - ETA: 0s - loss: 0.0063 - acc: 1.000 - 1s 12ms/step - loss: 0.0063 - acc: 1.0000 - val_loss: 0.3694 - val_acc: 0.8400\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - ETA: 1s - loss: 0.0056 - acc: 1.000 - ETA: 1s - loss: 0.0055 - acc: 1.000 - ETA: 0s - loss: 0.0055 - acc: 1.000 - ETA: 0s - loss: 0.0055 - acc: 1.000 - ETA: 0s - loss: 0.0054 - acc: 1.000 - ETA: 0s - loss: 0.0054 - acc: 1.000 - ETA: 0s - loss: 0.0054 - acc: 1.000 - ETA: 0s - loss: 0.0053 - acc: 1.000 - ETA: 0s - loss: 0.0053 - acc: 1.000 - ETA: 0s - loss: 0.0053 - acc: 1.000 - ETA: 0s - loss: 0.0052 - acc: 1.000 - ETA: 0s - loss: 0.0052 - acc: 1.000 - ETA: 0s - loss: 0.0052 - acc: 1.000 - ETA: 0s - loss: 0.0052 - acc: 1.000 - ETA: 0s - loss: 0.0051 - acc: 1.000 - ETA: 0s - loss: 0.0051 - acc: 1.000 - ETA: 0s - loss: 0.0051 - acc: 1.000 - ETA: 0s - loss: 0.0051 - acc: 1.000 - ETA: 0s - loss: 0.0050 - acc: 1.000 - ETA: 0s - loss: 0.0050 - acc: 1.000 - 1s 11ms/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.3721 - val_acc: 0.8400\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - ETA: 1s - loss: 0.0045 - acc: 1.000 - ETA: 1s - loss: 0.0045 - acc: 1.000 - ETA: 0s - loss: 0.0044 - acc: 1.000 - ETA: 0s - loss: 0.0044 - acc: 1.000 - ETA: 0s - loss: 0.0044 - acc: 1.000 - ETA: 0s - loss: 0.0044 - acc: 1.000 - ETA: 0s - loss: 0.0044 - acc: 1.000 - ETA: 0s - loss: 0.0043 - acc: 1.000 - ETA: 0s - loss: 0.0043 - acc: 1.000 - ETA: 0s - loss: 0.0043 - acc: 1.000 - ETA: 0s - loss: 0.0043 - acc: 1.000 - ETA: 0s - loss: 0.0043 - acc: 1.000 - ETA: 0s - loss: 0.0042 - acc: 1.000 - ETA: 0s - loss: 0.0042 - acc: 1.000 - ETA: 0s - loss: 0.0042 - acc: 1.000 - ETA: 0s - loss: 0.0042 - acc: 1.000 - ETA: 0s - loss: 0.0042 - acc: 1.000 - ETA: 0s - loss: 0.0042 - acc: 1.000 - ETA: 0s - loss: 0.0042 - acc: 1.000 - ETA: 0s - loss: 0.0041 - acc: 1.000 - ETA: 0s - loss: 0.0041 - acc: 1.000 - ETA: 0s - loss: 0.0041 - acc: 1.000 - 1s 12ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.3749 - val_acc: 0.8400\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - ETA: 1s - loss: 0.0037 - acc: 1.000 - ETA: 1s - loss: 0.0037 - acc: 1.000 - ETA: 1s - loss: 0.0037 - acc: 1.000 - ETA: 0s - loss: 0.0037 - acc: 1.000 - ETA: 0s - loss: 0.0036 - acc: 1.000 - ETA: 0s - loss: 0.0036 - acc: 1.000 - ETA: 0s - loss: 0.0036 - acc: 1.000 - ETA: 0s - loss: 0.0036 - acc: 1.000 - ETA: 0s - loss: 0.0036 - acc: 1.000 - ETA: 0s - loss: 0.0036 - acc: 1.000 - ETA: 0s - loss: 0.0035 - acc: 1.000 - ETA: 0s - loss: 0.0035 - acc: 1.000 - ETA: 0s - loss: 0.0035 - acc: 1.000 - ETA: 0s - loss: 0.0035 - acc: 1.000 - ETA: 0s - loss: 0.0035 - acc: 1.000 - ETA: 0s - loss: 0.0035 - acc: 1.000 - ETA: 0s - loss: 0.0035 - acc: 1.000 - ETA: 0s - loss: 0.0034 - acc: 1.000 - ETA: 0s - loss: 0.0034 - acc: 1.000 - ETA: 0s - loss: 0.0034 - acc: 1.000 - ETA: 0s - loss: 0.0034 - acc: 1.000 - 1s 12ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.3778 - val_acc: 0.8400\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0031 - acc: 1.000 - ETA: 1s - loss: 0.0031 - acc: 1.000 - ETA: 1s - loss: 0.0031 - acc: 1.000 - ETA: 0s - loss: 0.0031 - acc: 1.000 - ETA: 0s - loss: 0.0031 - acc: 1.000 - ETA: 0s - loss: 0.0030 - acc: 1.000 - ETA: 0s - loss: 0.0030 - acc: 1.000 - ETA: 0s - loss: 0.0030 - acc: 1.000 - ETA: 0s - loss: 0.0030 - acc: 1.000 - ETA: 0s - loss: 0.0030 - acc: 1.000 - ETA: 0s - loss: 0.0030 - acc: 1.000 - ETA: 0s - loss: 0.0030 - acc: 1.000 - ETA: 0s - loss: 0.0030 - acc: 1.000 - ETA: 0s - loss: 0.0029 - acc: 1.000 - ETA: 0s - loss: 0.0029 - acc: 1.000 - ETA: 0s - loss: 0.0029 - acc: 1.000 - ETA: 0s - loss: 0.0029 - acc: 1.000 - ETA: 0s - loss: 0.0029 - acc: 1.000 - ETA: 0s - loss: 0.0029 - acc: 1.000 - 1s 11ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.3808 - val_acc: 0.8400\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0026 - acc: 1.000 - ETA: 1s - loss: 0.0026 - acc: 1.000 - ETA: 1s - loss: 0.0026 - acc: 1.000 - ETA: 0s - loss: 0.0026 - acc: 1.000 - ETA: 0s - loss: 0.0026 - acc: 1.000 - ETA: 0s - loss: 0.0026 - acc: 1.000 - ETA: 0s - loss: 0.0026 - acc: 1.000 - ETA: 0s - loss: 0.0026 - acc: 1.000 - ETA: 0s - loss: 0.0026 - acc: 1.000 - ETA: 0s - loss: 0.0026 - acc: 1.000 - ETA: 0s - loss: 0.0025 - acc: 1.000 - ETA: 0s - loss: 0.0025 - acc: 1.000 - ETA: 0s - loss: 0.0025 - acc: 1.000 - ETA: 0s - loss: 0.0025 - acc: 1.000 - ETA: 0s - loss: 0.0025 - acc: 1.000 - ETA: 0s - loss: 0.0025 - acc: 1.000 - ETA: 0s - loss: 0.0025 - acc: 1.000 - ETA: 0s - loss: 0.0025 - acc: 1.000 - ETA: 0s - loss: 0.0025 - acc: 1.000 - ETA: 0s - loss: 0.0025 - acc: 1.000 - 1s 11ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.3838 - val_acc: 0.8400\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - ETA: 1s - loss: 0.0023 - acc: 1.000 - ETA: 1s - loss: 0.0023 - acc: 1.000 - ETA: 1s - loss: 0.0023 - acc: 1.000 - ETA: 0s - loss: 0.0022 - acc: 1.000 - ETA: 0s - loss: 0.0022 - acc: 1.000 - ETA: 0s - loss: 0.0022 - acc: 1.000 - ETA: 0s - loss: 0.0022 - acc: 1.000 - ETA: 0s - loss: 0.0022 - acc: 1.000 - ETA: 0s - loss: 0.0022 - acc: 1.000 - ETA: 0s - loss: 0.0022 - acc: 1.000 - ETA: 0s - loss: 0.0022 - acc: 1.000 - ETA: 0s - loss: 0.0022 - acc: 1.000 - ETA: 0s - loss: 0.0022 - acc: 1.000 - ETA: 0s - loss: 0.0022 - acc: 1.000 - ETA: 0s - loss: 0.0022 - acc: 1.000 - ETA: 0s - loss: 0.0022 - acc: 1.000 - ETA: 0s - loss: 0.0021 - acc: 1.000 - ETA: 0s - loss: 0.0021 - acc: 1.000 - ETA: 0s - loss: 0.0021 - acc: 1.000 - ETA: 0s - loss: 0.0021 - acc: 1.000 - ETA: 0s - loss: 0.0021 - acc: 1.000 - 1s 12ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.3868 - val_acc: 0.8400\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - ETA: 1s - loss: 0.0020 - acc: 1.000 - ETA: 1s - loss: 0.0020 - acc: 1.000 - ETA: 0s - loss: 0.0020 - acc: 1.000 - ETA: 0s - loss: 0.0019 - acc: 1.000 - ETA: 0s - loss: 0.0019 - acc: 1.000 - ETA: 0s - loss: 0.0019 - acc: 1.000 - ETA: 0s - loss: 0.0019 - acc: 1.000 - ETA: 0s - loss: 0.0019 - acc: 1.000 - ETA: 0s - loss: 0.0019 - acc: 1.000 - ETA: 0s - loss: 0.0019 - acc: 1.000 - ETA: 0s - loss: 0.0019 - acc: 1.000 - ETA: 0s - loss: 0.0019 - acc: 1.000 - ETA: 0s - loss: 0.0019 - acc: 1.000 - ETA: 0s - loss: 0.0019 - acc: 1.000 - ETA: 0s - loss: 0.0019 - acc: 1.000 - ETA: 0s - loss: 0.0019 - acc: 1.000 - ETA: 0s - loss: 0.0019 - acc: 1.000 - ETA: 0s - loss: 0.0019 - acc: 1.000 - ETA: 0s - loss: 0.0019 - acc: 1.000 - ETA: 0s - loss: 0.0019 - acc: 1.000 - ETA: 0s - loss: 0.0019 - acc: 1.000 - ETA: 0s - loss: 0.0019 - acc: 1.000 - ETA: 0s - loss: 0.0018 - acc: 1.000 - ETA: 0s - loss: 0.0018 - acc: 1.000 - 1s 14ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.3898 - val_acc: 0.8400\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - ETA: 1s - loss: 0.0017 - acc: 1.000 - ETA: 1s - loss: 0.0017 - acc: 1.000 - ETA: 1s - loss: 0.0017 - acc: 1.000 - ETA: 1s - loss: 0.0017 - acc: 1.000 - ETA: 0s - loss: 0.0017 - acc: 1.000 - ETA: 0s - loss: 0.0017 - acc: 1.000 - ETA: 0s - loss: 0.0017 - acc: 1.000 - ETA: 0s - loss: 0.0017 - acc: 1.000 - ETA: 0s - loss: 0.0017 - acc: 1.000 - ETA: 0s - loss: 0.0017 - acc: 1.000 - ETA: 0s - loss: 0.0017 - acc: 1.000 - ETA: 0s - loss: 0.0017 - acc: 1.000 - ETA: 0s - loss: 0.0017 - acc: 1.000 - ETA: 0s - loss: 0.0017 - acc: 1.000 - ETA: 0s - loss: 0.0016 - acc: 1.000 - ETA: 0s - loss: 0.0016 - acc: 1.000 - ETA: 0s - loss: 0.0016 - acc: 1.000 - ETA: 0s - loss: 0.0016 - acc: 1.000 - ETA: 0s - loss: 0.0016 - acc: 1.000 - ETA: 0s - loss: 0.0016 - acc: 1.000 - ETA: 0s - loss: 0.0016 - acc: 1.000 - 1s 12ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.3926 - val_acc: 0.8400\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - ETA: 1s - loss: 0.0015 - acc: 1.000 - ETA: 1s - loss: 0.0015 - acc: 1.000 - ETA: 0s - loss: 0.0015 - acc: 1.000 - ETA: 0s - loss: 0.0015 - acc: 1.000 - ETA: 0s - loss: 0.0015 - acc: 1.000 - ETA: 0s - loss: 0.0015 - acc: 1.000 - ETA: 0s - loss: 0.0015 - acc: 1.000 - ETA: 0s - loss: 0.0015 - acc: 1.000 - ETA: 0s - loss: 0.0015 - acc: 1.000 - ETA: 0s - loss: 0.0015 - acc: 1.000 - ETA: 0s - loss: 0.0015 - acc: 1.000 - ETA: 0s - loss: 0.0015 - acc: 1.000 - ETA: 0s - loss: 0.0015 - acc: 1.000 - ETA: 0s - loss: 0.0015 - acc: 1.000 - ETA: 0s - loss: 0.0015 - acc: 1.000 - ETA: 0s - loss: 0.0014 - acc: 1.000 - ETA: 0s - loss: 0.0014 - acc: 1.000 - ETA: 0s - loss: 0.0014 - acc: 1.000 - ETA: 0s - loss: 0.0014 - acc: 1.000 - 1s 11ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.3954 - val_acc: 0.8400\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - ETA: 1s - loss: 0.0013 - acc: 1.000 - ETA: 1s - loss: 0.0013 - acc: 1.000 - ETA: 1s - loss: 0.0013 - acc: 1.000 - ETA: 0s - loss: 0.0013 - acc: 1.000 - ETA: 0s - loss: 0.0013 - acc: 1.000 - ETA: 0s - loss: 0.0013 - acc: 1.000 - ETA: 0s - loss: 0.0013 - acc: 1.000 - ETA: 0s - loss: 0.0013 - acc: 1.000 - ETA: 0s - loss: 0.0013 - acc: 1.000 - ETA: 0s - loss: 0.0013 - acc: 1.000 - ETA: 0s - loss: 0.0013 - acc: 1.000 - ETA: 0s - loss: 0.0013 - acc: 1.000 - ETA: 0s - loss: 0.0013 - acc: 1.000 - ETA: 0s - loss: 0.0013 - acc: 1.000 - ETA: 0s - loss: 0.0013 - acc: 1.000 - ETA: 0s - loss: 0.0013 - acc: 1.000 - ETA: 0s - loss: 0.0013 - acc: 1.000 - ETA: 0s - loss: 0.0013 - acc: 1.000 - ETA: 0s - loss: 0.0013 - acc: 1.000 - 1s 11ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.3981 - val_acc: 0.8400\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - ETA: 1s - loss: 0.0012 - acc: 1.000 - ETA: 0s - loss: 0.0012 - acc: 1.000 - ETA: 0s - loss: 0.0012 - acc: 1.000 - ETA: 0s - loss: 0.0012 - acc: 1.000 - ETA: 0s - loss: 0.0012 - acc: 1.000 - ETA: 0s - loss: 0.0012 - acc: 1.000 - ETA: 0s - loss: 0.0012 - acc: 1.000 - ETA: 0s - loss: 0.0012 - acc: 1.000 - ETA: 0s - loss: 0.0012 - acc: 1.000 - ETA: 0s - loss: 0.0012 - acc: 1.000 - ETA: 0s - loss: 0.0012 - acc: 1.000 - ETA: 0s - loss: 0.0012 - acc: 1.000 - ETA: 0s - loss: 0.0012 - acc: 1.000 - ETA: 0s - loss: 0.0012 - acc: 1.000 - ETA: 0s - loss: 0.0012 - acc: 1.000 - ETA: 0s - loss: 0.0011 - acc: 1.000 - ETA: 0s - loss: 0.0011 - acc: 1.000 - ETA: 0s - loss: 0.0011 - acc: 1.000 - ETA: 0s - loss: 0.0011 - acc: 1.000 - ETA: 0s - loss: 0.0011 - acc: 1.000 - 1s 11ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.4007 - val_acc: 0.8400\n",
      "50/50 [==============================] - ETA:  - 0s 637us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:30, 30.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 170 samples, validate on 50 samples\n",
      "Epoch 1/20\n",
      "100/100 [==============================] - ETA: 3:40 - loss: 0.1186 - acc: 0.952 - ETA: 30s - loss: 0.0628 - acc: 0.980 - ETA: 15s - loss: 0.0470 - acc: 0.98 - ETA: 10s - loss: 0.0365 - acc: 0.99 - ETA: 7s - loss: 0.0302 - acc: 0.9946 - ETA: 5s - loss: 0.0264 - acc: 0.995 - ETA: 5s - loss: 0.0241 - acc: 0.996 - ETA: 4s - loss: 0.0222 - acc: 0.996 - ETA: 3s - loss: 0.0199 - acc: 0.996 - ETA: 2s - loss: 0.0180 - acc: 0.997 - ETA: 2s - loss: 0.0168 - acc: 0.997 - ETA: 1s - loss: 0.0156 - acc: 0.997 - ETA: 1s - loss: 0.0147 - acc: 0.998 - ETA: 1s - loss: 0.0139 - acc: 0.998 - ETA: 0s - loss: 0.0132 - acc: 0.998 - ETA: 0s - loss: 0.0127 - acc: 0.998 - ETA: 0s - loss: 0.0123 - acc: 0.998 - ETA: 0s - loss: 0.0117 - acc: 0.998 - ETA: 0s - loss: 0.0113 - acc: 0.998 - 3s 33ms/step - loss: 0.0108 - acc: 0.9986 - val_loss: 0.0063 - val_acc: 1.0000\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - ETA: 1s - loss: 0.0031 - acc: 1.000 - ETA: 0s - loss: 0.0030 - acc: 1.000 - ETA: 0s - loss: 0.0030 - acc: 1.000 - ETA: 0s - loss: 0.0029 - acc: 1.000 - ETA: 0s - loss: 0.0029 - acc: 1.000 - ETA: 0s - loss: 0.0029 - acc: 1.000 - ETA: 0s - loss: 0.0028 - acc: 1.000 - ETA: 0s - loss: 0.0028 - acc: 1.000 - ETA: 0s - loss: 0.0028 - acc: 1.000 - ETA: 0s - loss: 0.0027 - acc: 1.000 - ETA: 0s - loss: 0.0027 - acc: 1.000 - ETA: 0s - loss: 0.0027 - acc: 1.000 - ETA: 0s - loss: 0.0027 - acc: 1.000 - ETA: 0s - loss: 0.0026 - acc: 1.000 - ETA: 0s - loss: 0.0026 - acc: 1.000 - ETA: 0s - loss: 0.0026 - acc: 1.000 - ETA: 0s - loss: 0.0026 - acc: 1.000 - ETA: 0s - loss: 0.0025 - acc: 1.000 - ETA: 0s - loss: 0.0025 - acc: 1.000 - 1s 10ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0063 - val_acc: 1.0000\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - ETA: 1s - loss: 0.0021 - acc: 1.000 - ETA: 1s - loss: 0.0021 - acc: 1.000 - ETA: 1s - loss: 0.0021 - acc: 1.000 - ETA: 0s - loss: 0.0020 - acc: 1.000 - ETA: 0s - loss: 0.0020 - acc: 1.000 - ETA: 0s - loss: 0.0020 - acc: 1.000 - ETA: 0s - loss: 0.0020 - acc: 1.000 - ETA: 0s - loss: 0.0020 - acc: 1.000 - ETA: 0s - loss: 0.0020 - acc: 1.000 - ETA: 0s - loss: 0.0020 - acc: 1.000 - ETA: 0s - loss: 0.0019 - acc: 1.000 - ETA: 0s - loss: 0.0019 - acc: 1.000 - ETA: 0s - loss: 0.0019 - acc: 1.000 - ETA: 0s - loss: 0.0019 - acc: 1.000 - ETA: 0s - loss: 0.0019 - acc: 1.000 - ETA: 0s - loss: 0.0019 - acc: 1.000 - ETA: 0s - loss: 0.0019 - acc: 1.000 - ETA: 0s - loss: 0.0018 - acc: 1.000 - ETA: 0s - loss: 0.0018 - acc: 1.000 - ETA: 0s - loss: 0.0018 - acc: 1.000 - 1s 11ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0056 - val_acc: 1.0000\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - ETA: 1s - loss: 0.0016 - acc: 1.000 - ETA: 0s - loss: 0.0016 - acc: 1.000 - ETA: 0s - loss: 0.0016 - acc: 1.000 - ETA: 0s - loss: 0.0016 - acc: 1.000 - ETA: 0s - loss: 0.0016 - acc: 1.000 - ETA: 0s - loss: 0.0015 - acc: 1.000 - ETA: 0s - loss: 0.0015 - acc: 1.000 - ETA: 0s - loss: 0.0015 - acc: 1.000 - ETA: 0s - loss: 0.0015 - acc: 1.000 - ETA: 0s - loss: 0.0015 - acc: 1.000 - ETA: 0s - loss: 0.0015 - acc: 1.000 - ETA: 0s - loss: 0.0015 - acc: 1.000 - ETA: 0s - loss: 0.0015 - acc: 1.000 - ETA: 0s - loss: 0.0015 - acc: 1.000 - ETA: 0s - loss: 0.0015 - acc: 1.000 - ETA: 0s - loss: 0.0015 - acc: 1.000 - ETA: 0s - loss: 0.0015 - acc: 1.000 - ETA: 0s - loss: 0.0015 - acc: 1.000 - ETA: 0s - loss: 0.0015 - acc: 1.000 - ETA: 0s - loss: 0.0015 - acc: 1.000 - ETA: 0s - loss: 0.0014 - acc: 1.000 - ETA: 0s - loss: 0.0014 - acc: 1.000 - ETA: 0s - loss: 0.0014 - acc: 1.000 - 1s 13ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0054 - val_acc: 1.0000\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - ETA: 1s - loss: 0.0013 - acc: 1.000 - ETA: 1s - loss: 0.0013 - acc: 1.000 - ETA: 1s - loss: 0.0013 - acc: 1.000 - ETA: 1s - loss: 0.0013 - acc: 1.000 - ETA: 1s - loss: 0.0013 - acc: 1.000 - ETA: 1s - loss: 0.0013 - acc: 1.000 - ETA: 1s - loss: 0.0013 - acc: 1.000 - ETA: 0s - loss: 0.0013 - acc: 1.000 - ETA: 0s - loss: 0.0013 - acc: 1.000 - ETA: 0s - loss: 0.0013 - acc: 1.000 - ETA: 0s - loss: 0.0012 - acc: 1.000 - ETA: 0s - loss: 0.0012 - acc: 1.000 - ETA: 0s - loss: 0.0012 - acc: 1.000 - ETA: 0s - loss: 0.0012 - acc: 1.000 - ETA: 0s - loss: 0.0012 - acc: 1.000 - ETA: 0s - loss: 0.0012 - acc: 1.000 - ETA: 0s - loss: 0.0012 - acc: 1.000 - ETA: 0s - loss: 0.0012 - acc: 1.000 - ETA: 0s - loss: 0.0012 - acc: 1.000 - ETA: 0s - loss: 0.0012 - acc: 1.000 - ETA: 0s - loss: 0.0012 - acc: 1.000 - ETA: 0s - loss: 0.0012 - acc: 1.000 - ETA: 0s - loss: 0.0012 - acc: 1.000 - ETA: 0s - loss: 0.0012 - acc: 1.000 - 1s 13ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0052 - val_acc: 1.0000\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - ETA: 1s - loss: 0.0011 - acc: 1.000 - ETA: 1s - loss: 0.0011 - acc: 1.000 - ETA: 1s - loss: 0.0011 - acc: 1.000 - ETA: 1s - loss: 0.0011 - acc: 1.000 - ETA: 1s - loss: 0.0011 - acc: 1.000 - ETA: 0s - loss: 0.0011 - acc: 1.000 - ETA: 0s - loss: 0.0011 - acc: 1.000 - ETA: 0s - loss: 0.0011 - acc: 1.000 - ETA: 0s - loss: 0.0011 - acc: 1.000 - ETA: 0s - loss: 0.0011 - acc: 1.000 - ETA: 0s - loss: 0.0010 - acc: 1.000 - ETA: 0s - loss: 0.0010 - acc: 1.000 - ETA: 0s - loss: 0.0010 - acc: 1.000 - ETA: 0s - loss: 0.0010 - acc: 1.000 - ETA: 0s - loss: 0.0010 - acc: 1.000 - ETA: 0s - loss: 0.0010 - acc: 1.000 - ETA: 0s - loss: 0.0010 - acc: 1.000 - ETA: 0s - loss: 0.0010 - acc: 1.000 - ETA: 0s - loss: 0.0010 - acc: 1.000 - ETA: 0s - loss: 0.0010 - acc: 1.000 - ETA: 0s - loss: 0.0010 - acc: 1.000 - 1s 12ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0051 - val_acc: 1.0000\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - ETA: 0s - loss: 9.3048e-04 - acc: 1.000 - ETA: 0s - loss: 9.2634e-04 - acc: 1.000 - ETA: 0s - loss: 9.2361e-04 - acc: 1.000 - ETA: 0s - loss: 9.2089e-04 - acc: 1.000 - ETA: 0s - loss: 9.1819e-04 - acc: 1.000 - ETA: 0s - loss: 9.1484e-04 - acc: 1.000 - ETA: 0s - loss: 9.1152e-04 - acc: 1.000 - ETA: 0s - loss: 9.0888e-04 - acc: 1.000 - ETA: 0s - loss: 9.0496e-04 - acc: 1.000 - ETA: 0s - loss: 9.0237e-04 - acc: 1.000 - ETA: 0s - loss: 8.9916e-04 - acc: 1.000 - ETA: 0s - loss: 8.9533e-04 - acc: 1.000 - ETA: 0s - loss: 8.9281e-04 - acc: 1.000 - ETA: 0s - loss: 8.8905e-04 - acc: 1.000 - ETA: 0s - loss: 8.8656e-04 - acc: 1.000 - ETA: 0s - loss: 8.8287e-04 - acc: 1.000 - ETA: 0s - loss: 8.7981e-04 - acc: 1.000 - ETA: 0s - loss: 8.7618e-04 - acc: 1.000 - ETA: 0s - loss: 8.7378e-04 - acc: 1.000 - ETA: 0s - loss: 8.7080e-04 - acc: 1.000 - 1s 11ms/step - loss: 8.6725e-04 - acc: 1.0000 - val_loss: 0.0050 - val_acc: 1.0000\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - ETA: 0s - loss: 8.0791e-04 - acc: 1.000 - ETA: 0s - loss: 8.0521e-04 - acc: 1.000 - ETA: 0s - loss: 8.0253e-04 - acc: 1.000 - ETA: 0s - loss: 8.0041e-04 - acc: 1.000 - ETA: 0s - loss: 7.9830e-04 - acc: 1.000 - ETA: 0s - loss: 7.9567e-04 - acc: 1.000 - ETA: 0s - loss: 7.9307e-04 - acc: 1.000 - ETA: 0s - loss: 7.9049e-04 - acc: 1.000 - ETA: 0s - loss: 7.8741e-04 - acc: 1.000 - ETA: 0s - loss: 7.8538e-04 - acc: 1.000 - ETA: 0s - loss: 7.8285e-04 - acc: 1.000 - ETA: 0s - loss: 7.8034e-04 - acc: 1.000 - ETA: 0s - loss: 7.7785e-04 - acc: 1.000 - ETA: 0s - loss: 7.7488e-04 - acc: 1.000 - ETA: 0s - loss: 7.7242e-04 - acc: 1.000 - ETA: 0s - loss: 7.6999e-04 - acc: 1.000 - ETA: 0s - loss: 7.6757e-04 - acc: 1.000 - ETA: 0s - loss: 7.6469e-04 - acc: 1.000 - ETA: 0s - loss: 7.6230e-04 - acc: 1.000 - ETA: 0s - loss: 7.5994e-04 - acc: 1.000 - 1s 11ms/step - loss: 7.5805e-04 - acc: 1.0000 - val_loss: 0.0049 - val_acc: 1.0000\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - ETA: 0s - loss: 7.1070e-04 - acc: 1.000 - ETA: 1s - loss: 7.0852e-04 - acc: 1.000 - ETA: 1s - loss: 7.0636e-04 - acc: 1.000 - ETA: 0s - loss: 7.0378e-04 - acc: 1.000 - ETA: 0s - loss: 7.0207e-04 - acc: 1.000 - ETA: 0s - loss: 6.9995e-04 - acc: 1.000 - ETA: 0s - loss: 6.9743e-04 - acc: 1.000 - ETA: 0s - loss: 6.9575e-04 - acc: 1.000 - ETA: 0s - loss: 6.9326e-04 - acc: 1.000 - ETA: 0s - loss: 6.9161e-04 - acc: 1.000 - ETA: 0s - loss: 6.8955e-04 - acc: 1.000 - ETA: 0s - loss: 6.8751e-04 - acc: 1.000 - ETA: 0s - loss: 6.8589e-04 - acc: 1.000 - ETA: 0s - loss: 6.8427e-04 - acc: 1.000 - ETA: 0s - loss: 6.8226e-04 - acc: 1.000 - ETA: 0s - loss: 6.8067e-04 - acc: 1.000 - ETA: 0s - loss: 6.7868e-04 - acc: 1.000 - ETA: 0s - loss: 6.7632e-04 - acc: 1.000 - ETA: 0s - loss: 6.7436e-04 - acc: 1.000 - ETA: 0s - loss: 6.7202e-04 - acc: 1.000 - 1s 11ms/step - loss: 6.7009e-04 - acc: 1.0000 - val_loss: 0.0048 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - ETA: 1s - loss: 6.3120e-04 - acc: 1.000 - ETA: 1s - loss: 6.2904e-04 - acc: 1.000 - ETA: 0s - loss: 6.2725e-04 - acc: 1.000 - ETA: 1s - loss: 6.2582e-04 - acc: 1.000 - ETA: 0s - loss: 6.2370e-04 - acc: 1.000 - ETA: 0s - loss: 6.2194e-04 - acc: 1.000 - ETA: 0s - loss: 6.2019e-04 - acc: 1.000 - ETA: 0s - loss: 6.1811e-04 - acc: 1.000 - ETA: 0s - loss: 6.1604e-04 - acc: 1.000 - ETA: 0s - loss: 6.1398e-04 - acc: 1.000 - ETA: 0s - loss: 6.1262e-04 - acc: 1.000 - ETA: 0s - loss: 6.1093e-04 - acc: 1.000 - ETA: 0s - loss: 6.0924e-04 - acc: 1.000 - ETA: 0s - loss: 6.0757e-04 - acc: 1.000 - ETA: 0s - loss: 6.0557e-04 - acc: 1.000 - ETA: 0s - loss: 6.0359e-04 - acc: 1.000 - ETA: 0s - loss: 6.0162e-04 - acc: 1.000 - ETA: 0s - loss: 5.9998e-04 - acc: 1.000 - ETA: 0s - loss: 5.9804e-04 - acc: 1.000 - 1s 11ms/step - loss: 5.9739e-04 - acc: 1.0000 - val_loss: 0.0047 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - ETA: 0s - loss: 5.6482e-04 - acc: 1.000 - ETA: 1s - loss: 5.6361e-04 - acc: 1.000 - ETA: 0s - loss: 5.6179e-04 - acc: 1.000 - ETA: 0s - loss: 5.6029e-04 - acc: 1.000 - ETA: 0s - loss: 5.5850e-04 - acc: 1.000 - ETA: 0s - loss: 5.5702e-04 - acc: 1.000 - ETA: 0s - loss: 5.5525e-04 - acc: 1.000 - ETA: 0s - loss: 5.5378e-04 - acc: 1.000 - ETA: 0s - loss: 5.5203e-04 - acc: 1.000 - ETA: 0s - loss: 5.5000e-04 - acc: 1.000 - ETA: 0s - loss: 5.4799e-04 - acc: 1.000 - ETA: 0s - loss: 5.4628e-04 - acc: 1.000 - ETA: 0s - loss: 5.4514e-04 - acc: 1.000 - ETA: 0s - loss: 5.4345e-04 - acc: 1.000 - ETA: 0s - loss: 5.4204e-04 - acc: 1.000 - ETA: 0s - loss: 5.4065e-04 - acc: 1.000 - ETA: 0s - loss: 5.3898e-04 - acc: 1.000 - ETA: 0s - loss: 5.3760e-04 - acc: 1.000 - 1s 10ms/step - loss: 5.3622e-04 - acc: 1.0000 - val_loss: 0.0046 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - ETA: 0s - loss: 5.0854e-04 - acc: 1.000 - ETA: 1s - loss: 5.0750e-04 - acc: 1.000 - ETA: 1s - loss: 5.0647e-04 - acc: 1.000 - ETA: 0s - loss: 5.0467e-04 - acc: 1.000 - ETA: 0s - loss: 5.0365e-04 - acc: 1.000 - ETA: 0s - loss: 5.0213e-04 - acc: 1.000 - ETA: 0s - loss: 5.0061e-04 - acc: 1.000 - ETA: 0s - loss: 4.9910e-04 - acc: 1.000 - ETA: 0s - loss: 4.9786e-04 - acc: 1.000 - ETA: 0s - loss: 4.9636e-04 - acc: 1.000 - ETA: 0s - loss: 4.9513e-04 - acc: 1.000 - ETA: 0s - loss: 4.9365e-04 - acc: 1.000 - ETA: 0s - loss: 4.9195e-04 - acc: 1.000 - ETA: 0s - loss: 4.9097e-04 - acc: 1.000 - ETA: 0s - loss: 4.8977e-04 - acc: 1.000 - ETA: 0s - loss: 4.8856e-04 - acc: 1.000 - ETA: 0s - loss: 4.8736e-04 - acc: 1.000 - ETA: 0s - loss: 4.8617e-04 - acc: 1.000 - ETA: 0s - loss: 4.8499e-04 - acc: 1.000 - 1s 11ms/step - loss: 4.8404e-04 - acc: 1.0000 - val_loss: 0.0045 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - ETA: 1s - loss: 4.6025e-04 - acc: 1.000 - ETA: 0s - loss: 4.5890e-04 - acc: 1.000 - ETA: 0s - loss: 4.5757e-04 - acc: 1.000 - ETA: 0s - loss: 4.5624e-04 - acc: 1.000 - ETA: 0s - loss: 4.5558e-04 - acc: 1.000 - ETA: 0s - loss: 4.5448e-04 - acc: 1.000 - ETA: 0s - loss: 4.5339e-04 - acc: 1.000 - ETA: 0s - loss: 4.5252e-04 - acc: 1.000 - ETA: 0s - loss: 4.5144e-04 - acc: 1.000 - ETA: 0s - loss: 4.5058e-04 - acc: 1.000 - ETA: 0s - loss: 4.4929e-04 - acc: 1.000 - ETA: 0s - loss: 4.4822e-04 - acc: 1.000 - ETA: 0s - loss: 4.4716e-04 - acc: 1.000 - ETA: 0s - loss: 4.4589e-04 - acc: 1.000 - ETA: 0s - loss: 4.4484e-04 - acc: 1.000 - ETA: 0s - loss: 4.4358e-04 - acc: 1.000 - ETA: 0s - loss: 4.4275e-04 - acc: 1.000 - ETA: 0s - loss: 4.4171e-04 - acc: 1.000 - ETA: 0s - loss: 4.4068e-04 - acc: 1.000 - ETA: 0s - loss: 4.3965e-04 - acc: 1.000 - 1s 11ms/step - loss: 4.3903e-04 - acc: 1.0000 - val_loss: 0.0044 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - ETA: 1s - loss: 4.1838e-04 - acc: 1.000 - ETA: 1s - loss: 4.1740e-04 - acc: 1.000 - ETA: 0s - loss: 4.1643e-04 - acc: 1.000 - ETA: 0s - loss: 4.1527e-04 - acc: 1.000 - ETA: 0s - loss: 4.1431e-04 - acc: 1.000 - ETA: 0s - loss: 4.1335e-04 - acc: 1.000 - ETA: 0s - loss: 4.1240e-04 - acc: 1.000 - ETA: 0s - loss: 4.1145e-04 - acc: 1.000 - ETA: 0s - loss: 4.1050e-04 - acc: 1.000 - ETA: 0s - loss: 4.0994e-04 - acc: 1.000 - ETA: 0s - loss: 4.0882e-04 - acc: 1.000 - ETA: 0s - loss: 4.0770e-04 - acc: 1.000 - ETA: 0s - loss: 4.0677e-04 - acc: 1.000 - ETA: 0s - loss: 4.0585e-04 - acc: 1.000 - ETA: 0s - loss: 4.0493e-04 - acc: 1.000 - ETA: 0s - loss: 4.0401e-04 - acc: 1.000 - ETA: 0s - loss: 4.0310e-04 - acc: 1.000 - ETA: 0s - loss: 4.0201e-04 - acc: 1.000 - ETA: 0s - loss: 4.0093e-04 - acc: 1.000 - ETA: 0s - loss: 4.0003e-04 - acc: 1.000 - 1s 11ms/step - loss: 3.9985e-04 - acc: 1.0000 - val_loss: 0.0043 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.8175e-04 - acc: 1.000 - ETA: 0s - loss: 3.8090e-04 - acc: 1.000 - ETA: 0s - loss: 3.8005e-04 - acc: 1.000 - ETA: 0s - loss: 3.7903e-04 - acc: 1.000 - ETA: 0s - loss: 3.7802e-04 - acc: 1.000 - ETA: 0s - loss: 3.7734e-04 - acc: 1.000 - ETA: 0s - loss: 3.7634e-04 - acc: 1.000 - ETA: 0s - loss: 3.7551e-04 - acc: 1.000 - ETA: 0s - loss: 3.7484e-04 - acc: 1.000 - ETA: 0s - loss: 3.7385e-04 - acc: 1.000 - ETA: 0s - loss: 3.7319e-04 - acc: 1.000 - ETA: 0s - loss: 3.7237e-04 - acc: 1.000 - ETA: 0s - loss: 3.7156e-04 - acc: 1.000 - ETA: 0s - loss: 3.7058e-04 - acc: 1.000 - ETA: 0s - loss: 3.6977e-04 - acc: 1.000 - ETA: 0s - loss: 3.6896e-04 - acc: 1.000 - ETA: 0s - loss: 3.6816e-04 - acc: 1.000 - ETA: 0s - loss: 3.6752e-04 - acc: 1.000 - ETA: 0s - loss: 3.6657e-04 - acc: 1.000 - ETA: 0s - loss: 3.6577e-04 - acc: 1.000 - 1s 11ms/step - loss: 3.6546e-04 - acc: 1.0000 - val_loss: 0.0043 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - ETA: 1s - loss: 3.4950e-04 - acc: 1.000 - ETA: 0s - loss: 3.4859e-04 - acc: 1.000 - ETA: 1s - loss: 3.4799e-04 - acc: 1.000 - ETA: 1s - loss: 3.4769e-04 - acc: 1.000 - ETA: 1s - loss: 3.4724e-04 - acc: 1.000 - ETA: 1s - loss: 3.4679e-04 - acc: 1.000 - ETA: 1s - loss: 3.4635e-04 - acc: 1.000 - ETA: 1s - loss: 3.4560e-04 - acc: 1.000 - ETA: 1s - loss: 3.4486e-04 - acc: 1.000 - ETA: 0s - loss: 3.4442e-04 - acc: 1.000 - ETA: 0s - loss: 3.4383e-04 - acc: 1.000 - ETA: 0s - loss: 3.4295e-04 - acc: 1.000 - ETA: 0s - loss: 3.4207e-04 - acc: 1.000 - ETA: 0s - loss: 3.4135e-04 - acc: 1.000 - ETA: 0s - loss: 3.4062e-04 - acc: 1.000 - ETA: 0s - loss: 3.3976e-04 - acc: 1.000 - ETA: 0s - loss: 3.3904e-04 - acc: 1.000 - ETA: 0s - loss: 3.3847e-04 - acc: 1.000 - ETA: 0s - loss: 3.3761e-04 - acc: 1.000 - ETA: 0s - loss: 3.3690e-04 - acc: 1.000 - ETA: 0s - loss: 3.3620e-04 - acc: 1.000 - ETA: 0s - loss: 3.3549e-04 - acc: 1.000 - 1s 12ms/step - loss: 3.3507e-04 - acc: 1.0000 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - ETA: 0s - loss: 3.2092e-04 - acc: 1.000 - ETA: 1s - loss: 3.2025e-04 - acc: 1.000 - ETA: 1s - loss: 3.1971e-04 - acc: 1.000 - ETA: 1s - loss: 3.1917e-04 - acc: 1.000 - ETA: 0s - loss: 3.1838e-04 - acc: 1.000 - ETA: 0s - loss: 3.1758e-04 - acc: 1.000 - ETA: 0s - loss: 3.1705e-04 - acc: 1.000 - ETA: 0s - loss: 3.1639e-04 - acc: 1.000 - ETA: 0s - loss: 3.1574e-04 - acc: 1.000 - ETA: 0s - loss: 3.1509e-04 - acc: 1.000 - ETA: 0s - loss: 3.1444e-04 - acc: 1.000 - ETA: 0s - loss: 3.1392e-04 - acc: 1.000 - ETA: 0s - loss: 3.1314e-04 - acc: 1.000 - ETA: 0s - loss: 3.1263e-04 - acc: 1.000 - ETA: 0s - loss: 3.1173e-04 - acc: 1.000 - ETA: 0s - loss: 3.1109e-04 - acc: 1.000 - ETA: 0s - loss: 3.1046e-04 - acc: 1.000 - ETA: 0s - loss: 3.0957e-04 - acc: 1.000 - ETA: 0s - loss: 3.0919e-04 - acc: 1.000 - ETA: 0s - loss: 3.0844e-04 - acc: 1.000 - 1s 11ms/step - loss: 3.0806e-04 - acc: 1.0000 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.9543e-04 - acc: 1.000 - ETA: 1s - loss: 2.9495e-04 - acc: 1.000 - ETA: 0s - loss: 2.9435e-04 - acc: 1.000 - ETA: 0s - loss: 2.9375e-04 - acc: 1.000 - ETA: 0s - loss: 2.9316e-04 - acc: 1.000 - ETA: 0s - loss: 2.9256e-04 - acc: 1.000 - ETA: 0s - loss: 2.9186e-04 - acc: 1.000 - ETA: 0s - loss: 2.9115e-04 - acc: 1.000 - ETA: 0s - loss: 2.9056e-04 - acc: 1.000 - ETA: 0s - loss: 2.8987e-04 - acc: 1.000 - ETA: 0s - loss: 2.8917e-04 - acc: 1.000 - ETA: 0s - loss: 2.8836e-04 - acc: 1.000 - ETA: 0s - loss: 2.8778e-04 - acc: 1.000 - ETA: 0s - loss: 2.8710e-04 - acc: 1.000 - ETA: 0s - loss: 2.8641e-04 - acc: 1.000 - ETA: 0s - loss: 2.8584e-04 - acc: 1.000 - ETA: 0s - loss: 2.8539e-04 - acc: 1.000 - ETA: 0s - loss: 2.8494e-04 - acc: 1.000 - ETA: 0s - loss: 2.8426e-04 - acc: 1.000 - 1s 11ms/step - loss: 2.8392e-04 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - ETA: 1s - loss: 2.7260e-04 - acc: 1.000 - ETA: 1s - loss: 2.7206e-04 - acc: 1.000 - ETA: 0s - loss: 2.7141e-04 - acc: 1.000 - ETA: 0s - loss: 2.7088e-04 - acc: 1.000 - ETA: 0s - loss: 2.7024e-04 - acc: 1.000 - ETA: 0s - loss: 2.6960e-04 - acc: 1.000 - ETA: 0s - loss: 2.6897e-04 - acc: 1.000 - ETA: 0s - loss: 2.6844e-04 - acc: 1.000 - ETA: 0s - loss: 2.6802e-04 - acc: 1.000 - ETA: 0s - loss: 2.6750e-04 - acc: 1.000 - ETA: 0s - loss: 2.6697e-04 - acc: 1.000 - ETA: 0s - loss: 2.6656e-04 - acc: 1.000 - ETA: 0s - loss: 2.6604e-04 - acc: 1.000 - ETA: 0s - loss: 2.6542e-04 - acc: 1.000 - ETA: 0s - loss: 2.6480e-04 - acc: 1.000 - ETA: 0s - loss: 2.6418e-04 - acc: 1.000 - ETA: 0s - loss: 2.6357e-04 - acc: 1.000 - ETA: 0s - loss: 2.6317e-04 - acc: 1.000 - ETA: 0s - loss: 2.6276e-04 - acc: 1.000 - ETA: 0s - loss: 2.6235e-04 - acc: 1.000 - 1s 11ms/step - loss: 2.6225e-04 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.5206e-04 - acc: 1.000 - ETA: 1s - loss: 2.5157e-04 - acc: 1.000 - ETA: 0s - loss: 2.5109e-04 - acc: 1.000 - ETA: 0s - loss: 2.5070e-04 - acc: 1.000 - ETA: 0s - loss: 2.5022e-04 - acc: 1.000 - ETA: 0s - loss: 2.4974e-04 - acc: 1.000 - ETA: 0s - loss: 2.4935e-04 - acc: 1.000 - ETA: 0s - loss: 2.4887e-04 - acc: 1.000 - ETA: 0s - loss: 2.4830e-04 - acc: 1.000 - ETA: 0s - loss: 2.4783e-04 - acc: 1.000 - ETA: 0s - loss: 2.4736e-04 - acc: 1.000 - ETA: 0s - loss: 2.4679e-04 - acc: 1.000 - ETA: 0s - loss: 2.4642e-04 - acc: 1.000 - ETA: 0s - loss: 2.4586e-04 - acc: 1.000 - ETA: 0s - loss: 2.4539e-04 - acc: 1.000 - ETA: 0s - loss: 2.4483e-04 - acc: 1.000 - ETA: 0s - loss: 2.4428e-04 - acc: 1.000 - ETA: 0s - loss: 2.4391e-04 - acc: 1.000 - ETA: 0s - loss: 2.4345e-04 - acc: 1.000 - ETA: 0s - loss: 2.4299e-04 - acc: 1.000 - 1s 11ms/step - loss: 2.4272e-04 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "50/50 [==============================] - ETA:  - 0s 397us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2it [00:57, 29.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 180 samples, validate on 40 samples\n",
      "Epoch 1/20\n",
      "100/100 [==============================] - ETA: 3:18 - loss: 0.0013 - acc: 1.000 - ETA: 32s - loss: 9.9171e-04 - acc: 1.00 - ETA: 15s - loss: 7.7399e-04 - acc: 1.00 - ETA: 11s - loss: 7.0504e-04 - acc: 1.00 - ETA: 7s - loss: 6.4819e-04 - acc: 1.0000 - ETA: 6s - loss: 6.1762e-04 - acc: 1.000 - ETA: 5s - loss: 5.9739e-04 - acc: 1.000 - ETA: 4s - loss: 5.7524e-04 - acc: 1.000 - ETA: 3s - loss: 5.5598e-04 - acc: 1.000 - ETA: 3s - loss: 5.4250e-04 - acc: 1.000 - ETA: 2s - loss: 5.3341e-04 - acc: 1.000 - ETA: 2s - loss: 5.2250e-04 - acc: 1.000 - ETA: 2s - loss: 5.1276e-04 - acc: 1.000 - ETA: 1s - loss: 5.0401e-04 - acc: 1.000 - ETA: 1s - loss: 4.9608e-04 - acc: 1.000 - ETA: 1s - loss: 4.8710e-04 - acc: 1.000 - ETA: 1s - loss: 4.8056e-04 - acc: 1.000 - ETA: 0s - loss: 4.7450e-04 - acc: 1.000 - ETA: 0s - loss: 4.6887e-04 - acc: 1.000 - ETA: 0s - loss: 4.6361e-04 - acc: 1.000 - ETA: 0s - loss: 4.5867e-04 - acc: 1.000 - ETA: 0s - loss: 4.5516e-04 - acc: 1.000 - ETA: 0s - loss: 4.5071e-04 - acc: 1.000 - 3s 33ms/step - loss: 4.4651e-04 - acc: 1.0000 - val_loss: 1.8819e-04 - val_acc: 1.0000\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - ETA: 1s - loss: 3.4371e-04 - acc: 1.000 - ETA: 1s - loss: 3.4231e-04 - acc: 1.000 - ETA: 1s - loss: 3.4094e-04 - acc: 1.000 - ETA: 1s - loss: 3.3959e-04 - acc: 1.000 - ETA: 1s - loss: 3.3860e-04 - acc: 1.000 - ETA: 1s - loss: 3.3729e-04 - acc: 1.000 - ETA: 1s - loss: 3.3632e-04 - acc: 1.000 - ETA: 1s - loss: 3.3537e-04 - acc: 1.000 - ETA: 1s - loss: 3.3411e-04 - acc: 1.000 - ETA: 1s - loss: 3.3319e-04 - acc: 1.000 - ETA: 0s - loss: 3.3197e-04 - acc: 1.000 - ETA: 0s - loss: 3.3047e-04 - acc: 1.000 - ETA: 0s - loss: 3.2958e-04 - acc: 1.000 - ETA: 0s - loss: 3.2842e-04 - acc: 1.000 - ETA: 0s - loss: 3.2727e-04 - acc: 1.000 - ETA: 0s - loss: 3.2613e-04 - acc: 1.000 - ETA: 0s - loss: 3.2501e-04 - acc: 1.000 - ETA: 0s - loss: 3.2364e-04 - acc: 1.000 - ETA: 0s - loss: 3.2201e-04 - acc: 1.000 - ETA: 0s - loss: 3.2095e-04 - acc: 1.000 - ETA: 0s - loss: 3.1937e-04 - acc: 1.000 - ETA: 0s - loss: 3.1809e-04 - acc: 1.000 - ETA: 0s - loss: 3.1682e-04 - acc: 1.000 - ETA: 0s - loss: 3.1556e-04 - acc: 1.000 - 1s 14ms/step - loss: 3.1482e-04 - acc: 1.0000 - val_loss: 1.8450e-04 - val_acc: 1.0000\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - ETA: 1s - loss: 2.8997e-04 - acc: 1.000 - ETA: 1s - loss: 2.8871e-04 - acc: 1.000 - ETA: 0s - loss: 2.8768e-04 - acc: 1.000 - ETA: 0s - loss: 2.8686e-04 - acc: 1.000 - ETA: 0s - loss: 2.8605e-04 - acc: 1.000 - ETA: 0s - loss: 2.8504e-04 - acc: 1.000 - ETA: 0s - loss: 2.8425e-04 - acc: 1.000 - ETA: 0s - loss: 2.8327e-04 - acc: 1.000 - ETA: 0s - loss: 2.8230e-04 - acc: 1.000 - ETA: 0s - loss: 2.8134e-04 - acc: 1.000 - ETA: 0s - loss: 2.8039e-04 - acc: 1.000 - ETA: 0s - loss: 2.7945e-04 - acc: 1.000 - ETA: 0s - loss: 2.7870e-04 - acc: 1.000 - ETA: 0s - loss: 2.7796e-04 - acc: 1.000 - ETA: 0s - loss: 2.7723e-04 - acc: 1.000 - ETA: 0s - loss: 2.7632e-04 - acc: 1.000 - ETA: 0s - loss: 2.7543e-04 - acc: 1.000 - ETA: 0s - loss: 2.7454e-04 - acc: 1.000 - ETA: 0s - loss: 2.7383e-04 - acc: 1.000 - ETA: 0s - loss: 2.7296e-04 - acc: 1.000 - ETA: 0s - loss: 2.7226e-04 - acc: 1.000 - ETA: 0s - loss: 2.7158e-04 - acc: 1.000 - 1s 12ms/step - loss: 2.7123e-04 - acc: 1.0000 - val_loss: 1.8075e-04 - val_acc: 1.0000\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - ETA: 2s - loss: 2.5401e-04 - acc: 1.000 - ETA: 1s - loss: 2.5324e-04 - acc: 1.000 - ETA: 1s - loss: 2.5263e-04 - acc: 1.000 - ETA: 1s - loss: 2.5202e-04 - acc: 1.000 - ETA: 1s - loss: 2.5127e-04 - acc: 1.000 - ETA: 0s - loss: 2.5053e-04 - acc: 1.000 - ETA: 0s - loss: 2.4979e-04 - acc: 1.000 - ETA: 0s - loss: 2.4920e-04 - acc: 1.000 - ETA: 0s - loss: 2.4847e-04 - acc: 1.000 - ETA: 0s - loss: 2.4775e-04 - acc: 1.000 - ETA: 0s - loss: 2.4689e-04 - acc: 1.000 - ETA: 0s - loss: 2.4632e-04 - acc: 1.000 - ETA: 0s - loss: 2.4576e-04 - acc: 1.000 - ETA: 0s - loss: 2.4519e-04 - acc: 1.000 - ETA: 0s - loss: 2.4450e-04 - acc: 1.000 - ETA: 0s - loss: 2.4381e-04 - acc: 1.000 - ETA: 0s - loss: 2.4326e-04 - acc: 1.000 - ETA: 0s - loss: 2.4257e-04 - acc: 1.000 - ETA: 0s - loss: 2.4176e-04 - acc: 1.000 - ETA: 0s - loss: 2.4109e-04 - acc: 1.000 - ETA: 0s - loss: 2.4043e-04 - acc: 1.000 - 1s 12ms/step - loss: 2.3990e-04 - acc: 1.0000 - val_loss: 1.7692e-04 - val_acc: 1.0000\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - ETA: 1s - loss: 2.2660e-04 - acc: 1.000 - ETA: 1s - loss: 2.2598e-04 - acc: 1.000 - ETA: 1s - loss: 2.2538e-04 - acc: 1.000 - ETA: 0s - loss: 2.2478e-04 - acc: 1.000 - ETA: 0s - loss: 2.2419e-04 - acc: 1.000 - ETA: 0s - loss: 2.2359e-04 - acc: 1.000 - ETA: 0s - loss: 2.2312e-04 - acc: 1.000 - ETA: 0s - loss: 2.2242e-04 - acc: 1.000 - ETA: 0s - loss: 2.2196e-04 - acc: 1.000 - ETA: 0s - loss: 2.2127e-04 - acc: 1.000 - ETA: 0s - loss: 2.2081e-04 - acc: 1.000 - ETA: 0s - loss: 2.2024e-04 - acc: 1.000 - ETA: 0s - loss: 2.1979e-04 - acc: 1.000 - ETA: 0s - loss: 2.1923e-04 - acc: 1.000 - ETA: 0s - loss: 2.1878e-04 - acc: 1.000 - ETA: 0s - loss: 2.1812e-04 - acc: 1.000 - ETA: 0s - loss: 2.1768e-04 - acc: 1.000 - ETA: 0s - loss: 2.1713e-04 - acc: 1.000 - ETA: 0s - loss: 2.1669e-04 - acc: 1.000 - ETA: 0s - loss: 2.1604e-04 - acc: 1.000 - ETA: 0s - loss: 2.1550e-04 - acc: 1.000 - 1s 12ms/step - loss: 2.1529e-04 - acc: 1.0000 - val_loss: 1.7303e-04 - val_acc: 1.0000\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - ETA: 1s - loss: 2.0449e-04 - acc: 1.000 - ETA: 1s - loss: 2.0409e-04 - acc: 1.000 - ETA: 1s - loss: 2.0359e-04 - acc: 1.000 - ETA: 1s - loss: 2.0319e-04 - acc: 1.000 - ETA: 1s - loss: 2.0280e-04 - acc: 1.000 - ETA: 0s - loss: 2.0231e-04 - acc: 1.000 - ETA: 0s - loss: 2.0192e-04 - acc: 1.000 - ETA: 0s - loss: 2.0144e-04 - acc: 1.000 - ETA: 0s - loss: 2.0095e-04 - acc: 1.000 - ETA: 0s - loss: 2.0057e-04 - acc: 1.000 - ETA: 0s - loss: 2.0000e-04 - acc: 1.000 - ETA: 0s - loss: 1.9952e-04 - acc: 1.000 - ETA: 0s - loss: 1.9905e-04 - acc: 1.000 - ETA: 0s - loss: 1.9868e-04 - acc: 1.000 - ETA: 0s - loss: 1.9821e-04 - acc: 1.000 - ETA: 0s - loss: 1.9775e-04 - acc: 1.000 - ETA: 0s - loss: 1.9729e-04 - acc: 1.000 - ETA: 0s - loss: 1.9683e-04 - acc: 1.000 - ETA: 0s - loss: 1.9646e-04 - acc: 1.000 - ETA: 0s - loss: 1.9610e-04 - acc: 1.000 - ETA: 0s - loss: 1.9565e-04 - acc: 1.000 - ETA: 0s - loss: 1.9520e-04 - acc: 1.000 - 1s 12ms/step - loss: 1.9511e-04 - acc: 1.0000 - val_loss: 1.6914e-04 - val_acc: 1.0000\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - ETA: 1s - loss: 1.8607e-04 - acc: 1.000 - ETA: 1s - loss: 1.8564e-04 - acc: 1.000 - ETA: 1s - loss: 1.8530e-04 - acc: 1.000 - ETA: 1s - loss: 1.8497e-04 - acc: 1.000 - ETA: 0s - loss: 1.8455e-04 - acc: 1.000 - ETA: 0s - loss: 1.8422e-04 - acc: 1.000 - ETA: 0s - loss: 1.8381e-04 - acc: 1.000 - ETA: 0s - loss: 1.8332e-04 - acc: 1.000 - ETA: 0s - loss: 1.8291e-04 - acc: 1.000 - ETA: 0s - loss: 1.8258e-04 - acc: 1.000 - ETA: 0s - loss: 1.8210e-04 - acc: 1.000 - ETA: 0s - loss: 1.8186e-04 - acc: 1.000 - ETA: 0s - loss: 1.8146e-04 - acc: 1.000 - ETA: 0s - loss: 1.8106e-04 - acc: 1.000 - ETA: 0s - loss: 1.8066e-04 - acc: 1.000 - ETA: 0s - loss: 1.8027e-04 - acc: 1.000 - ETA: 0s - loss: 1.7995e-04 - acc: 1.000 - ETA: 0s - loss: 1.7956e-04 - acc: 1.000 - ETA: 0s - loss: 1.7917e-04 - acc: 1.000 - ETA: 0s - loss: 1.7886e-04 - acc: 1.000 - ETA: 0s - loss: 1.7848e-04 - acc: 1.000 - 1s 12ms/step - loss: 1.7809e-04 - acc: 1.0000 - val_loss: 1.6533e-04 - val_acc: 1.0000\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - ETA: 1s - loss: 1.7035e-04 - acc: 1.000 - ETA: 1s - loss: 1.6998e-04 - acc: 1.000 - ETA: 1s - loss: 1.6969e-04 - acc: 1.000 - ETA: 0s - loss: 1.6933e-04 - acc: 1.000 - ETA: 0s - loss: 1.6904e-04 - acc: 1.000 - ETA: 0s - loss: 1.6869e-04 - acc: 1.000 - ETA: 0s - loss: 1.6833e-04 - acc: 1.000 - ETA: 0s - loss: 1.6805e-04 - acc: 1.000 - ETA: 0s - loss: 1.6769e-04 - acc: 1.000 - ETA: 0s - loss: 1.6734e-04 - acc: 1.000 - ETA: 0s - loss: 1.6699e-04 - acc: 1.000 - ETA: 0s - loss: 1.6671e-04 - acc: 1.000 - ETA: 0s - loss: 1.6636e-04 - acc: 1.000 - ETA: 0s - loss: 1.6595e-04 - acc: 1.000 - ETA: 0s - loss: 1.6567e-04 - acc: 1.000 - ETA: 0s - loss: 1.6533e-04 - acc: 1.000 - ETA: 0s - loss: 1.6492e-04 - acc: 1.000 - ETA: 0s - loss: 1.6465e-04 - acc: 1.000 - ETA: 0s - loss: 1.6438e-04 - acc: 1.000 - ETA: 0s - loss: 1.6404e-04 - acc: 1.000 - ETA: 0s - loss: 1.6364e-04 - acc: 1.000 - 1s 12ms/step - loss: 1.6344e-04 - acc: 1.0000 - val_loss: 1.6171e-04 - val_acc: 1.0000\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.5670e-04 - acc: 1.000 - ETA: 1s - loss: 1.5638e-04 - acc: 1.000 - ETA: 1s - loss: 1.5606e-04 - acc: 1.000 - ETA: 0s - loss: 1.5574e-04 - acc: 1.000 - ETA: 0s - loss: 1.5555e-04 - acc: 1.000 - ETA: 0s - loss: 1.5524e-04 - acc: 1.000 - ETA: 0s - loss: 1.5493e-04 - acc: 1.000 - ETA: 0s - loss: 1.5462e-04 - acc: 1.000 - ETA: 0s - loss: 1.5431e-04 - acc: 1.000 - ETA: 0s - loss: 1.5406e-04 - acc: 1.000 - ETA: 0s - loss: 1.5375e-04 - acc: 1.000 - ETA: 0s - loss: 1.5339e-04 - acc: 1.000 - ETA: 0s - loss: 1.5314e-04 - acc: 1.000 - ETA: 0s - loss: 1.5284e-04 - acc: 1.000 - ETA: 0s - loss: 1.5259e-04 - acc: 1.000 - ETA: 0s - loss: 1.5223e-04 - acc: 1.000 - ETA: 0s - loss: 1.5193e-04 - acc: 1.000 - ETA: 0s - loss: 1.5169e-04 - acc: 1.000 - ETA: 0s - loss: 1.5139e-04 - acc: 1.000 - ETA: 0s - loss: 1.5110e-04 - acc: 1.000 - ETA: 0s - loss: 1.5080e-04 - acc: 1.000 - 1s 12ms/step - loss: 1.5062e-04 - acc: 1.0000 - val_loss: 1.5821e-04 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - ETA: 1s - loss: 1.4467e-04 - acc: 1.000 - ETA: 1s - loss: 1.4439e-04 - acc: 1.000 - ETA: 1s - loss: 1.4417e-04 - acc: 1.000 - ETA: 0s - loss: 1.4383e-04 - acc: 1.000 - ETA: 0s - loss: 1.4355e-04 - acc: 1.000 - ETA: 0s - loss: 1.4333e-04 - acc: 1.000 - ETA: 0s - loss: 1.4305e-04 - acc: 1.000 - ETA: 0s - loss: 1.4283e-04 - acc: 1.000 - ETA: 0s - loss: 1.4256e-04 - acc: 1.000 - ETA: 0s - loss: 1.4234e-04 - acc: 1.000 - ETA: 0s - loss: 1.4217e-04 - acc: 1.000 - ETA: 0s - loss: 1.4212e-04 - acc: 1.000 - ETA: 0s - loss: 1.4195e-04 - acc: 1.000 - ETA: 0s - loss: 1.4168e-04 - acc: 1.000 - ETA: 0s - loss: 1.4141e-04 - acc: 1.000 - ETA: 0s - loss: 1.4114e-04 - acc: 1.000 - ETA: 0s - loss: 1.4093e-04 - acc: 1.000 - ETA: 0s - loss: 1.4060e-04 - acc: 1.000 - ETA: 0s - loss: 1.4034e-04 - acc: 1.000 - ETA: 0s - loss: 1.4012e-04 - acc: 1.000 - ETA: 0s - loss: 1.3991e-04 - acc: 1.000 - ETA: 0s - loss: 1.3965e-04 - acc: 1.000 - ETA: 0s - loss: 1.3944e-04 - acc: 1.000 - 1s 13ms/step - loss: 1.3928e-04 - acc: 1.0000 - val_loss: 1.5488e-04 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - ETA: 1s - loss: 1.3397e-04 - acc: 1.000 - ETA: 1s - loss: 1.3373e-04 - acc: 1.000 - ETA: 1s - loss: 1.3342e-04 - acc: 1.000 - ETA: 1s - loss: 1.3322e-04 - acc: 1.000 - ETA: 1s - loss: 1.3307e-04 - acc: 1.000 - ETA: 1s - loss: 1.3287e-04 - acc: 1.000 - ETA: 0s - loss: 1.3257e-04 - acc: 1.000 - ETA: 0s - loss: 1.3238e-04 - acc: 1.000 - ETA: 0s - loss: 1.3218e-04 - acc: 1.000 - ETA: 0s - loss: 1.3203e-04 - acc: 1.000 - ETA: 0s - loss: 1.3183e-04 - acc: 1.000 - ETA: 0s - loss: 1.3164e-04 - acc: 1.000 - ETA: 0s - loss: 1.3139e-04 - acc: 1.000 - ETA: 0s - loss: 1.3120e-04 - acc: 1.000 - ETA: 0s - loss: 1.3100e-04 - acc: 1.000 - ETA: 0s - loss: 1.3081e-04 - acc: 1.000 - ETA: 0s - loss: 1.3062e-04 - acc: 1.000 - ETA: 0s - loss: 1.3047e-04 - acc: 1.000 - ETA: 0s - loss: 1.3023e-04 - acc: 1.000 - ETA: 0s - loss: 1.3009e-04 - acc: 1.000 - ETA: 0s - loss: 1.2990e-04 - acc: 1.000 - ETA: 0s - loss: 1.2976e-04 - acc: 1.000 - ETA: 0s - loss: 1.2966e-04 - acc: 1.000 - ETA: 0s - loss: 1.2942e-04 - acc: 1.000 - ETA: 0s - loss: 1.2923e-04 - acc: 1.000 - 1s 15ms/step - loss: 1.2914e-04 - acc: 1.0000 - val_loss: 1.5171e-04 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - ETA: 1s - loss: 1.2437e-04 - acc: 1.000 - ETA: 1s - loss: 1.2419e-04 - acc: 1.000 - ETA: 1s - loss: 1.2410e-04 - acc: 1.000 - ETA: 1s - loss: 1.2397e-04 - acc: 1.000 - ETA: 1s - loss: 1.2392e-04 - acc: 1.000 - ETA: 1s - loss: 1.2378e-04 - acc: 1.000 - ETA: 1s - loss: 1.2365e-04 - acc: 1.000 - ETA: 1s - loss: 1.2347e-04 - acc: 1.000 - ETA: 1s - loss: 1.2329e-04 - acc: 1.000 - ETA: 1s - loss: 1.2316e-04 - acc: 1.000 - ETA: 1s - loss: 1.2302e-04 - acc: 1.000 - ETA: 1s - loss: 1.2284e-04 - acc: 1.000 - ETA: 1s - loss: 1.2267e-04 - acc: 1.000 - ETA: 1s - loss: 1.2253e-04 - acc: 1.000 - ETA: 0s - loss: 1.2235e-04 - acc: 1.000 - ETA: 0s - loss: 1.2222e-04 - acc: 1.000 - ETA: 0s - loss: 1.2205e-04 - acc: 1.000 - ETA: 0s - loss: 1.2187e-04 - acc: 1.000 - ETA: 0s - loss: 1.2169e-04 - acc: 1.000 - ETA: 0s - loss: 1.2152e-04 - acc: 1.000 - ETA: 0s - loss: 1.2135e-04 - acc: 1.000 - ETA: 0s - loss: 1.2113e-04 - acc: 1.000 - ETA: 0s - loss: 1.2095e-04 - acc: 1.000 - ETA: 0s - loss: 1.2078e-04 - acc: 1.000 - ETA: 0s - loss: 1.2057e-04 - acc: 1.000 - ETA: 0s - loss: 1.2035e-04 - acc: 1.000 - ETA: 0s - loss: 1.2014e-04 - acc: 1.000 - 2s 16ms/step - loss: 1.2001e-04 - acc: 1.0000 - val_loss: 1.4867e-04 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.1571e-04 - acc: 1.000 - ETA: 1s - loss: 1.1554e-04 - acc: 1.000 - ETA: 1s - loss: 1.1537e-04 - acc: 1.000 - ETA: 1s - loss: 1.1525e-04 - acc: 1.000 - ETA: 1s - loss: 1.1508e-04 - acc: 1.000 - ETA: 1s - loss: 1.1492e-04 - acc: 1.000 - ETA: 1s - loss: 1.1476e-04 - acc: 1.000 - ETA: 1s - loss: 1.1456e-04 - acc: 1.000 - ETA: 0s - loss: 1.1435e-04 - acc: 1.000 - ETA: 0s - loss: 1.1419e-04 - acc: 1.000 - ETA: 0s - loss: 1.1399e-04 - acc: 1.000 - ETA: 0s - loss: 1.1383e-04 - acc: 1.000 - ETA: 0s - loss: 1.1363e-04 - acc: 1.000 - ETA: 0s - loss: 1.1343e-04 - acc: 1.000 - ETA: 0s - loss: 1.1323e-04 - acc: 1.000 - ETA: 0s - loss: 1.1303e-04 - acc: 1.000 - ETA: 0s - loss: 1.1284e-04 - acc: 1.000 - ETA: 0s - loss: 1.1264e-04 - acc: 1.000 - ETA: 0s - loss: 1.1248e-04 - acc: 1.000 - ETA: 0s - loss: 1.1232e-04 - acc: 1.000 - ETA: 0s - loss: 1.1221e-04 - acc: 1.000 - ETA: 0s - loss: 1.1201e-04 - acc: 1.000 - ETA: 0s - loss: 1.1182e-04 - acc: 1.000 - 1s 14ms/step - loss: 1.1174e-04 - acc: 1.0000 - val_loss: 1.4575e-04 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - ETA: 1s - loss: 1.0782e-04 - acc: 1.000 - ETA: 1s - loss: 1.0768e-04 - acc: 1.000 - ETA: 1s - loss: 1.0749e-04 - acc: 1.000 - ETA: 1s - loss: 1.0734e-04 - acc: 1.000 - ETA: 1s - loss: 1.0715e-04 - acc: 1.000 - ETA: 1s - loss: 1.0704e-04 - acc: 1.000 - ETA: 1s - loss: 1.0693e-04 - acc: 1.000 - ETA: 1s - loss: 1.0674e-04 - acc: 1.000 - ETA: 1s - loss: 1.0663e-04 - acc: 1.000 - ETA: 1s - loss: 1.0660e-04 - acc: 1.000 - ETA: 1s - loss: 1.0652e-04 - acc: 1.000 - ETA: 1s - loss: 1.0638e-04 - acc: 1.000 - ETA: 1s - loss: 1.0623e-04 - acc: 1.000 - ETA: 0s - loss: 1.0612e-04 - acc: 1.000 - ETA: 0s - loss: 1.0601e-04 - acc: 1.000 - ETA: 0s - loss: 1.0586e-04 - acc: 1.000 - ETA: 0s - loss: 1.0572e-04 - acc: 1.000 - ETA: 0s - loss: 1.0561e-04 - acc: 1.000 - ETA: 0s - loss: 1.0550e-04 - acc: 1.000 - ETA: 0s - loss: 1.0539e-04 - acc: 1.000 - ETA: 0s - loss: 1.0532e-04 - acc: 1.000 - ETA: 0s - loss: 1.0521e-04 - acc: 1.000 - ETA: 0s - loss: 1.0510e-04 - acc: 1.000 - ETA: 0s - loss: 1.0500e-04 - acc: 1.000 - ETA: 0s - loss: 1.0489e-04 - acc: 1.000 - ETA: 0s - loss: 1.0478e-04 - acc: 1.000 - ETA: 0s - loss: 1.0464e-04 - acc: 1.000 - ETA: 0s - loss: 1.0453e-04 - acc: 1.000 - ETA: 0s - loss: 1.0446e-04 - acc: 1.000 - ETA: 0s - loss: 1.0435e-04 - acc: 1.000 - ETA: 0s - loss: 1.0425e-04 - acc: 1.000 - 2s 18ms/step - loss: 1.0421e-04 - acc: 1.0000 - val_loss: 1.4294e-04 - val_acc: 1.0000\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - ETA: 1s - loss: 1.0064e-04 - acc: 1.000 - ETA: 1s - loss: 1.0050e-04 - acc: 1.000 - ETA: 1s - loss: 1.0037e-04 - acc: 1.000 - ETA: 1s - loss: 1.0023e-04 - acc: 1.000 - ETA: 1s - loss: 1.0009e-04 - acc: 1.000 - ETA: 0s - loss: 9.9922e-05 - acc: 1.000 - ETA: 0s - loss: 9.9752e-05 - acc: 1.000 - ETA: 0s - loss: 9.9583e-05 - acc: 1.000 - ETA: 0s - loss: 9.9415e-05 - acc: 1.000 - ETA: 0s - loss: 9.9314e-05 - acc: 1.000 - ETA: 0s - loss: 9.9180e-05 - acc: 1.000 - ETA: 0s - loss: 9.9013e-05 - acc: 1.000 - ETA: 0s - loss: 9.8846e-05 - acc: 1.000 - ETA: 0s - loss: 9.8680e-05 - acc: 1.000 - ETA: 0s - loss: 9.8514e-05 - acc: 1.000 - ETA: 0s - loss: 9.8349e-05 - acc: 1.000 - ETA: 0s - loss: 9.8217e-05 - acc: 1.000 - ETA: 0s - loss: 9.8052e-05 - acc: 1.000 - ETA: 0s - loss: 9.7888e-05 - acc: 1.000 - ETA: 0s - loss: 9.7757e-05 - acc: 1.000 - ETA: 0s - loss: 9.7594e-05 - acc: 1.000 - ETA: 0s - loss: 9.7464e-05 - acc: 1.000 - 1s 13ms/step - loss: 9.7334e-05 - acc: 1.0000 - val_loss: 1.4022e-04 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - ETA: 1s - loss: 9.4060e-05 - acc: 1.000 - ETA: 1s - loss: 9.3902e-05 - acc: 1.000 - ETA: 1s - loss: 9.3775e-05 - acc: 1.000 - ETA: 1s - loss: 9.3651e-05 - acc: 1.000 - ETA: 1s - loss: 9.3495e-05 - acc: 1.000 - ETA: 1s - loss: 9.3339e-05 - acc: 1.000 - ETA: 0s - loss: 9.3215e-05 - acc: 1.000 - ETA: 0s - loss: 9.3121e-05 - acc: 1.000 - ETA: 0s - loss: 9.3028e-05 - acc: 1.000 - ETA: 0s - loss: 9.2904e-05 - acc: 1.000 - ETA: 0s - loss: 9.2781e-05 - acc: 1.000 - ETA: 0s - loss: 9.2689e-05 - acc: 1.000 - ETA: 0s - loss: 9.2628e-05 - acc: 1.000 - ETA: 0s - loss: 9.2535e-05 - acc: 1.000 - ETA: 0s - loss: 9.2413e-05 - acc: 1.000 - ETA: 0s - loss: 9.2261e-05 - acc: 1.000 - ETA: 0s - loss: 9.2139e-05 - acc: 1.000 - ETA: 0s - loss: 9.2017e-05 - acc: 1.000 - ETA: 0s - loss: 9.1896e-05 - acc: 1.000 - ETA: 0s - loss: 9.1805e-05 - acc: 1.000 - ETA: 0s - loss: 9.1745e-05 - acc: 1.000 - ETA: 0s - loss: 9.1654e-05 - acc: 1.000 - ETA: 0s - loss: 9.1563e-05 - acc: 1.000 - ETA: 0s - loss: 9.1443e-05 - acc: 1.000 - ETA: 0s - loss: 9.1383e-05 - acc: 1.000 - ETA: 0s - loss: 9.1293e-05 - acc: 1.000 - ETA: 0s - loss: 9.1233e-05 - acc: 1.000 - ETA: 0s - loss: 9.1173e-05 - acc: 1.000 - ETA: 0s - loss: 9.1083e-05 - acc: 1.000 - 2s 17ms/step - loss: 9.1023e-05 - acc: 1.0000 - val_loss: 1.3758e-04 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - ETA: 1s - loss: 8.8009e-05 - acc: 1.000 - ETA: 1s - loss: 8.7894e-05 - acc: 1.000 - ETA: 1s - loss: 8.7779e-05 - acc: 1.000 - ETA: 1s - loss: 8.7664e-05 - acc: 1.000 - ETA: 1s - loss: 8.7578e-05 - acc: 1.000 - ETA: 1s - loss: 8.7491e-05 - acc: 1.000 - ETA: 1s - loss: 8.7377e-05 - acc: 1.000 - ETA: 1s - loss: 8.7291e-05 - acc: 1.000 - ETA: 1s - loss: 8.7206e-05 - acc: 1.000 - ETA: 1s - loss: 8.7120e-05 - acc: 1.000 - ETA: 0s - loss: 8.7006e-05 - acc: 1.000 - ETA: 0s - loss: 8.6922e-05 - acc: 1.000 - ETA: 0s - loss: 8.6836e-05 - acc: 1.000 - ETA: 0s - loss: 8.6723e-05 - acc: 1.000 - ETA: 0s - loss: 8.6583e-05 - acc: 1.000 - ETA: 0s - loss: 8.6470e-05 - acc: 1.000 - ETA: 0s - loss: 8.6357e-05 - acc: 1.000 - ETA: 0s - loss: 8.6245e-05 - acc: 1.000 - ETA: 0s - loss: 8.6161e-05 - acc: 1.000 - ETA: 0s - loss: 8.6049e-05 - acc: 1.000 - ETA: 0s - loss: 8.5965e-05 - acc: 1.000 - ETA: 0s - loss: 8.5882e-05 - acc: 1.000 - ETA: 0s - loss: 8.5770e-05 - acc: 1.000 - ETA: 0s - loss: 8.5659e-05 - acc: 1.000 - ETA: 0s - loss: 8.5604e-05 - acc: 1.000 - ETA: 0s - loss: 8.5493e-05 - acc: 1.000 - ETA: 0s - loss: 8.5410e-05 - acc: 1.000 - ETA: 0s - loss: 8.5328e-05 - acc: 1.000 - 2s 16ms/step - loss: 8.5217e-05 - acc: 1.0000 - val_loss: 1.3506e-04 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - ETA: 2s - loss: 8.2439e-05 - acc: 1.000 - ETA: 1s - loss: 8.2332e-05 - acc: 1.000 - ETA: 1s - loss: 8.2252e-05 - acc: 1.000 - ETA: 1s - loss: 8.2147e-05 - acc: 1.000 - ETA: 1s - loss: 8.2041e-05 - acc: 1.000 - ETA: 1s - loss: 8.1909e-05 - acc: 1.000 - ETA: 1s - loss: 8.1803e-05 - acc: 1.000 - ETA: 1s - loss: 8.1697e-05 - acc: 1.000 - ETA: 0s - loss: 8.1565e-05 - acc: 1.000 - ETA: 0s - loss: 8.1434e-05 - acc: 1.000 - ETA: 0s - loss: 8.1277e-05 - acc: 1.000 - ETA: 0s - loss: 8.1147e-05 - acc: 1.000 - ETA: 0s - loss: 8.1069e-05 - acc: 1.000 - ETA: 0s - loss: 8.0965e-05 - acc: 1.000 - ETA: 0s - loss: 8.0862e-05 - acc: 1.000 - ETA: 0s - loss: 8.0784e-05 - acc: 1.000 - ETA: 0s - loss: 8.0681e-05 - acc: 1.000 - ETA: 0s - loss: 8.0578e-05 - acc: 1.000 - ETA: 0s - loss: 8.0450e-05 - acc: 1.000 - ETA: 0s - loss: 8.0347e-05 - acc: 1.000 - ETA: 0s - loss: 8.0244e-05 - acc: 1.000 - ETA: 0s - loss: 8.0142e-05 - acc: 1.000 - ETA: 0s - loss: 8.0040e-05 - acc: 1.000 - ETA: 0s - loss: 7.9913e-05 - acc: 1.000 - 1s 14ms/step - loss: 7.9862e-05 - acc: 1.0000 - val_loss: 1.3258e-04 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - ETA: 2s - loss: 7.7301e-05 - acc: 1.000 - ETA: 1s - loss: 7.7174e-05 - acc: 1.000 - ETA: 1s - loss: 7.7074e-05 - acc: 1.000 - ETA: 1s - loss: 7.6975e-05 - acc: 1.000 - ETA: 1s - loss: 7.6877e-05 - acc: 1.000 - ETA: 1s - loss: 7.6780e-05 - acc: 1.000 - ETA: 0s - loss: 7.6682e-05 - acc: 1.000 - ETA: 0s - loss: 7.6584e-05 - acc: 1.000 - ETA: 0s - loss: 7.6463e-05 - acc: 1.000 - ETA: 0s - loss: 7.6341e-05 - acc: 1.000 - ETA: 0s - loss: 7.6268e-05 - acc: 1.000 - ETA: 0s - loss: 7.6196e-05 - acc: 1.000 - ETA: 0s - loss: 7.6123e-05 - acc: 1.000 - ETA: 0s - loss: 7.6027e-05 - acc: 1.000 - ETA: 0s - loss: 7.5954e-05 - acc: 1.000 - ETA: 0s - loss: 7.5882e-05 - acc: 1.000 - ETA: 0s - loss: 7.5810e-05 - acc: 1.000 - ETA: 0s - loss: 7.5714e-05 - acc: 1.000 - ETA: 0s - loss: 7.5619e-05 - acc: 1.000 - ETA: 0s - loss: 7.5524e-05 - acc: 1.000 - ETA: 0s - loss: 7.5404e-05 - acc: 1.000 - ETA: 0s - loss: 7.5309e-05 - acc: 1.000 - ETA: 0s - loss: 7.5215e-05 - acc: 1.000 - ETA: 0s - loss: 7.5096e-05 - acc: 1.000 - ETA: 0s - loss: 7.5026e-05 - acc: 1.000 - ETA: 0s - loss: 7.4931e-05 - acc: 1.000 - 1s 15ms/step - loss: 7.4908e-05 - acc: 1.0000 - val_loss: 1.3021e-04 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - ETA: 0s - loss: 7.2535e-05 - acc: 1.000 - ETA: 1s - loss: 7.2443e-05 - acc: 1.000 - ETA: 1s - loss: 7.2397e-05 - acc: 1.000 - ETA: 1s - loss: 7.2306e-05 - acc: 1.000 - ETA: 1s - loss: 7.2237e-05 - acc: 1.000 - ETA: 1s - loss: 7.2169e-05 - acc: 1.000 - ETA: 1s - loss: 7.2100e-05 - acc: 1.000 - ETA: 1s - loss: 7.2010e-05 - acc: 1.000 - ETA: 1s - loss: 7.1965e-05 - acc: 1.000 - ETA: 1s - loss: 7.1897e-05 - acc: 1.000 - ETA: 1s - loss: 7.1852e-05 - acc: 1.000 - ETA: 1s - loss: 7.1784e-05 - acc: 1.000 - ETA: 1s - loss: 7.1739e-05 - acc: 1.000 - ETA: 1s - loss: 7.1671e-05 - acc: 1.000 - ETA: 1s - loss: 7.1604e-05 - acc: 1.000 - ETA: 1s - loss: 7.1536e-05 - acc: 1.000 - ETA: 0s - loss: 7.1447e-05 - acc: 1.000 - ETA: 0s - loss: 7.1357e-05 - acc: 1.000 - ETA: 0s - loss: 7.1268e-05 - acc: 1.000 - ETA: 0s - loss: 7.1179e-05 - acc: 1.000 - ETA: 0s - loss: 7.1090e-05 - acc: 1.000 - ETA: 0s - loss: 7.1023e-05 - acc: 1.000 - ETA: 0s - loss: 7.0957e-05 - acc: 1.000 - ETA: 0s - loss: 7.0869e-05 - acc: 1.000 - ETA: 0s - loss: 7.0781e-05 - acc: 1.000 - ETA: 0s - loss: 7.0715e-05 - acc: 1.000 - ETA: 0s - loss: 7.0649e-05 - acc: 1.000 - ETA: 0s - loss: 7.0561e-05 - acc: 1.000 - ETA: 0s - loss: 7.0495e-05 - acc: 1.000 - ETA: 0s - loss: 7.0430e-05 - acc: 1.000 - ETA: 0s - loss: 7.0342e-05 - acc: 1.000 - 2s 18ms/step - loss: 7.0321e-05 - acc: 1.0000 - val_loss: 1.2790e-04 - val_acc: 1.0000\n",
      "40/40 [==============================] - ETA:  - 0s 603us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "3it [01:30, 30.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 180 samples, validate on 40 samples\n",
      "Epoch 1/20\n",
      "100/100 [==============================] - ETA: 3:56 - loss: 8.7746e-05 - acc: 1.000 - ETA: 46s - loss: 8.7542e-05 - acc: 1.000 - ETA: 25s - loss: 8.7222e-05 - acc: 1.00 - ETA: 15s - loss: 8.6739e-05 - acc: 1.00 - ETA: 11s - loss: 8.6221e-05 - acc: 1.00 - ETA: 8s - loss: 8.5810e-05 - acc: 1.0000 - ETA: 6s - loss: 8.5224e-05 - acc: 1.000 - ETA: 5s - loss: 8.4857e-05 - acc: 1.000 - ETA: 4s - loss: 8.4427e-05 - acc: 1.000 - ETA: 3s - loss: 8.4026e-05 - acc: 1.000 - ETA: 3s - loss: 8.3651e-05 - acc: 1.000 - ETA: 2s - loss: 8.3297e-05 - acc: 1.000 - ETA: 2s - loss: 8.3028e-05 - acc: 1.000 - ETA: 1s - loss: 8.2706e-05 - acc: 1.000 - ETA: 1s - loss: 8.2460e-05 - acc: 1.000 - ETA: 1s - loss: 8.2163e-05 - acc: 1.000 - ETA: 1s - loss: 8.1878e-05 - acc: 1.000 - ETA: 0s - loss: 8.1712e-05 - acc: 1.000 - ETA: 0s - loss: 8.1444e-05 - acc: 1.000 - ETA: 0s - loss: 8.1133e-05 - acc: 1.000 - ETA: 0s - loss: 8.0882e-05 - acc: 1.000 - ETA: 0s - loss: 8.0686e-05 - acc: 1.000 - 4s 36ms/step - loss: 8.0638e-05 - acc: 1.0000 - val_loss: 4.0701e-05 - val_acc: 1.0000\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - ETA: 0s - loss: 7.5792e-05 - acc: 1.000 - ETA: 1s - loss: 7.5611e-05 - acc: 1.000 - ETA: 1s - loss: 7.5434e-05 - acc: 1.000 - ETA: 1s - loss: 7.5295e-05 - acc: 1.000 - ETA: 1s - loss: 7.5191e-05 - acc: 1.000 - ETA: 0s - loss: 7.5021e-05 - acc: 1.000 - ETA: 0s - loss: 7.4886e-05 - acc: 1.000 - ETA: 0s - loss: 7.4751e-05 - acc: 1.000 - ETA: 0s - loss: 7.4552e-05 - acc: 1.000 - ETA: 0s - loss: 7.4453e-05 - acc: 1.000 - ETA: 0s - loss: 7.4322e-05 - acc: 1.000 - ETA: 0s - loss: 7.4127e-05 - acc: 1.000 - ETA: 0s - loss: 7.3934e-05 - acc: 1.000 - ETA: 0s - loss: 7.3807e-05 - acc: 1.000 - ETA: 0s - loss: 7.3680e-05 - acc: 1.000 - ETA: 0s - loss: 7.3492e-05 - acc: 1.000 - ETA: 0s - loss: 7.3398e-05 - acc: 1.000 - ETA: 0s - loss: 7.3243e-05 - acc: 1.000 - ETA: 0s - loss: 7.3089e-05 - acc: 1.000 - ETA: 0s - loss: 7.2906e-05 - acc: 1.000 - ETA: 0s - loss: 7.2785e-05 - acc: 1.000 - ETA: 0s - loss: 7.2634e-05 - acc: 1.000 - 1s 12ms/step - loss: 7.2574e-05 - acc: 1.0000 - val_loss: 4.0141e-05 - val_acc: 1.0000\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - ETA: 0s - loss: 6.9550e-05 - acc: 1.000 - ETA: 1s - loss: 6.9439e-05 - acc: 1.000 - ETA: 1s - loss: 6.9328e-05 - acc: 1.000 - ETA: 1s - loss: 6.9190e-05 - acc: 1.000 - ETA: 1s - loss: 6.9079e-05 - acc: 1.000 - ETA: 0s - loss: 6.8915e-05 - acc: 1.000 - ETA: 0s - loss: 6.8805e-05 - acc: 1.000 - ETA: 0s - loss: 6.8697e-05 - acc: 1.000 - ETA: 0s - loss: 6.8562e-05 - acc: 1.000 - ETA: 0s - loss: 6.8454e-05 - acc: 1.000 - ETA: 0s - loss: 6.8347e-05 - acc: 1.000 - ETA: 0s - loss: 6.8214e-05 - acc: 1.000 - ETA: 0s - loss: 6.8081e-05 - acc: 1.000 - ETA: 0s - loss: 6.7976e-05 - acc: 1.000 - ETA: 0s - loss: 6.7844e-05 - acc: 1.000 - ETA: 0s - loss: 6.7739e-05 - acc: 1.000 - ETA: 0s - loss: 6.7609e-05 - acc: 1.000 - ETA: 0s - loss: 6.7531e-05 - acc: 1.000 - ETA: 0s - loss: 6.7427e-05 - acc: 1.000 - ETA: 0s - loss: 6.7324e-05 - acc: 1.000 - ETA: 0s - loss: 6.7221e-05 - acc: 1.000 - ETA: 0s - loss: 6.7119e-05 - acc: 1.000 - ETA: 0s - loss: 6.6991e-05 - acc: 1.000 - 1s 13ms/step - loss: 6.6915e-05 - acc: 1.0000 - val_loss: 3.9497e-05 - val_acc: 1.0000\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - ETA: 0s - loss: 6.4358e-05 - acc: 1.000 - ETA: 1s - loss: 6.4284e-05 - acc: 1.000 - ETA: 1s - loss: 6.4188e-05 - acc: 1.000 - ETA: 1s - loss: 6.4093e-05 - acc: 1.000 - ETA: 1s - loss: 6.3998e-05 - acc: 1.000 - ETA: 1s - loss: 6.3902e-05 - acc: 1.000 - ETA: 1s - loss: 6.3784e-05 - acc: 1.000 - ETA: 1s - loss: 6.3713e-05 - acc: 1.000 - ETA: 0s - loss: 6.3594e-05 - acc: 1.000 - ETA: 0s - loss: 6.3523e-05 - acc: 1.000 - ETA: 0s - loss: 6.3407e-05 - acc: 1.000 - ETA: 0s - loss: 6.3290e-05 - acc: 1.000 - ETA: 0s - loss: 6.3197e-05 - acc: 1.000 - ETA: 0s - loss: 6.3082e-05 - acc: 1.000 - ETA: 0s - loss: 6.2990e-05 - acc: 1.000 - ETA: 0s - loss: 6.2898e-05 - acc: 1.000 - ETA: 0s - loss: 6.2783e-05 - acc: 1.000 - ETA: 0s - loss: 6.2692e-05 - acc: 1.000 - ETA: 0s - loss: 6.2601e-05 - acc: 1.000 - ETA: 0s - loss: 6.2488e-05 - acc: 1.000 - ETA: 0s - loss: 6.2375e-05 - acc: 1.000 - ETA: 0s - loss: 6.2263e-05 - acc: 1.000 - ETA: 0s - loss: 6.2151e-05 - acc: 1.000 - 1s 13ms/step - loss: 6.2062e-05 - acc: 1.0000 - val_loss: 3.8783e-05 - val_acc: 1.0000\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - ETA: 1s - loss: 5.9809e-05 - acc: 1.000 - ETA: 1s - loss: 5.9706e-05 - acc: 1.000 - ETA: 1s - loss: 5.9598e-05 - acc: 1.000 - ETA: 1s - loss: 5.9535e-05 - acc: 1.000 - ETA: 1s - loss: 5.9429e-05 - acc: 1.000 - ETA: 0s - loss: 5.9345e-05 - acc: 1.000 - ETA: 0s - loss: 5.9261e-05 - acc: 1.000 - ETA: 0s - loss: 5.9156e-05 - acc: 1.000 - ETA: 0s - loss: 5.9072e-05 - acc: 1.000 - ETA: 0s - loss: 5.8988e-05 - acc: 1.000 - ETA: 0s - loss: 5.8884e-05 - acc: 1.000 - ETA: 0s - loss: 5.8822e-05 - acc: 1.000 - ETA: 0s - loss: 5.8719e-05 - acc: 1.000 - ETA: 0s - loss: 5.8616e-05 - acc: 1.000 - ETA: 0s - loss: 5.8534e-05 - acc: 1.000 - ETA: 0s - loss: 5.8452e-05 - acc: 1.000 - ETA: 0s - loss: 5.8350e-05 - acc: 1.000 - ETA: 0s - loss: 5.8268e-05 - acc: 1.000 - ETA: 0s - loss: 5.8167e-05 - acc: 1.000 - ETA: 0s - loss: 5.8086e-05 - acc: 1.000 - ETA: 0s - loss: 5.7985e-05 - acc: 1.000 - ETA: 0s - loss: 5.7885e-05 - acc: 1.000 - ETA: 0s - loss: 5.7805e-05 - acc: 1.000 - 1s 13ms/step - loss: 5.7765e-05 - acc: 1.0000 - val_loss: 3.8086e-05 - val_acc: 1.0000\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - ETA: 1s - loss: 5.5749e-05 - acc: 1.000 - ETA: 1s - loss: 5.5670e-05 - acc: 1.000 - ETA: 1s - loss: 5.5575e-05 - acc: 1.000 - ETA: 0s - loss: 5.5460e-05 - acc: 1.000 - ETA: 0s - loss: 5.5363e-05 - acc: 1.000 - ETA: 0s - loss: 5.5268e-05 - acc: 1.000 - ETA: 0s - loss: 5.5212e-05 - acc: 1.000 - ETA: 0s - loss: 5.5117e-05 - acc: 1.000 - ETA: 0s - loss: 5.5023e-05 - acc: 1.000 - ETA: 0s - loss: 5.4948e-05 - acc: 1.000 - ETA: 0s - loss: 5.4854e-05 - acc: 1.000 - ETA: 0s - loss: 5.4798e-05 - acc: 1.000 - ETA: 0s - loss: 5.4723e-05 - acc: 1.000 - ETA: 0s - loss: 5.4630e-05 - acc: 1.000 - ETA: 0s - loss: 5.4537e-05 - acc: 1.000 - ETA: 0s - loss: 5.4445e-05 - acc: 1.000 - ETA: 0s - loss: 5.4372e-05 - acc: 1.000 - ETA: 0s - loss: 5.4280e-05 - acc: 1.000 - ETA: 0s - loss: 5.4170e-05 - acc: 1.000 - ETA: 0s - loss: 5.4097e-05 - acc: 1.000 - ETA: 0s - loss: 5.4024e-05 - acc: 1.000 - ETA: 0s - loss: 5.3933e-05 - acc: 1.000 - 1s 12ms/step - loss: 5.3897e-05 - acc: 1.0000 - val_loss: 3.7378e-05 - val_acc: 1.0000\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - ETA: 0s - loss: 5.2065e-05 - acc: 1.000 - ETA: 1s - loss: 5.1997e-05 - acc: 1.000 - ETA: 1s - loss: 5.1928e-05 - acc: 1.000 - ETA: 1s - loss: 5.1859e-05 - acc: 1.000 - ETA: 1s - loss: 5.1789e-05 - acc: 1.000 - ETA: 0s - loss: 5.1702e-05 - acc: 1.000 - ETA: 0s - loss: 5.1633e-05 - acc: 1.000 - ETA: 0s - loss: 5.1547e-05 - acc: 1.000 - ETA: 0s - loss: 5.1444e-05 - acc: 1.000 - ETA: 0s - loss: 5.1376e-05 - acc: 1.000 - ETA: 0s - loss: 5.1307e-05 - acc: 1.000 - ETA: 0s - loss: 5.1222e-05 - acc: 1.000 - ETA: 0s - loss: 5.1138e-05 - acc: 1.000 - ETA: 0s - loss: 5.1054e-05 - acc: 1.000 - ETA: 0s - loss: 5.1003e-05 - acc: 1.000 - ETA: 0s - loss: 5.0936e-05 - acc: 1.000 - ETA: 0s - loss: 5.0885e-05 - acc: 1.000 - ETA: 0s - loss: 5.0801e-05 - acc: 1.000 - ETA: 0s - loss: 5.0751e-05 - acc: 1.000 - ETA: 0s - loss: 5.0684e-05 - acc: 1.000 - ETA: 0s - loss: 5.0634e-05 - acc: 1.000 - ETA: 0s - loss: 5.0551e-05 - acc: 1.000 - ETA: 0s - loss: 5.0485e-05 - acc: 1.000 - ETA: 0s - loss: 5.0419e-05 - acc: 1.000 - 1s 13ms/step - loss: 5.0386e-05 - acc: 1.0000 - val_loss: 3.6678e-05 - val_acc: 1.0000\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.8720e-05 - acc: 1.000 - ETA: 1s - loss: 4.8657e-05 - acc: 1.000 - ETA: 1s - loss: 4.8592e-05 - acc: 1.000 - ETA: 1s - loss: 4.8544e-05 - acc: 1.000 - ETA: 1s - loss: 4.8496e-05 - acc: 1.000 - ETA: 1s - loss: 4.8433e-05 - acc: 1.000 - ETA: 1s - loss: 4.8385e-05 - acc: 1.000 - ETA: 1s - loss: 4.8337e-05 - acc: 1.000 - ETA: 1s - loss: 4.8274e-05 - acc: 1.000 - ETA: 1s - loss: 4.8211e-05 - acc: 1.000 - ETA: 1s - loss: 4.8164e-05 - acc: 1.000 - ETA: 0s - loss: 4.8101e-05 - acc: 1.000 - ETA: 0s - loss: 4.8054e-05 - acc: 1.000 - ETA: 0s - loss: 4.8008e-05 - acc: 1.000 - ETA: 0s - loss: 4.7961e-05 - acc: 1.000 - ETA: 0s - loss: 4.7914e-05 - acc: 1.000 - ETA: 0s - loss: 4.7867e-05 - acc: 1.000 - ETA: 0s - loss: 4.7836e-05 - acc: 1.000 - ETA: 0s - loss: 4.7774e-05 - acc: 1.000 - ETA: 0s - loss: 4.7727e-05 - acc: 1.000 - ETA: 0s - loss: 4.7681e-05 - acc: 1.000 - ETA: 0s - loss: 4.7635e-05 - acc: 1.000 - ETA: 0s - loss: 4.7604e-05 - acc: 1.000 - ETA: 0s - loss: 4.7557e-05 - acc: 1.000 - ETA: 0s - loss: 4.7511e-05 - acc: 1.000 - ETA: 0s - loss: 4.7465e-05 - acc: 1.000 - ETA: 0s - loss: 4.7419e-05 - acc: 1.000 - ETA: 0s - loss: 4.7373e-05 - acc: 1.000 - ETA: 0s - loss: 4.7312e-05 - acc: 1.000 - ETA: 0s - loss: 4.7235e-05 - acc: 1.000 - ETA: 0s - loss: 4.7190e-05 - acc: 1.000 - 2s 18ms/step - loss: 4.7174e-05 - acc: 1.0000 - val_loss: 3.5988e-05 - val_acc: 1.0000\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - ETA: 1s - loss: 4.5636e-05 - acc: 1.000 - ETA: 1s - loss: 4.5566e-05 - acc: 1.000 - ETA: 1s - loss: 4.5507e-05 - acc: 1.000 - ETA: 1s - loss: 4.5449e-05 - acc: 1.000 - ETA: 1s - loss: 4.5376e-05 - acc: 1.000 - ETA: 0s - loss: 4.5303e-05 - acc: 1.000 - ETA: 0s - loss: 4.5245e-05 - acc: 1.000 - ETA: 0s - loss: 4.5202e-05 - acc: 1.000 - ETA: 0s - loss: 4.5129e-05 - acc: 1.000 - ETA: 0s - loss: 4.5071e-05 - acc: 1.000 - ETA: 0s - loss: 4.5000e-05 - acc: 1.000 - ETA: 0s - loss: 4.4927e-05 - acc: 1.000 - ETA: 0s - loss: 4.4856e-05 - acc: 1.000 - ETA: 0s - loss: 4.4799e-05 - acc: 1.000 - ETA: 0s - loss: 4.4742e-05 - acc: 1.000 - ETA: 0s - loss: 4.4685e-05 - acc: 1.000 - ETA: 0s - loss: 4.4628e-05 - acc: 1.000 - ETA: 0s - loss: 4.4571e-05 - acc: 1.000 - ETA: 0s - loss: 4.4543e-05 - acc: 1.000 - ETA: 0s - loss: 4.4487e-05 - acc: 1.000 - ETA: 0s - loss: 4.4444e-05 - acc: 1.000 - ETA: 0s - loss: 4.4388e-05 - acc: 1.000 - ETA: 0s - loss: 4.4332e-05 - acc: 1.000 - ETA: 0s - loss: 4.4276e-05 - acc: 1.000 - 1s 14ms/step - loss: 4.4220e-05 - acc: 1.0000 - val_loss: 3.5320e-05 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - ETA: 1s - loss: 4.2805e-05 - acc: 1.000 - ETA: 1s - loss: 4.2753e-05 - acc: 1.000 - ETA: 1s - loss: 4.2670e-05 - acc: 1.000 - ETA: 1s - loss: 4.2629e-05 - acc: 1.000 - ETA: 1s - loss: 4.2575e-05 - acc: 1.000 - ETA: 0s - loss: 4.2508e-05 - acc: 1.000 - ETA: 0s - loss: 4.2441e-05 - acc: 1.000 - ETA: 0s - loss: 4.2374e-05 - acc: 1.000 - ETA: 0s - loss: 4.2321e-05 - acc: 1.000 - ETA: 0s - loss: 4.2254e-05 - acc: 1.000 - ETA: 0s - loss: 4.2201e-05 - acc: 1.000 - ETA: 0s - loss: 4.2147e-05 - acc: 1.000 - ETA: 0s - loss: 4.2068e-05 - acc: 1.000 - ETA: 0s - loss: 4.2028e-05 - acc: 1.000 - ETA: 0s - loss: 4.1950e-05 - acc: 1.000 - ETA: 0s - loss: 4.1910e-05 - acc: 1.000 - ETA: 0s - loss: 4.1858e-05 - acc: 1.000 - ETA: 0s - loss: 4.1819e-05 - acc: 1.000 - ETA: 0s - loss: 4.1779e-05 - acc: 1.000 - ETA: 0s - loss: 4.1740e-05 - acc: 1.000 - ETA: 0s - loss: 4.1701e-05 - acc: 1.000 - ETA: 0s - loss: 4.1662e-05 - acc: 1.000 - ETA: 0s - loss: 4.1636e-05 - acc: 1.000 - ETA: 0s - loss: 4.1610e-05 - acc: 1.000 - ETA: 0s - loss: 4.1558e-05 - acc: 1.000 - ETA: 0s - loss: 4.1506e-05 - acc: 1.000 - 1s 15ms/step - loss: 4.1493e-05 - acc: 1.0000 - val_loss: 3.4693e-05 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - ETA: 1s - loss: 4.0189e-05 - acc: 1.000 - ETA: 2s - loss: 4.0164e-05 - acc: 1.000 - ETA: 1s - loss: 4.0127e-05 - acc: 1.000 - ETA: 1s - loss: 4.0078e-05 - acc: 1.000 - ETA: 1s - loss: 4.0040e-05 - acc: 1.000 - ETA: 1s - loss: 3.9989e-05 - acc: 1.000 - ETA: 1s - loss: 3.9939e-05 - acc: 1.000 - ETA: 1s - loss: 3.9889e-05 - acc: 1.000 - ETA: 1s - loss: 3.9839e-05 - acc: 1.000 - ETA: 1s - loss: 3.9801e-05 - acc: 1.000 - ETA: 1s - loss: 3.9777e-05 - acc: 1.000 - ETA: 1s - loss: 3.9727e-05 - acc: 1.000 - ETA: 1s - loss: 3.9702e-05 - acc: 1.000 - ETA: 0s - loss: 3.9653e-05 - acc: 1.000 - ETA: 0s - loss: 3.9604e-05 - acc: 1.000 - ETA: 0s - loss: 3.9567e-05 - acc: 1.000 - ETA: 0s - loss: 3.9530e-05 - acc: 1.000 - ETA: 0s - loss: 3.9481e-05 - acc: 1.000 - ETA: 0s - loss: 3.9445e-05 - acc: 1.000 - ETA: 0s - loss: 3.9408e-05 - acc: 1.000 - ETA: 0s - loss: 3.9359e-05 - acc: 1.000 - ETA: 0s - loss: 3.9323e-05 - acc: 1.000 - ETA: 0s - loss: 3.9286e-05 - acc: 1.000 - ETA: 0s - loss: 3.9238e-05 - acc: 1.000 - ETA: 0s - loss: 3.9202e-05 - acc: 1.000 - ETA: 0s - loss: 3.9165e-05 - acc: 1.000 - ETA: 0s - loss: 3.9129e-05 - acc: 1.000 - ETA: 0s - loss: 3.9081e-05 - acc: 1.000 - ETA: 0s - loss: 3.9033e-05 - acc: 1.000 - ETA: 0s - loss: 3.8985e-05 - acc: 1.000 - 2s 16ms/step - loss: 3.8973e-05 - acc: 1.0000 - val_loss: 3.4068e-05 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.7754e-05 - acc: 1.000 - ETA: 1s - loss: 3.7711e-05 - acc: 1.000 - ETA: 1s - loss: 3.7677e-05 - acc: 1.000 - ETA: 1s - loss: 3.7630e-05 - acc: 1.000 - ETA: 1s - loss: 3.7594e-05 - acc: 1.000 - ETA: 1s - loss: 3.7548e-05 - acc: 1.000 - ETA: 1s - loss: 3.7503e-05 - acc: 1.000 - ETA: 1s - loss: 3.7457e-05 - acc: 1.000 - ETA: 0s - loss: 3.7411e-05 - acc: 1.000 - ETA: 0s - loss: 3.7365e-05 - acc: 1.000 - ETA: 0s - loss: 3.7320e-05 - acc: 1.000 - ETA: 0s - loss: 3.7274e-05 - acc: 1.000 - ETA: 0s - loss: 3.7240e-05 - acc: 1.000 - ETA: 0s - loss: 3.7206e-05 - acc: 1.000 - ETA: 0s - loss: 3.7172e-05 - acc: 1.000 - ETA: 0s - loss: 3.7126e-05 - acc: 1.000 - ETA: 0s - loss: 3.7081e-05 - acc: 1.000 - ETA: 0s - loss: 3.7024e-05 - acc: 1.000 - ETA: 0s - loss: 3.6990e-05 - acc: 1.000 - ETA: 0s - loss: 3.6934e-05 - acc: 1.000 - ETA: 0s - loss: 3.6878e-05 - acc: 1.000 - ETA: 0s - loss: 3.6844e-05 - acc: 1.000 - ETA: 0s - loss: 3.6788e-05 - acc: 1.000 - ETA: 0s - loss: 3.6732e-05 - acc: 1.000 - ETA: 0s - loss: 3.6687e-05 - acc: 1.000 - ETA: 0s - loss: 3.6665e-05 - acc: 1.000 - 1s 15ms/step - loss: 3.6631e-05 - acc: 1.0000 - val_loss: 3.3475e-05 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.5510e-05 - acc: 1.000 - ETA: 1s - loss: 3.5460e-05 - acc: 1.000 - ETA: 1s - loss: 3.5428e-05 - acc: 1.000 - ETA: 1s - loss: 3.5396e-05 - acc: 1.000 - ETA: 1s - loss: 3.5353e-05 - acc: 1.000 - ETA: 1s - loss: 3.5310e-05 - acc: 1.000 - ETA: 1s - loss: 3.5278e-05 - acc: 1.000 - ETA: 1s - loss: 3.5245e-05 - acc: 1.000 - ETA: 1s - loss: 3.5213e-05 - acc: 1.000 - ETA: 1s - loss: 3.5170e-05 - acc: 1.000 - ETA: 1s - loss: 3.5138e-05 - acc: 1.000 - ETA: 0s - loss: 3.5096e-05 - acc: 1.000 - ETA: 0s - loss: 3.5064e-05 - acc: 1.000 - ETA: 0s - loss: 3.5022e-05 - acc: 1.000 - ETA: 0s - loss: 3.4990e-05 - acc: 1.000 - ETA: 0s - loss: 3.4958e-05 - acc: 1.000 - ETA: 0s - loss: 3.4927e-05 - acc: 1.000 - ETA: 0s - loss: 3.4906e-05 - acc: 1.000 - ETA: 0s - loss: 3.4874e-05 - acc: 1.000 - ETA: 0s - loss: 3.4842e-05 - acc: 1.000 - ETA: 0s - loss: 3.4810e-05 - acc: 1.000 - ETA: 0s - loss: 3.4758e-05 - acc: 1.000 - ETA: 0s - loss: 3.4706e-05 - acc: 1.000 - ETA: 0s - loss: 3.4664e-05 - acc: 1.000 - ETA: 0s - loss: 3.4612e-05 - acc: 1.000 - ETA: 0s - loss: 3.4560e-05 - acc: 1.000 - ETA: 0s - loss: 3.4508e-05 - acc: 1.000 - ETA: 0s - loss: 3.4466e-05 - acc: 1.000 - 2s 16ms/step - loss: 3.4456e-05 - acc: 1.0000 - val_loss: 3.2915e-05 - val_acc: 1.0000\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - ETA: 1s - loss: 3.3409e-05 - acc: 1.000 - ETA: 1s - loss: 3.3359e-05 - acc: 1.000 - ETA: 1s - loss: 3.3302e-05 - acc: 1.000 - ETA: 0s - loss: 3.3251e-05 - acc: 1.000 - ETA: 0s - loss: 3.3201e-05 - acc: 1.000 - ETA: 0s - loss: 3.3150e-05 - acc: 1.000 - ETA: 0s - loss: 3.3121e-05 - acc: 1.000 - ETA: 0s - loss: 3.3080e-05 - acc: 1.000 - ETA: 0s - loss: 3.3031e-05 - acc: 1.000 - ETA: 0s - loss: 3.2971e-05 - acc: 1.000 - ETA: 0s - loss: 3.2922e-05 - acc: 1.000 - ETA: 0s - loss: 3.2873e-05 - acc: 1.000 - ETA: 0s - loss: 3.2824e-05 - acc: 1.000 - ETA: 0s - loss: 3.2765e-05 - acc: 1.000 - ETA: 0s - loss: 3.2716e-05 - acc: 1.000 - ETA: 0s - loss: 3.2658e-05 - acc: 1.000 - ETA: 0s - loss: 3.2619e-05 - acc: 1.000 - ETA: 0s - loss: 3.2560e-05 - acc: 1.000 - ETA: 0s - loss: 3.2512e-05 - acc: 1.000 - ETA: 0s - loss: 3.2463e-05 - acc: 1.000 - 1s 12ms/step - loss: 3.2434e-05 - acc: 1.0000 - val_loss: 3.2370e-05 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - ETA: 1s - loss: 3.1462e-05 - acc: 1.000 - ETA: 1s - loss: 3.1411e-05 - acc: 1.000 - ETA: 1s - loss: 3.1364e-05 - acc: 1.000 - ETA: 1s - loss: 3.1317e-05 - acc: 1.000 - ETA: 0s - loss: 3.1270e-05 - acc: 1.000 - ETA: 0s - loss: 3.1214e-05 - acc: 1.000 - ETA: 0s - loss: 3.1159e-05 - acc: 1.000 - ETA: 0s - loss: 3.1103e-05 - acc: 1.000 - ETA: 0s - loss: 3.1048e-05 - acc: 1.000 - ETA: 0s - loss: 3.1002e-05 - acc: 1.000 - ETA: 0s - loss: 3.0956e-05 - acc: 1.000 - ETA: 0s - loss: 3.0910e-05 - acc: 1.000 - ETA: 0s - loss: 3.0855e-05 - acc: 1.000 - ETA: 0s - loss: 3.0800e-05 - acc: 1.000 - ETA: 0s - loss: 3.0745e-05 - acc: 1.000 - ETA: 0s - loss: 3.0700e-05 - acc: 1.000 - ETA: 0s - loss: 3.0636e-05 - acc: 1.000 - ETA: 0s - loss: 3.0591e-05 - acc: 1.000 - 1s 11ms/step - loss: 3.0546e-05 - acc: 1.0000 - val_loss: 3.1856e-05 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.9631e-05 - acc: 1.000 - ETA: 1s - loss: 2.9591e-05 - acc: 1.000 - ETA: 1s - loss: 2.9558e-05 - acc: 1.000 - ETA: 1s - loss: 2.9514e-05 - acc: 1.000 - ETA: 0s - loss: 2.9471e-05 - acc: 1.000 - ETA: 0s - loss: 2.9419e-05 - acc: 1.000 - ETA: 0s - loss: 2.9376e-05 - acc: 1.000 - ETA: 0s - loss: 2.9333e-05 - acc: 1.000 - ETA: 0s - loss: 2.9281e-05 - acc: 1.000 - ETA: 0s - loss: 2.9238e-05 - acc: 1.000 - ETA: 0s - loss: 2.9186e-05 - acc: 1.000 - ETA: 0s - loss: 2.9142e-05 - acc: 1.000 - ETA: 0s - loss: 2.9099e-05 - acc: 1.000 - ETA: 0s - loss: 2.9064e-05 - acc: 1.000 - ETA: 0s - loss: 2.9012e-05 - acc: 1.000 - ETA: 0s - loss: 2.8978e-05 - acc: 1.000 - ETA: 0s - loss: 2.8927e-05 - acc: 1.000 - ETA: 0s - loss: 2.8892e-05 - acc: 1.000 - ETA: 0s - loss: 2.8841e-05 - acc: 1.000 - ETA: 0s - loss: 2.8799e-05 - acc: 1.000 - 1s 12ms/step - loss: 2.8782e-05 - acc: 1.0000 - val_loss: 3.1361e-05 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - ETA: 1s - loss: 2.7927e-05 - acc: 1.000 - ETA: 1s - loss: 2.7891e-05 - acc: 1.000 - ETA: 1s - loss: 2.7843e-05 - acc: 1.000 - ETA: 0s - loss: 2.7801e-05 - acc: 1.000 - ETA: 0s - loss: 2.7760e-05 - acc: 1.000 - ETA: 0s - loss: 2.7719e-05 - acc: 1.000 - ETA: 0s - loss: 2.7670e-05 - acc: 1.000 - ETA: 0s - loss: 2.7629e-05 - acc: 1.000 - ETA: 0s - loss: 2.7580e-05 - acc: 1.000 - ETA: 0s - loss: 2.7548e-05 - acc: 1.000 - ETA: 0s - loss: 2.7499e-05 - acc: 1.000 - ETA: 0s - loss: 2.7459e-05 - acc: 1.000 - ETA: 0s - loss: 2.7419e-05 - acc: 1.000 - ETA: 0s - loss: 2.7379e-05 - acc: 1.000 - ETA: 0s - loss: 2.7339e-05 - acc: 1.000 - ETA: 0s - loss: 2.7307e-05 - acc: 1.000 - ETA: 0s - loss: 2.7268e-05 - acc: 1.000 - ETA: 0s - loss: 2.7228e-05 - acc: 1.000 - ETA: 0s - loss: 2.7188e-05 - acc: 1.000 - ETA: 0s - loss: 2.7157e-05 - acc: 1.000 - 1s 12ms/step - loss: 2.7133e-05 - acc: 1.0000 - val_loss: 3.0887e-05 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - ETA: 1s - loss: 2.6335e-05 - acc: 1.000 - ETA: 1s - loss: 2.6303e-05 - acc: 1.000 - ETA: 1s - loss: 2.6265e-05 - acc: 1.000 - ETA: 1s - loss: 2.6233e-05 - acc: 1.000 - ETA: 1s - loss: 2.6195e-05 - acc: 1.000 - ETA: 1s - loss: 2.6157e-05 - acc: 1.000 - ETA: 0s - loss: 2.6127e-05 - acc: 1.000 - ETA: 0s - loss: 2.6089e-05 - acc: 1.000 - ETA: 0s - loss: 2.6059e-05 - acc: 1.000 - ETA: 0s - loss: 2.6020e-05 - acc: 1.000 - ETA: 0s - loss: 2.5990e-05 - acc: 1.000 - ETA: 0s - loss: 2.5953e-05 - acc: 1.000 - ETA: 0s - loss: 2.5915e-05 - acc: 1.000 - ETA: 0s - loss: 2.5885e-05 - acc: 1.000 - ETA: 0s - loss: 2.5870e-05 - acc: 1.000 - ETA: 0s - loss: 2.5840e-05 - acc: 1.000 - ETA: 0s - loss: 2.5810e-05 - acc: 1.000 - ETA: 0s - loss: 2.5780e-05 - acc: 1.000 - ETA: 0s - loss: 2.5750e-05 - acc: 1.000 - ETA: 0s - loss: 2.5713e-05 - acc: 1.000 - ETA: 0s - loss: 2.5676e-05 - acc: 1.000 - ETA: 0s - loss: 2.5639e-05 - acc: 1.000 - ETA: 0s - loss: 2.5595e-05 - acc: 1.000 - 1s 14ms/step - loss: 2.5588e-05 - acc: 1.0000 - val_loss: 3.0440e-05 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.4841e-05 - acc: 1.000 - ETA: 1s - loss: 2.4803e-05 - acc: 1.000 - ETA: 1s - loss: 2.4774e-05 - acc: 1.000 - ETA: 1s - loss: 2.4745e-05 - acc: 1.000 - ETA: 1s - loss: 2.4709e-05 - acc: 1.000 - ETA: 0s - loss: 2.4674e-05 - acc: 1.000 - ETA: 0s - loss: 2.4638e-05 - acc: 1.000 - ETA: 0s - loss: 2.4610e-05 - acc: 1.000 - ETA: 0s - loss: 2.4574e-05 - acc: 1.000 - ETA: 0s - loss: 2.4539e-05 - acc: 1.000 - ETA: 0s - loss: 2.4504e-05 - acc: 1.000 - ETA: 0s - loss: 2.4469e-05 - acc: 1.000 - ETA: 0s - loss: 2.4434e-05 - acc: 1.000 - ETA: 0s - loss: 2.4399e-05 - acc: 1.000 - ETA: 0s - loss: 2.4364e-05 - acc: 1.000 - ETA: 0s - loss: 2.4336e-05 - acc: 1.000 - ETA: 0s - loss: 2.4302e-05 - acc: 1.000 - ETA: 0s - loss: 2.4267e-05 - acc: 1.000 - ETA: 0s - loss: 2.4239e-05 - acc: 1.000 - ETA: 0s - loss: 2.4198e-05 - acc: 1.000 - ETA: 0s - loss: 2.4156e-05 - acc: 1.000 - 1s 12ms/step - loss: 2.4142e-05 - acc: 1.0000 - val_loss: 3.0008e-05 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - ETA: 1s - loss: 2.3447e-05 - acc: 1.000 - ETA: 1s - loss: 2.3402e-05 - acc: 1.000 - ETA: 1s - loss: 2.3375e-05 - acc: 1.000 - ETA: 1s - loss: 2.3340e-05 - acc: 1.000 - ETA: 1s - loss: 2.3313e-05 - acc: 1.000 - ETA: 0s - loss: 2.3280e-05 - acc: 1.000 - ETA: 0s - loss: 2.3246e-05 - acc: 1.000 - ETA: 0s - loss: 2.3212e-05 - acc: 1.000 - ETA: 0s - loss: 2.3185e-05 - acc: 1.000 - ETA: 0s - loss: 2.3159e-05 - acc: 1.000 - ETA: 0s - loss: 2.3126e-05 - acc: 1.000 - ETA: 0s - loss: 2.3086e-05 - acc: 1.000 - ETA: 0s - loss: 2.3053e-05 - acc: 1.000 - ETA: 0s - loss: 2.3021e-05 - acc: 1.000 - ETA: 0s - loss: 2.2988e-05 - acc: 1.000 - ETA: 0s - loss: 2.2955e-05 - acc: 1.000 - ETA: 0s - loss: 2.2929e-05 - acc: 1.000 - ETA: 0s - loss: 2.2897e-05 - acc: 1.000 - ETA: 0s - loss: 2.2871e-05 - acc: 1.000 - ETA: 0s - loss: 2.2845e-05 - acc: 1.000 - ETA: 0s - loss: 2.2819e-05 - acc: 1.000 - 1s 13ms/step - loss: 2.2786e-05 - acc: 1.0000 - val_loss: 2.9606e-05 - val_acc: 1.0000\n",
      "40/40 [==============================] - ETA:  - 0s 500us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "4it [02:02, 30.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 180 samples, validate on 40 samples\n",
      "Epoch 1/20\n",
      "100/100 [==============================] - ETA: 3:21 - loss: 2.3954e-05 - acc: 1.000 - ETA: 32s - loss: 2.3870e-05 - acc: 1.000 - ETA: 17s - loss: 2.3740e-05 - acc: 1.00 - ETA: 10s - loss: 2.3566e-05 - acc: 1.00 - ETA: 7s - loss: 2.3400e-05 - acc: 1.0000 - ETA: 5s - loss: 2.3250e-05 - acc: 1.000 - ETA: 4s - loss: 2.3117e-05 - acc: 1.000 - ETA: 3s - loss: 2.2997e-05 - acc: 1.000 - ETA: 2s - loss: 2.2889e-05 - acc: 1.000 - ETA: 2s - loss: 2.2789e-05 - acc: 1.000 - ETA: 1s - loss: 2.2710e-05 - acc: 1.000 - ETA: 1s - loss: 2.2636e-05 - acc: 1.000 - ETA: 1s - loss: 2.2552e-05 - acc: 1.000 - ETA: 0s - loss: 2.2484e-05 - acc: 1.000 - ETA: 0s - loss: 2.2419e-05 - acc: 1.000 - ETA: 0s - loss: 2.2344e-05 - acc: 1.000 - ETA: 0s - loss: 2.2284e-05 - acc: 1.000 - ETA: 0s - loss: 2.2214e-05 - acc: 1.000 - 3s 31ms/step - loss: 2.2168e-05 - acc: 1.0000 - val_loss: 2.2588e-05 - val_acc: 1.0000\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1035e-05 - acc: 1.000 - ETA: 1s - loss: 2.1000e-05 - acc: 1.000 - ETA: 1s - loss: 2.0951e-05 - acc: 1.000 - ETA: 0s - loss: 2.0909e-05 - acc: 1.000 - ETA: 0s - loss: 2.0859e-05 - acc: 1.000 - ETA: 0s - loss: 2.0818e-05 - acc: 1.000 - ETA: 0s - loss: 2.0777e-05 - acc: 1.000 - ETA: 0s - loss: 2.0737e-05 - acc: 1.000 - ETA: 0s - loss: 2.0698e-05 - acc: 1.000 - ETA: 0s - loss: 2.0658e-05 - acc: 1.000 - ETA: 0s - loss: 2.0612e-05 - acc: 1.000 - ETA: 0s - loss: 2.0565e-05 - acc: 1.000 - ETA: 0s - loss: 2.0526e-05 - acc: 1.000 - ETA: 0s - loss: 2.0481e-05 - acc: 1.000 - ETA: 0s - loss: 2.0435e-05 - acc: 1.000 - ETA: 0s - loss: 2.0390e-05 - acc: 1.000 - ETA: 0s - loss: 2.0353e-05 - acc: 1.000 - ETA: 0s - loss: 2.0316e-05 - acc: 1.000 - ETA: 0s - loss: 2.0279e-05 - acc: 1.000 - 1s 11ms/step - loss: 2.0257e-05 - acc: 1.0000 - val_loss: 2.3126e-05 - val_acc: 1.0000\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9514e-05 - acc: 1.000 - ETA: 1s - loss: 1.9480e-05 - acc: 1.000 - ETA: 0s - loss: 1.9437e-05 - acc: 1.000 - ETA: 0s - loss: 1.9403e-05 - acc: 1.000 - ETA: 0s - loss: 1.9369e-05 - acc: 1.000 - ETA: 0s - loss: 1.9349e-05 - acc: 1.000 - ETA: 0s - loss: 1.9310e-05 - acc: 1.000 - ETA: 0s - loss: 1.9276e-05 - acc: 1.000 - ETA: 0s - loss: 1.9243e-05 - acc: 1.000 - ETA: 0s - loss: 1.9210e-05 - acc: 1.000 - ETA: 0s - loss: 1.9177e-05 - acc: 1.000 - ETA: 0s - loss: 1.9138e-05 - acc: 1.000 - ETA: 0s - loss: 1.9105e-05 - acc: 1.000 - ETA: 0s - loss: 1.9072e-05 - acc: 1.000 - ETA: 0s - loss: 1.9040e-05 - acc: 1.000 - ETA: 0s - loss: 1.9008e-05 - acc: 1.000 - ETA: 0s - loss: 1.8975e-05 - acc: 1.000 - ETA: 0s - loss: 1.8943e-05 - acc: 1.000 - ETA: 0s - loss: 1.8905e-05 - acc: 1.000 - ETA: 0s - loss: 1.8873e-05 - acc: 1.000 - 1s 12ms/step - loss: 1.8860e-05 - acc: 1.0000 - val_loss: 2.3346e-05 - val_acc: 1.0000\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - ETA: 1s - loss: 1.8219e-05 - acc: 1.000 - ETA: 1s - loss: 1.8181e-05 - acc: 1.000 - ETA: 0s - loss: 1.8143e-05 - acc: 1.000 - ETA: 0s - loss: 1.8119e-05 - acc: 1.000 - ETA: 0s - loss: 1.8084e-05 - acc: 1.000 - ETA: 0s - loss: 1.8054e-05 - acc: 1.000 - ETA: 0s - loss: 1.8024e-05 - acc: 1.000 - ETA: 0s - loss: 1.7988e-05 - acc: 1.000 - ETA: 0s - loss: 1.7953e-05 - acc: 1.000 - ETA: 0s - loss: 1.7923e-05 - acc: 1.000 - ETA: 0s - loss: 1.7888e-05 - acc: 1.000 - ETA: 0s - loss: 1.7859e-05 - acc: 1.000 - ETA: 0s - loss: 1.7823e-05 - acc: 1.000 - ETA: 0s - loss: 1.7794e-05 - acc: 1.000 - ETA: 0s - loss: 1.7759e-05 - acc: 1.000 - ETA: 0s - loss: 1.7725e-05 - acc: 1.000 - ETA: 0s - loss: 1.7696e-05 - acc: 1.000 - ETA: 0s - loss: 1.7667e-05 - acc: 1.000 - ETA: 0s - loss: 1.7639e-05 - acc: 1.000 - 1s 11ms/step - loss: 1.7633e-05 - acc: 1.0000 - val_loss: 2.3468e-05 - val_acc: 1.0000\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7054e-05 - acc: 1.000 - ETA: 1s - loss: 1.7026e-05 - acc: 1.000 - ETA: 1s - loss: 1.6998e-05 - acc: 1.000 - ETA: 0s - loss: 1.6971e-05 - acc: 1.000 - ETA: 0s - loss: 1.6939e-05 - acc: 1.000 - ETA: 0s - loss: 1.6912e-05 - acc: 1.000 - ETA: 0s - loss: 1.6886e-05 - acc: 1.000 - ETA: 0s - loss: 1.6865e-05 - acc: 1.000 - ETA: 0s - loss: 1.6833e-05 - acc: 1.000 - ETA: 0s - loss: 1.6801e-05 - acc: 1.000 - ETA: 0s - loss: 1.6774e-05 - acc: 1.000 - ETA: 0s - loss: 1.6748e-05 - acc: 1.000 - ETA: 0s - loss: 1.6716e-05 - acc: 1.000 - ETA: 0s - loss: 1.6694e-05 - acc: 1.000 - ETA: 0s - loss: 1.6668e-05 - acc: 1.000 - ETA: 0s - loss: 1.6641e-05 - acc: 1.000 - ETA: 0s - loss: 1.6615e-05 - acc: 1.000 - ETA: 0s - loss: 1.6589e-05 - acc: 1.000 - ETA: 0s - loss: 1.6568e-05 - acc: 1.000 - ETA: 0s - loss: 1.6542e-05 - acc: 1.000 - 1s 12ms/step - loss: 1.6527e-05 - acc: 1.0000 - val_loss: 2.3574e-05 - val_acc: 1.0000\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - ETA: 1s - loss: 1.6007e-05 - acc: 1.000 - ETA: 1s - loss: 1.5980e-05 - acc: 1.000 - ETA: 1s - loss: 1.5954e-05 - acc: 1.000 - ETA: 1s - loss: 1.5929e-05 - acc: 1.000 - ETA: 0s - loss: 1.5905e-05 - acc: 1.000 - ETA: 0s - loss: 1.5880e-05 - acc: 1.000 - ETA: 0s - loss: 1.5850e-05 - acc: 1.000 - ETA: 0s - loss: 1.5821e-05 - acc: 1.000 - ETA: 0s - loss: 1.5797e-05 - acc: 1.000 - ETA: 0s - loss: 1.5767e-05 - acc: 1.000 - ETA: 0s - loss: 1.5737e-05 - acc: 1.000 - ETA: 0s - loss: 1.5707e-05 - acc: 1.000 - ETA: 0s - loss: 1.5683e-05 - acc: 1.000 - ETA: 0s - loss: 1.5659e-05 - acc: 1.000 - ETA: 0s - loss: 1.5635e-05 - acc: 1.000 - ETA: 0s - loss: 1.5611e-05 - acc: 1.000 - ETA: 0s - loss: 1.5587e-05 - acc: 1.000 - ETA: 0s - loss: 1.5558e-05 - acc: 1.000 - ETA: 0s - loss: 1.5534e-05 - acc: 1.000 - 1s 11ms/step - loss: 1.5520e-05 - acc: 1.0000 - val_loss: 2.3675e-05 - val_acc: 1.0000\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - ETA: 1s - loss: 1.5042e-05 - acc: 1.000 - ETA: 1s - loss: 1.5016e-05 - acc: 1.000 - ETA: 1s - loss: 1.4997e-05 - acc: 1.000 - ETA: 1s - loss: 1.4974e-05 - acc: 1.000 - ETA: 1s - loss: 1.4951e-05 - acc: 1.000 - ETA: 0s - loss: 1.4924e-05 - acc: 1.000 - ETA: 0s - loss: 1.4901e-05 - acc: 1.000 - ETA: 0s - loss: 1.4874e-05 - acc: 1.000 - ETA: 0s - loss: 1.4852e-05 - acc: 1.000 - ETA: 0s - loss: 1.4829e-05 - acc: 1.000 - ETA: 0s - loss: 1.4802e-05 - acc: 1.000 - ETA: 0s - loss: 1.4784e-05 - acc: 1.000 - ETA: 0s - loss: 1.4761e-05 - acc: 1.000 - ETA: 0s - loss: 1.4734e-05 - acc: 1.000 - ETA: 0s - loss: 1.4712e-05 - acc: 1.000 - ETA: 0s - loss: 1.4690e-05 - acc: 1.000 - ETA: 0s - loss: 1.4668e-05 - acc: 1.000 - ETA: 0s - loss: 1.4641e-05 - acc: 1.000 - ETA: 0s - loss: 1.4619e-05 - acc: 1.000 - 1s 12ms/step - loss: 1.4596e-05 - acc: 1.0000 - val_loss: 2.3775e-05 - val_acc: 1.0000\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - ETA: 1s - loss: 1.4150e-05 - acc: 1.000 - ETA: 1s - loss: 1.4126e-05 - acc: 1.000 - ETA: 0s - loss: 1.4101e-05 - acc: 1.000 - ETA: 0s - loss: 1.4075e-05 - acc: 1.000 - ETA: 0s - loss: 1.4055e-05 - acc: 1.000 - ETA: 0s - loss: 1.4030e-05 - acc: 1.000 - ETA: 0s - loss: 1.4009e-05 - acc: 1.000 - ETA: 0s - loss: 1.3988e-05 - acc: 1.000 - ETA: 0s - loss: 1.3967e-05 - acc: 1.000 - ETA: 0s - loss: 1.3942e-05 - acc: 1.000 - ETA: 0s - loss: 1.3921e-05 - acc: 1.000 - ETA: 0s - loss: 1.3901e-05 - acc: 1.000 - ETA: 0s - loss: 1.3880e-05 - acc: 1.000 - ETA: 0s - loss: 1.3855e-05 - acc: 1.000 - ETA: 0s - loss: 1.3835e-05 - acc: 1.000 - ETA: 0s - loss: 1.3810e-05 - acc: 1.000 - ETA: 0s - loss: 1.3790e-05 - acc: 1.000 - ETA: 0s - loss: 1.3773e-05 - acc: 1.000 - ETA: 0s - loss: 1.3757e-05 - acc: 1.000 - 1s 11ms/step - loss: 1.3741e-05 - acc: 1.0000 - val_loss: 2.3889e-05 - val_acc: 1.0000\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.3331e-05 - acc: 1.000 - ETA: 1s - loss: 1.3310e-05 - acc: 1.000 - ETA: 1s - loss: 1.3290e-05 - acc: 1.000 - ETA: 0s - loss: 1.3271e-05 - acc: 1.000 - ETA: 0s - loss: 1.3251e-05 - acc: 1.000 - ETA: 0s - loss: 1.3232e-05 - acc: 1.000 - ETA: 0s - loss: 1.3208e-05 - acc: 1.000 - ETA: 0s - loss: 1.3189e-05 - acc: 1.000 - ETA: 0s - loss: 1.3165e-05 - acc: 1.000 - ETA: 0s - loss: 1.3146e-05 - acc: 1.000 - ETA: 0s - loss: 1.3126e-05 - acc: 1.000 - ETA: 0s - loss: 1.3107e-05 - acc: 1.000 - ETA: 0s - loss: 1.3088e-05 - acc: 1.000 - ETA: 0s - loss: 1.3069e-05 - acc: 1.000 - ETA: 0s - loss: 1.3050e-05 - acc: 1.000 - ETA: 0s - loss: 1.3035e-05 - acc: 1.000 - ETA: 0s - loss: 1.3016e-05 - acc: 1.000 - ETA: 0s - loss: 1.2997e-05 - acc: 1.000 - ETA: 0s - loss: 1.2981e-05 - acc: 1.000 - ETA: 0s - loss: 1.2962e-05 - acc: 1.000 - 1s 12ms/step - loss: 1.2947e-05 - acc: 1.0000 - val_loss: 2.4005e-05 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.2567e-05 - acc: 1.000 - ETA: 1s - loss: 1.2552e-05 - acc: 1.000 - ETA: 1s - loss: 1.2533e-05 - acc: 1.000 - ETA: 1s - loss: 1.2515e-05 - acc: 1.000 - ETA: 0s - loss: 1.2493e-05 - acc: 1.000 - ETA: 0s - loss: 1.2474e-05 - acc: 1.000 - ETA: 0s - loss: 1.2456e-05 - acc: 1.000 - ETA: 0s - loss: 1.2437e-05 - acc: 1.000 - ETA: 0s - loss: 1.2415e-05 - acc: 1.000 - ETA: 0s - loss: 1.2400e-05 - acc: 1.000 - ETA: 0s - loss: 1.2382e-05 - acc: 1.000 - ETA: 0s - loss: 1.2364e-05 - acc: 1.000 - ETA: 0s - loss: 1.2357e-05 - acc: 1.000 - ETA: 0s - loss: 1.2347e-05 - acc: 1.000 - ETA: 0s - loss: 1.2333e-05 - acc: 1.000 - ETA: 0s - loss: 1.2322e-05 - acc: 1.000 - ETA: 0s - loss: 1.2308e-05 - acc: 1.000 - ETA: 0s - loss: 1.2291e-05 - acc: 1.000 - ETA: 0s - loss: 1.2276e-05 - acc: 1.000 - ETA: 0s - loss: 1.2255e-05 - acc: 1.000 - ETA: 0s - loss: 1.2238e-05 - acc: 1.000 - ETA: 0s - loss: 1.2217e-05 - acc: 1.000 - 1s 13ms/step - loss: 1.2210e-05 - acc: 1.0000 - val_loss: 2.4130e-05 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - ETA: 1s - loss: 1.1852e-05 - acc: 1.000 - ETA: 1s - loss: 1.1836e-05 - acc: 1.000 - ETA: 1s - loss: 1.1819e-05 - acc: 1.000 - ETA: 0s - loss: 1.1803e-05 - acc: 1.000 - ETA: 0s - loss: 1.1783e-05 - acc: 1.000 - ETA: 0s - loss: 1.1763e-05 - acc: 1.000 - ETA: 0s - loss: 1.1749e-05 - acc: 1.000 - ETA: 0s - loss: 1.1729e-05 - acc: 1.000 - ETA: 0s - loss: 1.1712e-05 - acc: 1.000 - ETA: 0s - loss: 1.1698e-05 - acc: 1.000 - ETA: 0s - loss: 1.1681e-05 - acc: 1.000 - ETA: 0s - loss: 1.1664e-05 - acc: 1.000 - ETA: 0s - loss: 1.1646e-05 - acc: 1.000 - ETA: 0s - loss: 1.1630e-05 - acc: 1.000 - ETA: 0s - loss: 1.1613e-05 - acc: 1.000 - ETA: 0s - loss: 1.1599e-05 - acc: 1.000 - ETA: 0s - loss: 1.1583e-05 - acc: 1.000 - ETA: 0s - loss: 1.1569e-05 - acc: 1.000 - ETA: 0s - loss: 1.1556e-05 - acc: 1.000 - ETA: 0s - loss: 1.1539e-05 - acc: 1.000 - 1s 12ms/step - loss: 1.1523e-05 - acc: 1.0000 - val_loss: 2.4285e-05 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.1187e-05 - acc: 1.000 - ETA: 1s - loss: 1.1173e-05 - acc: 1.000 - ETA: 1s - loss: 1.1157e-05 - acc: 1.000 - ETA: 0s - loss: 1.1140e-05 - acc: 1.000 - ETA: 0s - loss: 1.1124e-05 - acc: 1.000 - ETA: 0s - loss: 1.1108e-05 - acc: 1.000 - ETA: 0s - loss: 1.1096e-05 - acc: 1.000 - ETA: 0s - loss: 1.1080e-05 - acc: 1.000 - ETA: 0s - loss: 1.1065e-05 - acc: 1.000 - ETA: 0s - loss: 1.1049e-05 - acc: 1.000 - ETA: 0s - loss: 1.1030e-05 - acc: 1.000 - ETA: 0s - loss: 1.1018e-05 - acc: 1.000 - ETA: 0s - loss: 1.1002e-05 - acc: 1.000 - ETA: 0s - loss: 1.0990e-05 - acc: 1.000 - ETA: 0s - loss: 1.0974e-05 - acc: 1.000 - ETA: 0s - loss: 1.0958e-05 - acc: 1.000 - ETA: 0s - loss: 1.0943e-05 - acc: 1.000 - ETA: 0s - loss: 1.0927e-05 - acc: 1.000 - ETA: 0s - loss: 1.0912e-05 - acc: 1.000 - ETA: 0s - loss: 1.0896e-05 - acc: 1.000 - 1s 12ms/step - loss: 1.0878e-05 - acc: 1.0000 - val_loss: 2.4439e-05 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - ETA: 1s - loss: 1.0564e-05 - acc: 1.000 - ETA: 1s - loss: 1.0549e-05 - acc: 1.000 - ETA: 1s - loss: 1.0535e-05 - acc: 1.000 - ETA: 1s - loss: 1.0524e-05 - acc: 1.000 - ETA: 0s - loss: 1.0508e-05 - acc: 1.000 - ETA: 0s - loss: 1.0494e-05 - acc: 1.000 - ETA: 0s - loss: 1.0479e-05 - acc: 1.000 - ETA: 0s - loss: 1.0461e-05 - acc: 1.000 - ETA: 0s - loss: 1.0444e-05 - acc: 1.000 - ETA: 0s - loss: 1.0429e-05 - acc: 1.000 - ETA: 0s - loss: 1.0414e-05 - acc: 1.000 - ETA: 0s - loss: 1.0400e-05 - acc: 1.000 - ETA: 0s - loss: 1.0382e-05 - acc: 1.000 - ETA: 0s - loss: 1.0368e-05 - acc: 1.000 - ETA: 0s - loss: 1.0356e-05 - acc: 1.000 - ETA: 0s - loss: 1.0345e-05 - acc: 1.000 - ETA: 0s - loss: 1.0333e-05 - acc: 1.000 - ETA: 0s - loss: 1.0319e-05 - acc: 1.000 - ETA: 0s - loss: 1.0304e-05 - acc: 1.000 - ETA: 0s - loss: 1.0287e-05 - acc: 1.000 - 1s 12ms/step - loss: 1.0278e-05 - acc: 1.0000 - val_loss: 2.4616e-05 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - ETA: 0s - loss: 9.9888e-06 - acc: 1.000 - ETA: 1s - loss: 9.9750e-06 - acc: 1.000 - ETA: 1s - loss: 9.9603e-06 - acc: 1.000 - ETA: 0s - loss: 9.9422e-06 - acc: 1.000 - ETA: 0s - loss: 9.9240e-06 - acc: 1.000 - ETA: 0s - loss: 9.9095e-06 - acc: 1.000 - ETA: 0s - loss: 9.8978e-06 - acc: 1.000 - ETA: 0s - loss: 9.8831e-06 - acc: 1.000 - ETA: 0s - loss: 9.8687e-06 - acc: 1.000 - ETA: 0s - loss: 9.8548e-06 - acc: 1.000 - ETA: 0s - loss: 9.8386e-06 - acc: 1.000 - ETA: 0s - loss: 9.8248e-06 - acc: 1.000 - ETA: 0s - loss: 9.8080e-06 - acc: 1.000 - ETA: 0s - loss: 9.7912e-06 - acc: 1.000 - ETA: 0s - loss: 9.7747e-06 - acc: 1.000 - ETA: 0s - loss: 9.7609e-06 - acc: 1.000 - ETA: 0s - loss: 9.7447e-06 - acc: 1.000 - ETA: 0s - loss: 9.7310e-06 - acc: 1.000 - ETA: 0s - loss: 9.7174e-06 - acc: 1.000 - 1s 11ms/step - loss: 9.7093e-06 - acc: 1.0000 - val_loss: 2.4808e-05 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - ETA: 1s - loss: 9.4385e-06 - acc: 1.000 - ETA: 1s - loss: 9.4215e-06 - acc: 1.000 - ETA: 1s - loss: 9.4067e-06 - acc: 1.000 - ETA: 0s - loss: 9.3943e-06 - acc: 1.000 - ETA: 0s - loss: 9.3815e-06 - acc: 1.000 - ETA: 0s - loss: 9.3687e-06 - acc: 1.000 - ETA: 0s - loss: 9.3557e-06 - acc: 1.000 - ETA: 0s - loss: 9.3399e-06 - acc: 1.000 - ETA: 0s - loss: 9.3269e-06 - acc: 1.000 - ETA: 0s - loss: 9.3139e-06 - acc: 1.000 - ETA: 0s - loss: 9.3036e-06 - acc: 1.000 - ETA: 0s - loss: 9.2935e-06 - acc: 1.000 - ETA: 0s - loss: 9.2783e-06 - acc: 1.000 - ETA: 0s - loss: 9.2657e-06 - acc: 1.000 - ETA: 0s - loss: 9.2530e-06 - acc: 1.000 - ETA: 0s - loss: 9.2405e-06 - acc: 1.000 - ETA: 0s - loss: 9.2253e-06 - acc: 1.000 - ETA: 0s - loss: 9.2126e-06 - acc: 1.000 - ETA: 0s - loss: 9.1999e-06 - acc: 1.000 - ETA: 0s - loss: 9.1872e-06 - acc: 1.000 - 1s 12ms/step - loss: 9.1822e-06 - acc: 1.0000 - val_loss: 2.5038e-05 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - ETA: 0s - loss: 8.9282e-06 - acc: 1.000 - ETA: 1s - loss: 8.9126e-06 - acc: 1.000 - ETA: 1s - loss: 8.9013e-06 - acc: 1.000 - ETA: 0s - loss: 8.8897e-06 - acc: 1.000 - ETA: 0s - loss: 8.8762e-06 - acc: 1.000 - ETA: 0s - loss: 8.8636e-06 - acc: 1.000 - ETA: 0s - loss: 8.8494e-06 - acc: 1.000 - ETA: 0s - loss: 8.8374e-06 - acc: 1.000 - ETA: 0s - loss: 8.8230e-06 - acc: 1.000 - ETA: 0s - loss: 8.8110e-06 - acc: 1.000 - ETA: 0s - loss: 8.7963e-06 - acc: 1.000 - ETA: 0s - loss: 8.7842e-06 - acc: 1.000 - ETA: 0s - loss: 8.7718e-06 - acc: 1.000 - ETA: 0s - loss: 8.7571e-06 - acc: 1.000 - ETA: 0s - loss: 8.7447e-06 - acc: 1.000 - ETA: 0s - loss: 8.7325e-06 - acc: 1.000 - ETA: 0s - loss: 8.7205e-06 - acc: 1.000 - ETA: 0s - loss: 8.7086e-06 - acc: 1.000 - ETA: 0s - loss: 8.6968e-06 - acc: 1.000 - ETA: 0s - loss: 8.6874e-06 - acc: 1.000 - 1s 12ms/step - loss: 8.6850e-06 - acc: 1.0000 - val_loss: 2.5267e-05 - val_acc: 1.0000\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - ETA: 0s - loss: 8.4510e-06 - acc: 1.000 - ETA: 1s - loss: 8.4375e-06 - acc: 1.000 - ETA: 1s - loss: 8.4268e-06 - acc: 1.000 - ETA: 1s - loss: 8.4126e-06 - acc: 1.000 - ETA: 1s - loss: 8.4024e-06 - acc: 1.000 - ETA: 0s - loss: 8.3904e-06 - acc: 1.000 - ETA: 0s - loss: 8.3785e-06 - acc: 1.000 - ETA: 0s - loss: 8.3644e-06 - acc: 1.000 - ETA: 0s - loss: 8.3528e-06 - acc: 1.000 - ETA: 0s - loss: 8.3411e-06 - acc: 1.000 - ETA: 0s - loss: 8.3296e-06 - acc: 1.000 - ETA: 0s - loss: 8.3181e-06 - acc: 1.000 - ETA: 0s - loss: 8.3065e-06 - acc: 1.000 - ETA: 0s - loss: 8.2929e-06 - acc: 1.000 - ETA: 0s - loss: 8.2817e-06 - acc: 1.000 - ETA: 0s - loss: 8.2683e-06 - acc: 1.000 - ETA: 0s - loss: 8.2572e-06 - acc: 1.000 - ETA: 0s - loss: 8.2461e-06 - acc: 1.000 - ETA: 0s - loss: 8.2327e-06 - acc: 1.000 - ETA: 0s - loss: 8.2213e-06 - acc: 1.000 - 1s 12ms/step - loss: 8.2168e-06 - acc: 1.0000 - val_loss: 2.5522e-05 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - ETA: 0s - loss: 7.9884e-06 - acc: 1.000 - ETA: 1s - loss: 7.9763e-06 - acc: 1.000 - ETA: 1s - loss: 7.9638e-06 - acc: 1.000 - ETA: 1s - loss: 7.9535e-06 - acc: 1.000 - ETA: 0s - loss: 7.9413e-06 - acc: 1.000 - ETA: 0s - loss: 7.9307e-06 - acc: 1.000 - ETA: 0s - loss: 7.9205e-06 - acc: 1.000 - ETA: 0s - loss: 7.9098e-06 - acc: 1.000 - ETA: 0s - loss: 7.8988e-06 - acc: 1.000 - ETA: 0s - loss: 7.8881e-06 - acc: 1.000 - ETA: 0s - loss: 7.8772e-06 - acc: 1.000 - ETA: 0s - loss: 7.8665e-06 - acc: 1.000 - ETA: 0s - loss: 7.8559e-06 - acc: 1.000 - ETA: 0s - loss: 7.8455e-06 - acc: 1.000 - ETA: 0s - loss: 7.8350e-06 - acc: 1.000 - ETA: 0s - loss: 7.8247e-06 - acc: 1.000 - ETA: 0s - loss: 7.8142e-06 - acc: 1.000 - ETA: 0s - loss: 7.8057e-06 - acc: 1.000 - ETA: 0s - loss: 7.7953e-06 - acc: 1.000 - ETA: 0s - loss: 7.7849e-06 - acc: 1.000 - 1s 12ms/step - loss: 7.7787e-06 - acc: 1.0000 - val_loss: 2.5807e-05 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - ETA: 1s - loss: 7.5695e-06 - acc: 1.000 - ETA: 1s - loss: 7.5589e-06 - acc: 1.000 - ETA: 1s - loss: 7.5492e-06 - acc: 1.000 - ETA: 1s - loss: 7.5409e-06 - acc: 1.000 - ETA: 0s - loss: 7.5276e-06 - acc: 1.000 - ETA: 0s - loss: 7.5174e-06 - acc: 1.000 - ETA: 0s - loss: 7.5090e-06 - acc: 1.000 - ETA: 0s - loss: 7.4982e-06 - acc: 1.000 - ETA: 0s - loss: 7.4846e-06 - acc: 1.000 - ETA: 0s - loss: 7.4718e-06 - acc: 1.000 - ETA: 0s - loss: 7.4635e-06 - acc: 1.000 - ETA: 0s - loss: 7.4533e-06 - acc: 1.000 - ETA: 0s - loss: 7.4432e-06 - acc: 1.000 - ETA: 0s - loss: 7.4334e-06 - acc: 1.000 - ETA: 0s - loss: 7.4234e-06 - acc: 1.000 - ETA: 0s - loss: 7.4154e-06 - acc: 1.000 - ETA: 0s - loss: 7.4034e-06 - acc: 1.000 - ETA: 0s - loss: 7.3956e-06 - acc: 1.000 - ETA: 0s - loss: 7.3858e-06 - acc: 1.000 - ETA: 0s - loss: 7.3779e-06 - acc: 1.000 - ETA: 0s - loss: 7.3681e-06 - acc: 1.000 - 1s 13ms/step - loss: 7.3662e-06 - acc: 1.0000 - val_loss: 2.6108e-05 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - ETA: 0s - loss: 7.1672e-06 - acc: 1.000 - ETA: 1s - loss: 7.1586e-06 - acc: 1.000 - ETA: 1s - loss: 7.1499e-06 - acc: 1.000 - ETA: 1s - loss: 7.1403e-06 - acc: 1.000 - ETA: 1s - loss: 7.1312e-06 - acc: 1.000 - ETA: 1s - loss: 7.1234e-06 - acc: 1.000 - ETA: 0s - loss: 7.1139e-06 - acc: 1.000 - ETA: 0s - loss: 7.1044e-06 - acc: 1.000 - ETA: 0s - loss: 7.0947e-06 - acc: 1.000 - ETA: 0s - loss: 7.0871e-06 - acc: 1.000 - ETA: 0s - loss: 7.0777e-06 - acc: 1.000 - ETA: 0s - loss: 7.0665e-06 - acc: 1.000 - ETA: 0s - loss: 7.0553e-06 - acc: 1.000 - ETA: 0s - loss: 7.0457e-06 - acc: 1.000 - ETA: 0s - loss: 7.0379e-06 - acc: 1.000 - ETA: 0s - loss: 7.0282e-06 - acc: 1.000 - ETA: 0s - loss: 7.0164e-06 - acc: 1.000 - ETA: 0s - loss: 7.0067e-06 - acc: 1.000 - ETA: 0s - loss: 6.9970e-06 - acc: 1.000 - ETA: 0s - loss: 6.9875e-06 - acc: 1.000 - ETA: 0s - loss: 6.9781e-06 - acc: 1.000 - 1s 12ms/step - loss: 6.9762e-06 - acc: 1.0000 - val_loss: 2.6434e-05 - val_acc: 1.0000\n",
      "40/40 [==============================] - ETA:  - 0s 500us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "5it [02:31, 30.40s/it]"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from keras.models import load_model\n",
    "from keras.utils import to_categorical\n",
    "from tqdm import tqdm\n",
    "x_valid = KFold(n_splits=5)\n",
    "acc_vector = []\n",
    "for train_idxs, test_idxs in tqdm(x_valid.split(X)):\n",
    "#     \"\"\"loading untrained model\"\"\"\n",
    "    model = load_model('model_conv_untrained.h5')\n",
    "    \"\"\"importing data\"\"\"\n",
    "    X_train = X[train_idxs, :]\n",
    "    X_test = X[test_idxs, :]\n",
    "    y_train = y[train_idxs, :]\n",
    "    y_test = y[test_idxs, :]\n",
    "    \"\"\"reshaping to 2d tensor \n",
    "        axis0 - n0 of data example\n",
    "        axis1 - mfcc flatten to feed into FNN\"\"\"\n",
    "    X_train_flat = np.reshape(X_train, (X_train.shape[0]*X_train.shape[1], 70*13))\n",
    "    X_train_conv = np.reshape(X_train, (X_train.shape[0]*X_train.shape[1], 70, 13, 1))\n",
    "    y_train = np.reshape(y_train, (y_train.shape[0]*y_train.shape[1]))\n",
    "    y_train_onehot = to_categorical(y_train, 10)\n",
    "    X_test_flat = np.reshape(X_test, (X_test.shape[0]*X_test.shape[1], 70*13))\n",
    "    X_test_conv = np.reshape(X_test, (X_test.shape[0]*X_test.shape[1], 70, 13, 1))\n",
    "    y_test = np.reshape(y_test, (y_test.shape[0]*y_test.shape[1]))    \n",
    "    y_test_onehot = to_categorical(y_test, 10)\n",
    "    \n",
    "    model_conv.fit(X_train_conv, y_train_onehot, epochs=20, steps_per_epoch=100, \n",
    "          validation_data=(X_test_conv, y_test_onehot), validation_steps=1)\n",
    "    score, acc = model_conv.evaluate(X_test_conv, y_test_onehot, batch_size=10)\n",
    "    acc_vector.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 170 samples, validate on 50 samples\n",
      "Epoch 1/20\n",
      "170/170 [==============================] - 1s 6ms/step - loss: 10.6571 - acc: 0.1529 - val_loss: 6.9131 - val_acc: 0.2800\n",
      "Epoch 2/20\n",
      "170/170 [==============================] - 0s 329us/step - loss: 7.8740 - acc: 0.2471 - val_loss: 2.6109 - val_acc: 0.5000\n",
      "Epoch 3/20\n",
      "170/170 [==============================] - 0s 347us/step - loss: 4.4782 - acc: 0.4059 - val_loss: 1.7522 - val_acc: 0.6200\n",
      "Epoch 4/20\n",
      "170/170 [==============================] - 0s 376us/step - loss: 3.3647 - acc: 0.4824 - val_loss: 1.0833 - val_acc: 0.6800\n",
      "Epoch 5/20\n",
      "170/170 [==============================] - 0s 370us/step - loss: 2.3628 - acc: 0.5765 - val_loss: 0.9787 - val_acc: 0.7800\n",
      "Epoch 6/20\n",
      "170/170 [==============================] - 0s 341us/step - loss: 1.9775 - acc: 0.6529 - val_loss: 0.7590 - val_acc: 0.8000\n",
      "Epoch 7/20\n",
      "170/170 [==============================] - 0s 359us/step - loss: 1.9260 - acc: 0.6118 - val_loss: 0.5530 - val_acc: 0.7800\n",
      "Epoch 8/20\n",
      "170/170 [==============================] - 0s 364us/step - loss: 1.1934 - acc: 0.7059 - val_loss: 0.3268 - val_acc: 0.8600\n",
      "Epoch 9/20\n",
      "170/170 [==============================] - 0s 359us/step - loss: 1.2368 - acc: 0.7588 - val_loss: 0.3659 - val_acc: 0.8400\n",
      "Epoch 10/20\n",
      "170/170 [==============================] - 0s 388us/step - loss: 0.7585 - acc: 0.7824 - val_loss: 0.2917 - val_acc: 0.8800\n",
      "Epoch 11/20\n",
      "170/170 [==============================] - 0s 341us/step - loss: 0.8478 - acc: 0.7824 - val_loss: 0.2029 - val_acc: 0.9400\n",
      "Epoch 12/20\n",
      "170/170 [==============================] - 0s 364us/step - loss: 0.8229 - acc: 0.8059 - val_loss: 0.2266 - val_acc: 0.9200\n",
      "Epoch 13/20\n",
      "170/170 [==============================] - 0s 382us/step - loss: 0.6267 - acc: 0.8471 - val_loss: 0.2543 - val_acc: 0.8800\n",
      "Epoch 14/20\n",
      "170/170 [==============================] - 0s 341us/step - loss: 0.5527 - acc: 0.8235 - val_loss: 0.2368 - val_acc: 0.9200\n",
      "Epoch 15/20\n",
      "170/170 [==============================] - 0s 359us/step - loss: 0.5646 - acc: 0.8588 - val_loss: 0.2003 - val_acc: 0.9200\n",
      "Epoch 16/20\n",
      "170/170 [==============================] - 0s 341us/step - loss: 0.5168 - acc: 0.8529 - val_loss: 0.1716 - val_acc: 0.9400\n",
      "Epoch 17/20\n",
      "170/170 [==============================] - 0s 335us/step - loss: 0.4017 - acc: 0.8824 - val_loss: 0.1448 - val_acc: 0.9200\n",
      "Epoch 18/20\n",
      "170/170 [==============================] - 0s 364us/step - loss: 0.5602 - acc: 0.8588 - val_loss: 0.1815 - val_acc: 0.9000\n",
      "Epoch 19/20\n",
      "170/170 [==============================] - 0s 353us/step - loss: 0.4952 - acc: 0.8765 - val_loss: 0.1578 - val_acc: 0.9600\n",
      "Epoch 20/20\n",
      "170/170 [==============================] - 0s 406us/step - loss: 0.4297 - acc: 0.8529 - val_loss: 0.1981 - val_acc: 0.9200\n",
      "50/50 [==============================] - 0s 240us/step\n",
      "Train on 170 samples, validate on 50 samples\n",
      "Epoch 1/20\n",
      "170/170 [==============================] - 1s 7ms/step - loss: 11.3497 - acc: 0.0941 - val_loss: 6.6239 - val_acc: 0.2200\n",
      "Epoch 2/20\n",
      "170/170 [==============================] - 0s 341us/step - loss: 6.5061 - acc: 0.2529 - val_loss: 3.5904 - val_acc: 0.3800\n",
      "Epoch 3/20\n",
      "170/170 [==============================] - 0s 370us/step - loss: 4.6561 - acc: 0.3588 - val_loss: 1.9121 - val_acc: 0.6600\n",
      "Epoch 4/20\n",
      "170/170 [==============================] - 0s 329us/step - loss: 3.0448 - acc: 0.5235 - val_loss: 1.1257 - val_acc: 0.7600\n",
      "Epoch 5/20\n",
      "170/170 [==============================] - 0s 323us/step - loss: 2.1895 - acc: 0.6412 - val_loss: 0.5766 - val_acc: 0.8200\n",
      "Epoch 6/20\n",
      "170/170 [==============================] - 0s 353us/step - loss: 1.6061 - acc: 0.6765 - val_loss: 0.8261 - val_acc: 0.8000\n",
      "Epoch 7/20\n",
      "170/170 [==============================] - 0s 329us/step - loss: 1.4169 - acc: 0.6941 - val_loss: 0.6750 - val_acc: 0.8600\n",
      "Epoch 8/20\n",
      "170/170 [==============================] - 0s 323us/step - loss: 1.0259 - acc: 0.7059 - val_loss: 0.4661 - val_acc: 0.8600\n",
      "Epoch 9/20\n",
      "170/170 [==============================] - 0s 347us/step - loss: 0.8418 - acc: 0.7706 - val_loss: 0.3996 - val_acc: 0.8600\n",
      "Epoch 10/20\n",
      "170/170 [==============================] - 0s 364us/step - loss: 0.5563 - acc: 0.8765 - val_loss: 0.3019 - val_acc: 0.9200\n",
      "Epoch 11/20\n",
      "170/170 [==============================] - 0s 347us/step - loss: 0.7408 - acc: 0.7882 - val_loss: 0.3837 - val_acc: 0.8600\n",
      "Epoch 12/20\n",
      "170/170 [==============================] - 0s 370us/step - loss: 0.6655 - acc: 0.8118 - val_loss: 0.4622 - val_acc: 0.8800\n",
      "Epoch 13/20\n",
      "170/170 [==============================] - 0s 359us/step - loss: 0.5191 - acc: 0.8882 - val_loss: 0.4313 - val_acc: 0.8800\n",
      "Epoch 14/20\n",
      "170/170 [==============================] - 0s 329us/step - loss: 0.5176 - acc: 0.8588 - val_loss: 0.3978 - val_acc: 0.8600\n",
      "Epoch 15/20\n",
      "170/170 [==============================] - 0s 353us/step - loss: 0.3476 - acc: 0.8882 - val_loss: 0.5463 - val_acc: 0.8600\n",
      "Epoch 16/20\n",
      "170/170 [==============================] - 0s 353us/step - loss: 0.5866 - acc: 0.8588 - val_loss: 0.6839 - val_acc: 0.8600\n",
      "Epoch 17/20\n",
      "170/170 [==============================] - 0s 364us/step - loss: 0.3081 - acc: 0.9000 - val_loss: 0.6448 - val_acc: 0.8400\n",
      "Epoch 18/20\n",
      "170/170 [==============================] - 0s 364us/step - loss: 0.3935 - acc: 0.9176 - val_loss: 0.6477 - val_acc: 0.8600\n",
      "Epoch 19/20\n",
      "170/170 [==============================] - 0s 382us/step - loss: 0.3879 - acc: 0.8882 - val_loss: 0.5786 - val_acc: 0.9200\n",
      "Epoch 20/20\n",
      "170/170 [==============================] - 0s 341us/step - loss: 0.2563 - acc: 0.9176 - val_loss: 0.4990 - val_acc: 0.9000\n",
      "50/50 [==============================] - 0s 140us/step\n",
      "Train on 180 samples, validate on 40 samples\n",
      "Epoch 1/20\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 11.0279 - acc: 0.1111 - val_loss: 5.6135 - val_acc: 0.2750\n",
      "Epoch 2/20\n",
      "180/180 [==============================] - 0s 305us/step - loss: 6.3025 - acc: 0.2611 - val_loss: 2.7988 - val_acc: 0.4750\n",
      "Epoch 3/20\n",
      "180/180 [==============================] - 0s 296us/step - loss: 4.3990 - acc: 0.4167 - val_loss: 1.4266 - val_acc: 0.6750\n",
      "Epoch 4/20\n",
      "180/180 [==============================] - 0s 316us/step - loss: 3.3623 - acc: 0.5056 - val_loss: 0.7674 - val_acc: 0.8500\n",
      "Epoch 5/20\n",
      "180/180 [==============================] - 0s 311us/step - loss: 2.2442 - acc: 0.5556 - val_loss: 0.5268 - val_acc: 0.8500\n",
      "Epoch 6/20\n",
      "180/180 [==============================] - 0s 300us/step - loss: 1.4275 - acc: 0.6778 - val_loss: 0.5770 - val_acc: 0.8500\n",
      "Epoch 7/20\n",
      "180/180 [==============================] - 0s 316us/step - loss: 1.2677 - acc: 0.6778 - val_loss: 0.3024 - val_acc: 0.9250\n",
      "Epoch 8/20\n",
      "180/180 [==============================] - 0s 305us/step - loss: 0.8784 - acc: 0.7944 - val_loss: 0.1764 - val_acc: 0.9250\n",
      "Epoch 9/20\n",
      "180/180 [==============================] - 0s 305us/step - loss: 0.9643 - acc: 0.7389 - val_loss: 0.1778 - val_acc: 0.9000\n",
      "Epoch 10/20\n",
      "180/180 [==============================] - 0s 313us/step - loss: 0.6556 - acc: 0.7722 - val_loss: 0.2642 - val_acc: 0.8750\n",
      "Epoch 11/20\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.2405 - acc: 0.875 - 0s 305us/step - loss: 0.4092 - acc: 0.8611 - val_loss: 0.3945 - val_acc: 0.8750\n",
      "Epoch 12/20\n",
      "180/180 [==============================] - 0s 322us/step - loss: 0.5576 - acc: 0.8333 - val_loss: 0.3749 - val_acc: 0.8750\n",
      "Epoch 13/20\n",
      "180/180 [==============================] - 0s 311us/step - loss: 0.3890 - acc: 0.8611 - val_loss: 0.2964 - val_acc: 0.9250\n",
      "Epoch 14/20\n",
      "180/180 [==============================] - 0s 322us/step - loss: 0.2913 - acc: 0.9056 - val_loss: 0.2501 - val_acc: 0.9500\n",
      "Epoch 15/20\n",
      "180/180 [==============================] - 0s 294us/step - loss: 0.3639 - acc: 0.9000 - val_loss: 0.1978 - val_acc: 0.9500\n",
      "Epoch 16/20\n",
      "180/180 [==============================] - 0s 322us/step - loss: 0.3076 - acc: 0.8889 - val_loss: 0.2106 - val_acc: 0.9250\n",
      "Epoch 17/20\n",
      "180/180 [==============================] - 0s 300us/step - loss: 0.4366 - acc: 0.8556 - val_loss: 0.2215 - val_acc: 0.9250\n",
      "Epoch 18/20\n",
      "180/180 [==============================] - 0s 316us/step - loss: 0.2442 - acc: 0.9167 - val_loss: 0.1776 - val_acc: 0.9500\n",
      "Epoch 19/20\n",
      "180/180 [==============================] - 0s 294us/step - loss: 0.2738 - acc: 0.9056 - val_loss: 0.1769 - val_acc: 0.9500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "180/180 [==============================] - 0s 300us/step - loss: 0.5016 - acc: 0.8778 - val_loss: 0.2086 - val_acc: 0.9250\n",
      "40/40 [==============================] - 0s 225us/step\n",
      "Train on 180 samples, validate on 40 samples\n",
      "Epoch 1/20\n",
      "180/180 [==============================] - 1s 8ms/step - loss: 11.0218 - acc: 0.1222 - val_loss: 5.7810 - val_acc: 0.2000\n",
      "Epoch 2/20\n",
      "180/180 [==============================] - 0s 489us/step - loss: 6.9780 - acc: 0.3167 - val_loss: 2.4914 - val_acc: 0.5000\n",
      "Epoch 3/20\n",
      "180/180 [==============================] - 0s 355us/step - loss: 4.3862 - acc: 0.4167 - val_loss: 1.1213 - val_acc: 0.7750\n",
      "Epoch 4/20\n",
      "180/180 [==============================] - 0s 499us/step - loss: 2.7392 - acc: 0.5389 - val_loss: 0.4701 - val_acc: 0.8250\n",
      "Epoch 5/20\n",
      "180/180 [==============================] - 0s 339us/step - loss: 2.0628 - acc: 0.5833 - val_loss: 0.1803 - val_acc: 0.9000\n",
      "Epoch 6/20\n",
      "180/180 [==============================] - 0s 333us/step - loss: 1.1905 - acc: 0.7389 - val_loss: 0.2671 - val_acc: 0.9250\n",
      "Epoch 7/20\n",
      "180/180 [==============================] - 0s 344us/step - loss: 1.1933 - acc: 0.7111 - val_loss: 0.1575 - val_acc: 0.9250\n",
      "Epoch 8/20\n",
      "180/180 [==============================] - 0s 327us/step - loss: 0.9372 - acc: 0.7500 - val_loss: 0.1391 - val_acc: 0.9250\n",
      "Epoch 9/20\n",
      "180/180 [==============================] - 0s 306us/step - loss: 0.8092 - acc: 0.8167 - val_loss: 0.1473 - val_acc: 0.9500\n",
      "Epoch 10/20\n",
      "180/180 [==============================] - 0s 322us/step - loss: 0.6004 - acc: 0.8222 - val_loss: 0.2356 - val_acc: 0.8750\n",
      "Epoch 11/20\n",
      "180/180 [==============================] - 0s 305us/step - loss: 0.3796 - acc: 0.9000 - val_loss: 0.2206 - val_acc: 0.9000\n",
      "Epoch 12/20\n",
      "180/180 [==============================] - 0s 328us/step - loss: 0.4935 - acc: 0.8611 - val_loss: 0.1363 - val_acc: 0.9500\n",
      "Epoch 13/20\n",
      "180/180 [==============================] - 0s 333us/step - loss: 0.3248 - acc: 0.8889 - val_loss: 0.0941 - val_acc: 0.9750\n",
      "Epoch 14/20\n",
      "180/180 [==============================] - 0s 322us/step - loss: 0.3090 - acc: 0.8833 - val_loss: 0.0834 - val_acc: 0.9750\n",
      "Epoch 15/20\n",
      "180/180 [==============================] - 0s 350us/step - loss: 0.3878 - acc: 0.8833 - val_loss: 0.0708 - val_acc: 0.9750\n",
      "Epoch 16/20\n",
      "180/180 [==============================] - 0s 350us/step - loss: 0.2234 - acc: 0.9222 - val_loss: 0.1031 - val_acc: 0.9500\n",
      "Epoch 17/20\n",
      "180/180 [==============================] - 0s 316us/step - loss: 0.1674 - acc: 0.9444 - val_loss: 0.1117 - val_acc: 0.9250\n",
      "Epoch 18/20\n",
      "180/180 [==============================] - 0s 311us/step - loss: 0.3534 - acc: 0.9111 - val_loss: 0.1131 - val_acc: 0.9500\n",
      "Epoch 19/20\n",
      "180/180 [==============================] - 0s 311us/step - loss: 0.2463 - acc: 0.9444 - val_loss: 0.0954 - val_acc: 0.9500\n",
      "Epoch 20/20\n",
      "180/180 [==============================] - 0s 316us/step - loss: 0.2210 - acc: 0.9222 - val_loss: 0.1116 - val_acc: 0.9500\n",
      "40/40 [==============================] - 0s 225us/step\n",
      "Train on 180 samples, validate on 40 samples\n",
      "Epoch 1/20\n",
      "180/180 [==============================] - 2s 9ms/step - loss: 11.4424 - acc: 0.1111 - val_loss: 5.3069 - val_acc: 0.3000\n",
      "Epoch 2/20\n",
      "180/180 [==============================] - 0s 311us/step - loss: 6.3632 - acc: 0.3167 - val_loss: 2.8803 - val_acc: 0.5250\n",
      "Epoch 3/20\n",
      "180/180 [==============================] - 0s 328us/step - loss: 4.5825 - acc: 0.3833 - val_loss: 2.3149 - val_acc: 0.6000\n",
      "Epoch 4/20\n",
      "180/180 [==============================] - 0s 311us/step - loss: 2.3427 - acc: 0.5611 - val_loss: 2.2952 - val_acc: 0.5750\n",
      "Epoch 5/20\n",
      "180/180 [==============================] - 0s 316us/step - loss: 1.5241 - acc: 0.6722 - val_loss: 1.7833 - val_acc: 0.6500\n",
      "Epoch 6/20\n",
      "180/180 [==============================] - 0s 461us/step - loss: 1.4435 - acc: 0.7111 - val_loss: 1.5450 - val_acc: 0.7250\n",
      "Epoch 7/20\n",
      "180/180 [==============================] - 0s 361us/step - loss: 1.0190 - acc: 0.7278 - val_loss: 1.5266 - val_acc: 0.6750\n",
      "Epoch 8/20\n",
      "180/180 [==============================] - 0s 333us/step - loss: 0.5942 - acc: 0.8333 - val_loss: 1.6689 - val_acc: 0.7500\n",
      "Epoch 9/20\n",
      "180/180 [==============================] - 0s 344us/step - loss: 0.4919 - acc: 0.8500 - val_loss: 1.8034 - val_acc: 0.7250\n",
      "Epoch 10/20\n",
      "180/180 [==============================] - 0s 336us/step - loss: 0.3618 - acc: 0.8611 - val_loss: 1.5865 - val_acc: 0.7250\n",
      "Epoch 11/20\n",
      "180/180 [==============================] - 0s 350us/step - loss: 0.5869 - acc: 0.8389 - val_loss: 1.5467 - val_acc: 0.7250\n",
      "Epoch 12/20\n",
      "180/180 [==============================] - 0s 328us/step - loss: 0.4764 - acc: 0.8722 - val_loss: 1.4959 - val_acc: 0.7750\n",
      "Epoch 13/20\n",
      "180/180 [==============================] - 0s 328us/step - loss: 0.3032 - acc: 0.8944 - val_loss: 1.4586 - val_acc: 0.7750\n",
      "Epoch 14/20\n",
      "180/180 [==============================] - 0s 339us/step - loss: 0.3235 - acc: 0.9056 - val_loss: 1.4143 - val_acc: 0.8250\n",
      "Epoch 15/20\n",
      "180/180 [==============================] - 0s 344us/step - loss: 0.1642 - acc: 0.9500 - val_loss: 1.3220 - val_acc: 0.8250\n",
      "Epoch 16/20\n",
      "180/180 [==============================] - 0s 316us/step - loss: 0.2478 - acc: 0.9000 - val_loss: 1.3340 - val_acc: 0.8250\n",
      "Epoch 17/20\n",
      "180/180 [==============================] - 0s 355us/step - loss: 0.2379 - acc: 0.9056 - val_loss: 1.4207 - val_acc: 0.8000\n",
      "Epoch 18/20\n",
      "180/180 [==============================] - 0s 328us/step - loss: 0.1940 - acc: 0.9444 - val_loss: 1.4107 - val_acc: 0.7750\n",
      "Epoch 19/20\n",
      "180/180 [==============================] - 0s 350us/step - loss: 0.3522 - acc: 0.8833 - val_loss: 1.3288 - val_acc: 0.8000\n",
      "Epoch 20/20\n",
      "180/180 [==============================] - 0s 361us/step - loss: 0.1729 - acc: 0.9500 - val_loss: 1.3535 - val_acc: 0.7750\n",
      "40/40 [==============================] - 0s 325us/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils import train_and_validate\n",
    "\n",
    "models = train_and_validate(X, y, model_type='dense', epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 910) (40, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_test_flat.shape, y_test_onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg acc:  0.937999997138977\n",
      "std dev:  0.07110554915555009\n"
     ]
    }
   ],
   "source": [
    "plt.plot(acc_vector)\n",
    "plt.ylim(0,1.2)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "print('avg acc: ', np.mean(acc_vector))\n",
    "print('std dev: ', np.std(acc_vector))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
